{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "k40.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2Ka2oWYoq1N",
        "outputId": "4d8a3367-f3c1-4fb9-838a-d3cf1f017454"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kbTa2g8Io4bw",
        "outputId": "76ea4b99-2df9-4ac3-fcbb-cb6ea55dd4e5"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a21gd8I7o88B",
        "outputId": "c948aa86-18ff-41cf-a78f-af6292af9050"
      },
      "source": [
        "cd \"/content/drive/MyDrive/Colab Notebooks\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAzmpIiCo_hF",
        "outputId": "7540b606-6860-4b7f-d54f-a02867e2b0e8"
      },
      "source": [
        "%run main_experiment_VAE.py -nf 40"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch: 378 [  100/50000 ( 0%)]  \tLoss:   91.103035\trec:   63.837879\tkl:   27.265154\n",
            "Epoch: 378 [10100/50000 (20%)]  \tLoss:   93.042755\trec:   65.168190\tkl:   27.874563\n",
            "Epoch: 378 [20100/50000 (40%)]  \tLoss:   92.371811\trec:   64.318687\tkl:   28.053127\n",
            "Epoch: 378 [30100/50000 (60%)]  \tLoss:   92.363785\trec:   65.914810\tkl:   26.448978\n",
            "Epoch: 378 [40100/50000 (80%)]  \tLoss:   87.803238\trec:   61.169861\tkl:   26.633373\n",
            "====> Epoch: 378 Average train loss: 90.8829\n",
            "====> Validation set loss: 93.2211\n",
            "====> Validation set kl: 27.4630\n",
            "Epoch: 379 [  100/50000 ( 0%)]  \tLoss:   89.007812\trec:   62.346111\tkl:   26.661695\n",
            "Epoch: 379 [10100/50000 (20%)]  \tLoss:   89.055763\trec:   62.004169\tkl:   27.051586\n",
            "Epoch: 379 [20100/50000 (40%)]  \tLoss:   89.474411\trec:   62.687103\tkl:   26.787312\n",
            "Epoch: 379 [30100/50000 (60%)]  \tLoss:   87.210144\trec:   59.778145\tkl:   27.432001\n",
            "Epoch: 379 [40100/50000 (80%)]  \tLoss:   90.766609\trec:   63.717060\tkl:   27.049553\n",
            "====> Epoch: 379 Average train loss: 90.8815\n",
            "====> Validation set loss: 93.2001\n",
            "====> Validation set kl: 27.1830\n",
            "Epoch: 380 [  100/50000 ( 0%)]  \tLoss:   87.732544\trec:   60.788330\tkl:   26.944218\n",
            "Epoch: 380 [10100/50000 (20%)]  \tLoss:   86.591522\trec:   60.394276\tkl:   26.197241\n",
            "Epoch: 380 [20100/50000 (40%)]  \tLoss:   95.764679\trec:   66.885010\tkl:   28.879667\n",
            "Epoch: 380 [30100/50000 (60%)]  \tLoss:   95.039444\trec:   66.513512\tkl:   28.525925\n",
            "Epoch: 380 [40100/50000 (80%)]  \tLoss:   92.630798\trec:   64.257042\tkl:   28.373758\n",
            "====> Epoch: 380 Average train loss: 90.8465\n",
            "====> Validation set loss: 93.2679\n",
            "====> Validation set kl: 26.9263\n",
            "Epoch: 381 [  100/50000 ( 0%)]  \tLoss:   90.445786\trec:   63.667713\tkl:   26.778076\n",
            "Epoch: 381 [10100/50000 (20%)]  \tLoss:   91.125694\trec:   63.439011\tkl:   27.686680\n",
            "Epoch: 381 [20100/50000 (40%)]  \tLoss:   90.949791\trec:   63.867558\tkl:   27.082235\n",
            "Epoch: 381 [30100/50000 (60%)]  \tLoss:   86.505203\trec:   60.073269\tkl:   26.431932\n",
            "Epoch: 381 [40100/50000 (80%)]  \tLoss:   90.242447\trec:   62.816303\tkl:   27.426149\n",
            "====> Epoch: 381 Average train loss: 90.8681\n",
            "====> Validation set loss: 93.2419\n",
            "====> Validation set kl: 27.0656\n",
            "Epoch: 382 [  100/50000 ( 0%)]  \tLoss:   94.220200\trec:   66.361359\tkl:   27.858847\n",
            "Epoch: 382 [10100/50000 (20%)]  \tLoss:   91.263283\trec:   63.537849\tkl:   27.725424\n",
            "Epoch: 382 [20100/50000 (40%)]  \tLoss:   87.795685\trec:   60.693134\tkl:   27.102549\n",
            "Epoch: 382 [30100/50000 (60%)]  \tLoss:   89.525330\trec:   62.684307\tkl:   26.841022\n",
            "Epoch: 382 [40100/50000 (80%)]  \tLoss:   90.129059\trec:   64.453484\tkl:   25.675571\n",
            "====> Epoch: 382 Average train loss: 90.8507\n",
            "====> Validation set loss: 93.1847\n",
            "====> Validation set kl: 27.1090\n",
            "Epoch: 383 [  100/50000 ( 0%)]  \tLoss:   91.501015\trec:   64.063911\tkl:   27.437103\n",
            "Epoch: 383 [10100/50000 (20%)]  \tLoss:   90.182617\trec:   62.571922\tkl:   27.610691\n",
            "Epoch: 383 [20100/50000 (40%)]  \tLoss:   93.777206\trec:   66.081223\tkl:   27.695986\n",
            "Epoch: 383 [30100/50000 (60%)]  \tLoss:   92.531631\trec:   65.113091\tkl:   27.418531\n",
            "Epoch: 383 [40100/50000 (80%)]  \tLoss:   92.289421\trec:   65.188248\tkl:   27.101171\n",
            "====> Epoch: 383 Average train loss: 90.8561\n",
            "====> Validation set loss: 93.2025\n",
            "====> Validation set kl: 27.1274\n",
            "Epoch: 384 [  100/50000 ( 0%)]  \tLoss:   89.634392\trec:   62.547436\tkl:   27.086952\n",
            "Epoch: 384 [10100/50000 (20%)]  \tLoss:   87.759415\trec:   61.979588\tkl:   25.779829\n",
            "Epoch: 384 [20100/50000 (40%)]  \tLoss:   92.264053\trec:   64.866249\tkl:   27.397804\n",
            "Epoch: 384 [30100/50000 (60%)]  \tLoss:   90.422577\trec:   63.314823\tkl:   27.107754\n",
            "Epoch: 384 [40100/50000 (80%)]  \tLoss:   90.876434\trec:   63.769680\tkl:   27.106752\n",
            "====> Epoch: 384 Average train loss: 90.8578\n",
            "====> Validation set loss: 93.1947\n",
            "====> Validation set kl: 26.8161\n",
            "Epoch: 385 [  100/50000 ( 0%)]  \tLoss:   84.065125\trec:   58.869686\tkl:   25.195438\n",
            "Epoch: 385 [10100/50000 (20%)]  \tLoss:   90.391060\trec:   63.312168\tkl:   27.078897\n",
            "Epoch: 385 [20100/50000 (40%)]  \tLoss:   91.955132\trec:   64.753761\tkl:   27.201376\n",
            "Epoch: 385 [30100/50000 (60%)]  \tLoss:   89.788086\trec:   62.992889\tkl:   26.795200\n",
            "Epoch: 385 [40100/50000 (80%)]  \tLoss:   90.511169\trec:   63.341015\tkl:   27.170153\n",
            "====> Epoch: 385 Average train loss: 90.8359\n",
            "====> Validation set loss: 93.2404\n",
            "====> Validation set kl: 26.9125\n",
            "Epoch: 386 [  100/50000 ( 0%)]  \tLoss:   91.085587\trec:   64.215233\tkl:   26.870352\n",
            "Epoch: 386 [10100/50000 (20%)]  \tLoss:   90.071815\trec:   62.049927\tkl:   28.021894\n",
            "Epoch: 386 [20100/50000 (40%)]  \tLoss:   90.602936\trec:   63.772663\tkl:   26.830271\n",
            "Epoch: 386 [30100/50000 (60%)]  \tLoss:   91.058975\trec:   64.069695\tkl:   26.989277\n",
            "Epoch: 386 [40100/50000 (80%)]  \tLoss:   93.345581\trec:   64.851357\tkl:   28.494230\n",
            "====> Epoch: 386 Average train loss: 90.8424\n",
            "====> Validation set loss: 93.2221\n",
            "====> Validation set kl: 27.1260\n",
            "Epoch: 387 [  100/50000 ( 0%)]  \tLoss:   91.696342\trec:   63.853489\tkl:   27.842852\n",
            "Epoch: 387 [10100/50000 (20%)]  \tLoss:   89.950302\trec:   63.192982\tkl:   26.757320\n",
            "Epoch: 387 [20100/50000 (40%)]  \tLoss:   93.362427\trec:   65.138649\tkl:   28.223785\n",
            "Epoch: 387 [30100/50000 (60%)]  \tLoss:   87.997452\trec:   60.697968\tkl:   27.299479\n",
            "Epoch: 387 [40100/50000 (80%)]  \tLoss:   90.436325\trec:   62.802319\tkl:   27.634010\n",
            "====> Epoch: 387 Average train loss: 90.8336\n",
            "====> Validation set loss: 93.3383\n",
            "====> Validation set kl: 27.4259\n",
            "Epoch: 388 [  100/50000 ( 0%)]  \tLoss:   94.121910\trec:   66.684685\tkl:   27.437229\n",
            "Epoch: 388 [10100/50000 (20%)]  \tLoss:   86.583771\trec:   59.855335\tkl:   26.728430\n",
            "Epoch: 388 [20100/50000 (40%)]  \tLoss:   90.348221\trec:   62.750801\tkl:   27.597416\n",
            "Epoch: 388 [30100/50000 (60%)]  \tLoss:   89.118179\trec:   62.668144\tkl:   26.450039\n",
            "Epoch: 388 [40100/50000 (80%)]  \tLoss:   88.713219\trec:   62.503078\tkl:   26.210140\n",
            "====> Epoch: 388 Average train loss: 90.8272\n",
            "====> Validation set loss: 93.2176\n",
            "====> Validation set kl: 27.2474\n",
            "Epoch: 389 [  100/50000 ( 0%)]  \tLoss:   88.802597\trec:   61.710346\tkl:   27.092255\n",
            "Epoch: 389 [10100/50000 (20%)]  \tLoss:   92.061630\trec:   64.331963\tkl:   27.729668\n",
            "Epoch: 389 [20100/50000 (40%)]  \tLoss:   93.181366\trec:   65.678642\tkl:   27.502726\n",
            "Epoch: 389 [30100/50000 (60%)]  \tLoss:   90.889191\trec:   62.409912\tkl:   28.479275\n",
            "Epoch: 389 [40100/50000 (80%)]  \tLoss:   91.351883\trec:   64.129898\tkl:   27.221985\n",
            "====> Epoch: 389 Average train loss: 90.8051\n",
            "====> Validation set loss: 93.1894\n",
            "====> Validation set kl: 27.1899\n",
            "Epoch: 390 [  100/50000 ( 0%)]  \tLoss:   91.370087\trec:   63.959114\tkl:   27.410971\n",
            "Epoch: 390 [10100/50000 (20%)]  \tLoss:   89.178719\trec:   62.506611\tkl:   26.672110\n",
            "Epoch: 390 [20100/50000 (40%)]  \tLoss:   91.546280\trec:   63.392651\tkl:   28.153627\n",
            "Epoch: 390 [30100/50000 (60%)]  \tLoss:   93.552887\trec:   66.172462\tkl:   27.380419\n",
            "Epoch: 390 [40100/50000 (80%)]  \tLoss:   94.715279\trec:   66.709190\tkl:   28.006094\n",
            "====> Epoch: 390 Average train loss: 90.8210\n",
            "====> Validation set loss: 93.1868\n",
            "====> Validation set kl: 27.3800\n",
            "Epoch: 391 [  100/50000 ( 0%)]  \tLoss:   90.699615\trec:   63.104511\tkl:   27.595110\n",
            "Epoch: 391 [10100/50000 (20%)]  \tLoss:   91.537697\trec:   63.935589\tkl:   27.602098\n",
            "Epoch: 391 [20100/50000 (40%)]  \tLoss:   92.447556\trec:   65.212753\tkl:   27.234810\n",
            "Epoch: 391 [30100/50000 (60%)]  \tLoss:   91.535088\trec:   64.078278\tkl:   27.456810\n",
            "Epoch: 391 [40100/50000 (80%)]  \tLoss:   92.004570\trec:   65.186989\tkl:   26.817577\n",
            "====> Epoch: 391 Average train loss: 90.7963\n",
            "====> Validation set loss: 93.2556\n",
            "====> Validation set kl: 27.4080\n",
            "Epoch: 392 [  100/50000 ( 0%)]  \tLoss:   94.595367\trec:   66.123703\tkl:   28.471666\n",
            "Epoch: 392 [10100/50000 (20%)]  \tLoss:   92.539604\trec:   64.856102\tkl:   27.683506\n",
            "Epoch: 392 [20100/50000 (40%)]  \tLoss:   91.458374\trec:   63.925732\tkl:   27.532648\n",
            "Epoch: 392 [30100/50000 (60%)]  \tLoss:   88.724861\trec:   61.909412\tkl:   26.815443\n",
            "Epoch: 392 [40100/50000 (80%)]  \tLoss:   89.361031\trec:   62.188602\tkl:   27.172434\n",
            "====> Epoch: 392 Average train loss: 90.7878\n",
            "====> Validation set loss: 93.2284\n",
            "====> Validation set kl: 27.3392\n",
            "Epoch: 393 [  100/50000 ( 0%)]  \tLoss:   87.931816\trec:   60.566532\tkl:   27.365278\n",
            "Epoch: 393 [10100/50000 (20%)]  \tLoss:   92.032295\trec:   65.418381\tkl:   26.613914\n",
            "Epoch: 393 [20100/50000 (40%)]  \tLoss:   93.339287\trec:   65.362465\tkl:   27.976820\n",
            "Epoch: 393 [30100/50000 (60%)]  \tLoss:   91.483955\trec:   63.880306\tkl:   27.603647\n",
            "Epoch: 393 [40100/50000 (80%)]  \tLoss:   90.857857\trec:   63.542782\tkl:   27.315077\n",
            "====> Epoch: 393 Average train loss: 90.7709\n",
            "====> Validation set loss: 93.2134\n",
            "====> Validation set kl: 27.0649\n",
            "Epoch: 394 [  100/50000 ( 0%)]  \tLoss:   90.144737\trec:   62.918427\tkl:   27.226311\n",
            "Epoch: 394 [10100/50000 (20%)]  \tLoss:   89.184753\trec:   62.309246\tkl:   26.875509\n",
            "Epoch: 394 [20100/50000 (40%)]  \tLoss:   88.691612\trec:   61.557224\tkl:   27.134386\n",
            "Epoch: 394 [30100/50000 (60%)]  \tLoss:   91.492744\trec:   62.936005\tkl:   28.556736\n",
            "Epoch: 394 [40100/50000 (80%)]  \tLoss:   89.868965\trec:   63.104137\tkl:   26.764828\n",
            "====> Epoch: 394 Average train loss: 90.7739\n",
            "====> Validation set loss: 93.2060\n",
            "====> Validation set kl: 27.1949\n",
            "Epoch: 395 [  100/50000 ( 0%)]  \tLoss:   86.532394\trec:   60.618183\tkl:   25.914207\n",
            "Epoch: 395 [10100/50000 (20%)]  \tLoss:   89.563789\trec:   62.588215\tkl:   26.975569\n",
            "Epoch: 395 [20100/50000 (40%)]  \tLoss:   93.448212\trec:   65.037582\tkl:   28.410629\n",
            "Epoch: 395 [30100/50000 (60%)]  \tLoss:   90.725952\trec:   62.595844\tkl:   28.130112\n",
            "Epoch: 395 [40100/50000 (80%)]  \tLoss:   97.704224\trec:   67.736938\tkl:   29.967287\n",
            "====> Epoch: 395 Average train loss: 90.7693\n",
            "====> Validation set loss: 93.2223\n",
            "====> Validation set kl: 27.2690\n",
            "Epoch: 396 [  100/50000 ( 0%)]  \tLoss:   91.084961\trec:   63.815544\tkl:   27.269419\n",
            "Epoch: 396 [10100/50000 (20%)]  \tLoss:   93.182320\trec:   65.732719\tkl:   27.449598\n",
            "Epoch: 396 [20100/50000 (40%)]  \tLoss:   93.621826\trec:   65.412605\tkl:   28.209221\n",
            "Epoch: 396 [30100/50000 (60%)]  \tLoss:   87.423637\trec:   60.319920\tkl:   27.103722\n",
            "Epoch: 396 [40100/50000 (80%)]  \tLoss:   95.045998\trec:   67.385757\tkl:   27.660238\n",
            "====> Epoch: 396 Average train loss: 90.7718\n",
            "====> Validation set loss: 93.2227\n",
            "====> Validation set kl: 27.0676\n",
            "Epoch: 397 [  100/50000 ( 0%)]  \tLoss:   93.962418\trec:   66.407387\tkl:   27.555031\n",
            "Epoch: 397 [10100/50000 (20%)]  \tLoss:   90.485184\trec:   62.923916\tkl:   27.561266\n",
            "Epoch: 397 [20100/50000 (40%)]  \tLoss:   92.772232\trec:   64.346985\tkl:   28.425249\n",
            "Epoch: 397 [30100/50000 (60%)]  \tLoss:   92.275742\trec:   64.478737\tkl:   27.797007\n",
            "Epoch: 397 [40100/50000 (80%)]  \tLoss:   86.506256\trec:   60.728352\tkl:   25.777906\n",
            "====> Epoch: 397 Average train loss: 90.7408\n",
            "====> Validation set loss: 93.2202\n",
            "====> Validation set kl: 27.2211\n",
            "Epoch: 398 [  100/50000 ( 0%)]  \tLoss:   89.835007\trec:   63.389595\tkl:   26.445414\n",
            "Epoch: 398 [10100/50000 (20%)]  \tLoss:   84.413376\trec:   58.567490\tkl:   25.845882\n",
            "Epoch: 398 [20100/50000 (40%)]  \tLoss:   91.307243\trec:   64.268394\tkl:   27.038841\n",
            "Epoch: 398 [30100/50000 (60%)]  \tLoss:   91.824356\trec:   63.944099\tkl:   27.880249\n",
            "Epoch: 398 [40100/50000 (80%)]  \tLoss:   87.588387\trec:   61.275879\tkl:   26.312511\n",
            "====> Epoch: 398 Average train loss: 90.7488\n",
            "====> Validation set loss: 93.2966\n",
            "====> Validation set kl: 27.4178\n",
            "Epoch: 399 [  100/50000 ( 0%)]  \tLoss:   89.914139\trec:   62.463486\tkl:   27.450657\n",
            "Epoch: 399 [10100/50000 (20%)]  \tLoss:   91.438728\trec:   64.241318\tkl:   27.197416\n",
            "Epoch: 399 [20100/50000 (40%)]  \tLoss:   89.132690\trec:   62.505009\tkl:   26.627689\n",
            "Epoch: 399 [30100/50000 (60%)]  \tLoss:   94.335205\trec:   66.847115\tkl:   27.488091\n",
            "Epoch: 399 [40100/50000 (80%)]  \tLoss:   91.566765\trec:   63.984570\tkl:   27.582193\n",
            "====> Epoch: 399 Average train loss: 90.7236\n",
            "====> Validation set loss: 93.1813\n",
            "====> Validation set kl: 27.3459\n",
            "Epoch: 400 [  100/50000 ( 0%)]  \tLoss:   93.158905\trec:   65.243179\tkl:   27.915724\n",
            "Epoch: 400 [10100/50000 (20%)]  \tLoss:   92.419823\trec:   64.707970\tkl:   27.711855\n",
            "Epoch: 400 [20100/50000 (40%)]  \tLoss:   92.365547\trec:   63.768314\tkl:   28.597237\n",
            "Epoch: 400 [30100/50000 (60%)]  \tLoss:   93.534950\trec:   65.274727\tkl:   28.260221\n",
            "Epoch: 400 [40100/50000 (80%)]  \tLoss:   95.280190\trec:   67.046349\tkl:   28.233839\n",
            "====> Epoch: 400 Average train loss: 90.7132\n",
            "====> Validation set loss: 93.1654\n",
            "====> Validation set kl: 27.1897\n",
            "Epoch: 401 [  100/50000 ( 0%)]  \tLoss:   92.051384\trec:   64.322182\tkl:   27.729204\n",
            "Epoch: 401 [10100/50000 (20%)]  \tLoss:   93.977959\trec:   65.582184\tkl:   28.395775\n",
            "Epoch: 401 [20100/50000 (40%)]  \tLoss:   91.644760\trec:   63.982037\tkl:   27.662731\n",
            "Epoch: 401 [30100/50000 (60%)]  \tLoss:   88.050583\trec:   61.336758\tkl:   26.713827\n",
            "Epoch: 401 [40100/50000 (80%)]  \tLoss:   93.542770\trec:   65.035973\tkl:   28.506796\n",
            "====> Epoch: 401 Average train loss: 90.7381\n",
            "====> Validation set loss: 93.1773\n",
            "====> Validation set kl: 27.2621\n",
            "Epoch: 402 [  100/50000 ( 0%)]  \tLoss:   87.608307\trec:   61.087563\tkl:   26.520748\n",
            "Epoch: 402 [10100/50000 (20%)]  \tLoss:   93.690254\trec:   65.589195\tkl:   28.101051\n",
            "Epoch: 402 [20100/50000 (40%)]  \tLoss:   90.791344\trec:   63.609631\tkl:   27.181711\n",
            "Epoch: 402 [30100/50000 (60%)]  \tLoss:   93.630287\trec:   65.702644\tkl:   27.927641\n",
            "Epoch: 402 [40100/50000 (80%)]  \tLoss:   92.047821\trec:   64.626915\tkl:   27.420902\n",
            "====> Epoch: 402 Average train loss: 90.7270\n",
            "====> Validation set loss: 93.1539\n",
            "====> Validation set kl: 27.2230\n",
            "Epoch: 403 [  100/50000 ( 0%)]  \tLoss:   87.713493\trec:   61.437626\tkl:   26.275871\n",
            "Epoch: 403 [10100/50000 (20%)]  \tLoss:   87.597153\trec:   61.349052\tkl:   26.248104\n",
            "Epoch: 403 [20100/50000 (40%)]  \tLoss:   91.194496\trec:   63.899509\tkl:   27.294991\n",
            "Epoch: 403 [30100/50000 (60%)]  \tLoss:   87.697563\trec:   60.925007\tkl:   26.772560\n",
            "Epoch: 403 [40100/50000 (80%)]  \tLoss:   90.153496\trec:   63.763016\tkl:   26.390482\n",
            "====> Epoch: 403 Average train loss: 90.7147\n",
            "====> Validation set loss: 93.1912\n",
            "====> Validation set kl: 27.2569\n",
            "Epoch: 404 [  100/50000 ( 0%)]  \tLoss:   89.282654\trec:   62.266853\tkl:   27.015795\n",
            "Epoch: 404 [10100/50000 (20%)]  \tLoss:   91.666168\trec:   64.389305\tkl:   27.276867\n",
            "Epoch: 404 [20100/50000 (40%)]  \tLoss:   89.404030\trec:   62.446091\tkl:   26.957939\n",
            "Epoch: 404 [30100/50000 (60%)]  \tLoss:   90.687576\trec:   63.051628\tkl:   27.635948\n",
            "Epoch: 404 [40100/50000 (80%)]  \tLoss:   90.683678\trec:   62.656288\tkl:   28.027390\n",
            "====> Epoch: 404 Average train loss: 90.7058\n",
            "====> Validation set loss: 93.0894\n",
            "====> Validation set kl: 27.3996\n",
            "Epoch: 405 [  100/50000 ( 0%)]  \tLoss:   92.487061\trec:   65.620377\tkl:   26.866684\n",
            "Epoch: 405 [10100/50000 (20%)]  \tLoss:   90.765167\trec:   63.221992\tkl:   27.543175\n",
            "Epoch: 405 [20100/50000 (40%)]  \tLoss:   87.621460\trec:   61.209877\tkl:   26.411581\n",
            "Epoch: 405 [30100/50000 (60%)]  \tLoss:   88.205147\trec:   61.624504\tkl:   26.580639\n",
            "Epoch: 405 [40100/50000 (80%)]  \tLoss:   87.811333\trec:   61.162460\tkl:   26.648874\n",
            "====> Epoch: 405 Average train loss: 90.7174\n",
            "====> Validation set loss: 93.1787\n",
            "====> Validation set kl: 27.1278\n",
            "Epoch: 406 [  100/50000 ( 0%)]  \tLoss:   89.891853\trec:   62.219784\tkl:   27.672075\n",
            "Epoch: 406 [10100/50000 (20%)]  \tLoss:   92.584923\trec:   64.289742\tkl:   28.295176\n",
            "Epoch: 406 [20100/50000 (40%)]  \tLoss:   86.333824\trec:   60.707764\tkl:   25.626064\n",
            "Epoch: 406 [30100/50000 (60%)]  \tLoss:   90.692810\trec:   63.308456\tkl:   27.384352\n",
            "Epoch: 406 [40100/50000 (80%)]  \tLoss:   89.150078\trec:   62.837097\tkl:   26.312979\n",
            "====> Epoch: 406 Average train loss: 90.6943\n",
            "====> Validation set loss: 93.1223\n",
            "====> Validation set kl: 27.4619\n",
            "Epoch: 407 [  100/50000 ( 0%)]  \tLoss:   92.980942\trec:   65.783127\tkl:   27.197823\n",
            "Epoch: 407 [10100/50000 (20%)]  \tLoss:   90.966881\trec:   63.700134\tkl:   27.266745\n",
            "Epoch: 407 [20100/50000 (40%)]  \tLoss:   90.787964\trec:   63.565945\tkl:   27.222015\n",
            "Epoch: 407 [30100/50000 (60%)]  \tLoss:   91.655663\trec:   64.040779\tkl:   27.614887\n",
            "Epoch: 407 [40100/50000 (80%)]  \tLoss:   87.911980\trec:   60.995262\tkl:   26.916716\n",
            "====> Epoch: 407 Average train loss: 90.7057\n",
            "====> Validation set loss: 93.2332\n",
            "====> Validation set kl: 27.0087\n",
            "Epoch: 408 [  100/50000 ( 0%)]  \tLoss:   88.250854\trec:   61.890285\tkl:   26.360573\n",
            "Epoch: 408 [10100/50000 (20%)]  \tLoss:   90.863174\trec:   64.162437\tkl:   26.700729\n",
            "Epoch: 408 [20100/50000 (40%)]  \tLoss:   92.513809\trec:   65.839943\tkl:   26.673859\n",
            "Epoch: 408 [30100/50000 (60%)]  \tLoss:   93.682205\trec:   65.014587\tkl:   28.667620\n",
            "Epoch: 408 [40100/50000 (80%)]  \tLoss:   93.565483\trec:   66.056267\tkl:   27.509220\n",
            "====> Epoch: 408 Average train loss: 90.7021\n",
            "====> Validation set loss: 93.0963\n",
            "====> Validation set kl: 27.2219\n",
            "Epoch: 409 [  100/50000 ( 0%)]  \tLoss:   90.959686\trec:   63.285164\tkl:   27.674526\n",
            "Epoch: 409 [10100/50000 (20%)]  \tLoss:   89.527672\trec:   62.553841\tkl:   26.973837\n",
            "Epoch: 409 [20100/50000 (40%)]  \tLoss:   95.422050\trec:   66.964149\tkl:   28.457899\n",
            "Epoch: 409 [30100/50000 (60%)]  \tLoss:   88.034081\trec:   60.972855\tkl:   27.061226\n",
            "Epoch: 409 [40100/50000 (80%)]  \tLoss:   90.681168\trec:   64.371284\tkl:   26.309887\n",
            "====> Epoch: 409 Average train loss: 90.6582\n",
            "====> Validation set loss: 93.2432\n",
            "====> Validation set kl: 27.6326\n",
            "Epoch: 410 [  100/50000 ( 0%)]  \tLoss:   87.987595\trec:   60.930038\tkl:   27.057556\n",
            "Epoch: 410 [10100/50000 (20%)]  \tLoss:   91.274361\trec:   62.853317\tkl:   28.421041\n",
            "Epoch: 410 [20100/50000 (40%)]  \tLoss:   90.214043\trec:   63.255360\tkl:   26.958675\n",
            "Epoch: 410 [30100/50000 (60%)]  \tLoss:   88.695526\trec:   61.681580\tkl:   27.013950\n",
            "Epoch: 410 [40100/50000 (80%)]  \tLoss:   86.454361\trec:   60.732430\tkl:   25.721933\n",
            "====> Epoch: 410 Average train loss: 90.6785\n",
            "====> Validation set loss: 93.0479\n",
            "====> Validation set kl: 27.3574\n",
            "Epoch: 411 [  100/50000 ( 0%)]  \tLoss:   88.728874\trec:   62.025257\tkl:   26.703615\n",
            "Epoch: 411 [10100/50000 (20%)]  \tLoss:   89.116982\trec:   61.881527\tkl:   27.235456\n",
            "Epoch: 411 [20100/50000 (40%)]  \tLoss:   87.547440\trec:   60.351807\tkl:   27.195631\n",
            "Epoch: 411 [30100/50000 (60%)]  \tLoss:   88.637459\trec:   61.609890\tkl:   27.027573\n",
            "Epoch: 411 [40100/50000 (80%)]  \tLoss:   90.991119\trec:   64.093224\tkl:   26.897896\n",
            "====> Epoch: 411 Average train loss: 90.6771\n",
            "====> Validation set loss: 92.9853\n",
            "====> Validation set kl: 27.0895\n",
            "Epoch: 412 [  100/50000 ( 0%)]  \tLoss:   92.332436\trec:   64.606857\tkl:   27.725582\n",
            "Epoch: 412 [10100/50000 (20%)]  \tLoss:   91.151596\trec:   63.525017\tkl:   27.626583\n",
            "Epoch: 412 [20100/50000 (40%)]  \tLoss:   90.218025\trec:   62.666073\tkl:   27.551950\n",
            "Epoch: 412 [30100/50000 (60%)]  \tLoss:   92.928581\trec:   64.316246\tkl:   28.612335\n",
            "Epoch: 412 [40100/50000 (80%)]  \tLoss:   87.047379\trec:   60.213730\tkl:   26.833649\n",
            "====> Epoch: 412 Average train loss: 90.6647\n",
            "====> Validation set loss: 93.1697\n",
            "====> Validation set kl: 27.1854\n",
            "Epoch: 413 [  100/50000 ( 0%)]  \tLoss:   91.505165\trec:   63.396309\tkl:   28.108856\n",
            "Epoch: 413 [10100/50000 (20%)]  \tLoss:   92.140450\trec:   64.698402\tkl:   27.442045\n",
            "Epoch: 413 [20100/50000 (40%)]  \tLoss:   92.055244\trec:   64.028206\tkl:   28.027033\n",
            "Epoch: 413 [30100/50000 (60%)]  \tLoss:   89.595711\trec:   62.387508\tkl:   27.208200\n",
            "Epoch: 413 [40100/50000 (80%)]  \tLoss:   89.108330\trec:   62.264011\tkl:   26.844318\n",
            "====> Epoch: 413 Average train loss: 90.6671\n",
            "====> Validation set loss: 93.1508\n",
            "====> Validation set kl: 27.2364\n",
            "Epoch: 414 [  100/50000 ( 0%)]  \tLoss:   86.920425\trec:   60.155998\tkl:   26.764423\n",
            "Epoch: 414 [10100/50000 (20%)]  \tLoss:   90.817589\trec:   63.886845\tkl:   26.930742\n",
            "Epoch: 414 [20100/50000 (40%)]  \tLoss:   90.714546\trec:   63.584209\tkl:   27.130346\n",
            "Epoch: 414 [30100/50000 (60%)]  \tLoss:   92.111580\trec:   65.529831\tkl:   26.581743\n",
            "Epoch: 414 [40100/50000 (80%)]  \tLoss:   90.926796\trec:   63.080261\tkl:   27.846537\n",
            "====> Epoch: 414 Average train loss: 90.6482\n",
            "====> Validation set loss: 93.0372\n",
            "====> Validation set kl: 27.2704\n",
            "Epoch: 415 [  100/50000 ( 0%)]  \tLoss:   92.873817\trec:   64.560631\tkl:   28.313181\n",
            "Epoch: 415 [10100/50000 (20%)]  \tLoss:   86.205505\trec:   60.380596\tkl:   25.824913\n",
            "Epoch: 415 [20100/50000 (40%)]  \tLoss:   91.454865\trec:   64.250420\tkl:   27.204441\n",
            "Epoch: 415 [30100/50000 (60%)]  \tLoss:   88.772583\trec:   61.722645\tkl:   27.049940\n",
            "Epoch: 415 [40100/50000 (80%)]  \tLoss:   89.222069\trec:   62.513447\tkl:   26.708628\n",
            "====> Epoch: 415 Average train loss: 90.6401\n",
            "====> Validation set loss: 93.2387\n",
            "====> Validation set kl: 27.2957\n",
            "Epoch: 416 [  100/50000 ( 0%)]  \tLoss:   90.602066\trec:   63.363285\tkl:   27.238787\n",
            "Epoch: 416 [10100/50000 (20%)]  \tLoss:   93.557632\trec:   64.801979\tkl:   28.755653\n",
            "Epoch: 416 [20100/50000 (40%)]  \tLoss:   89.114014\trec:   62.520847\tkl:   26.593161\n",
            "Epoch: 416 [30100/50000 (60%)]  \tLoss:   93.494301\trec:   65.023918\tkl:   28.470390\n",
            "Epoch: 416 [40100/50000 (80%)]  \tLoss:   89.169800\trec:   62.457146\tkl:   26.712656\n",
            "====> Epoch: 416 Average train loss: 90.6378\n",
            "====> Validation set loss: 93.1372\n",
            "====> Validation set kl: 27.2152\n",
            "Epoch: 417 [  100/50000 ( 0%)]  \tLoss:   92.650307\trec:   63.696972\tkl:   28.953339\n",
            "Epoch: 417 [10100/50000 (20%)]  \tLoss:   91.787514\trec:   65.140289\tkl:   26.647221\n",
            "Epoch: 417 [20100/50000 (40%)]  \tLoss:   90.397362\trec:   63.609280\tkl:   26.788076\n",
            "Epoch: 417 [30100/50000 (60%)]  \tLoss:   89.089600\trec:   61.709442\tkl:   27.380157\n",
            "Epoch: 417 [40100/50000 (80%)]  \tLoss:   91.455582\trec:   63.203796\tkl:   28.251789\n",
            "====> Epoch: 417 Average train loss: 90.6491\n",
            "====> Validation set loss: 93.0679\n",
            "====> Validation set kl: 27.4677\n",
            "Epoch: 418 [  100/50000 ( 0%)]  \tLoss:   90.207397\trec:   62.507919\tkl:   27.699476\n",
            "Epoch: 418 [10100/50000 (20%)]  \tLoss:   92.281456\trec:   64.776627\tkl:   27.504824\n",
            "Epoch: 418 [20100/50000 (40%)]  \tLoss:   92.457695\trec:   64.207703\tkl:   28.249992\n",
            "Epoch: 418 [30100/50000 (60%)]  \tLoss:   91.182945\trec:   64.258125\tkl:   26.924818\n",
            "Epoch: 418 [40100/50000 (80%)]  \tLoss:   94.320351\trec:   65.810089\tkl:   28.510265\n",
            "====> Epoch: 418 Average train loss: 90.6093\n",
            "====> Validation set loss: 93.0390\n",
            "====> Validation set kl: 27.3049\n",
            "Epoch: 419 [  100/50000 ( 0%)]  \tLoss:   88.301758\trec:   61.639782\tkl:   26.661972\n",
            "Epoch: 419 [10100/50000 (20%)]  \tLoss:   88.008553\trec:   61.079285\tkl:   26.929270\n",
            "Epoch: 419 [20100/50000 (40%)]  \tLoss:   87.976112\trec:   61.403587\tkl:   26.572523\n",
            "Epoch: 419 [30100/50000 (60%)]  \tLoss:   89.185448\trec:   62.275688\tkl:   26.909760\n",
            "Epoch: 419 [40100/50000 (80%)]  \tLoss:   89.459236\trec:   63.030613\tkl:   26.428623\n",
            "====> Epoch: 419 Average train loss: 90.6120\n",
            "====> Validation set loss: 93.1770\n",
            "====> Validation set kl: 27.3425\n",
            "Epoch: 420 [  100/50000 ( 0%)]  \tLoss:   88.790985\trec:   61.023369\tkl:   27.767616\n",
            "Epoch: 420 [10100/50000 (20%)]  \tLoss:   91.524002\trec:   63.999519\tkl:   27.524483\n",
            "Epoch: 420 [20100/50000 (40%)]  \tLoss:   86.709297\trec:   59.659283\tkl:   27.050014\n",
            "Epoch: 420 [30100/50000 (60%)]  \tLoss:   95.637726\trec:   67.713043\tkl:   27.924677\n",
            "Epoch: 420 [40100/50000 (80%)]  \tLoss:   87.655113\trec:   60.818806\tkl:   26.836313\n",
            "====> Epoch: 420 Average train loss: 90.6021\n",
            "====> Validation set loss: 92.9618\n",
            "====> Validation set kl: 27.1374\n",
            "Epoch: 421 [  100/50000 ( 0%)]  \tLoss:   90.913582\trec:   63.665134\tkl:   27.248444\n",
            "Epoch: 421 [10100/50000 (20%)]  \tLoss:   89.627480\trec:   63.725174\tkl:   25.902304\n",
            "Epoch: 421 [20100/50000 (40%)]  \tLoss:   90.490547\trec:   63.343876\tkl:   27.146669\n",
            "Epoch: 421 [30100/50000 (60%)]  \tLoss:   91.421402\trec:   64.136345\tkl:   27.285063\n",
            "Epoch: 421 [40100/50000 (80%)]  \tLoss:   91.503632\trec:   63.426208\tkl:   28.077423\n",
            "====> Epoch: 421 Average train loss: 90.6032\n",
            "====> Validation set loss: 93.0235\n",
            "====> Validation set kl: 27.3219\n",
            "Epoch: 422 [  100/50000 ( 0%)]  \tLoss:   90.963608\trec:   62.976814\tkl:   27.986799\n",
            "Epoch: 422 [10100/50000 (20%)]  \tLoss:   88.336227\trec:   61.521587\tkl:   26.814638\n",
            "Epoch: 422 [20100/50000 (40%)]  \tLoss:   85.933525\trec:   59.507236\tkl:   26.426291\n",
            "Epoch: 422 [30100/50000 (60%)]  \tLoss:   93.856415\trec:   66.405518\tkl:   27.450901\n",
            "Epoch: 422 [40100/50000 (80%)]  \tLoss:   89.736519\trec:   63.289867\tkl:   26.446650\n",
            "====> Epoch: 422 Average train loss: 90.5997\n",
            "====> Validation set loss: 93.0934\n",
            "====> Validation set kl: 27.2218\n",
            "Epoch: 423 [  100/50000 ( 0%)]  \tLoss:   89.059395\trec:   63.039299\tkl:   26.020092\n",
            "Epoch: 423 [10100/50000 (20%)]  \tLoss:   89.951599\trec:   62.342419\tkl:   27.609175\n",
            "Epoch: 423 [20100/50000 (40%)]  \tLoss:   91.250206\trec:   63.605980\tkl:   27.644222\n",
            "Epoch: 423 [30100/50000 (60%)]  \tLoss:   89.801353\trec:   63.100555\tkl:   26.700798\n",
            "Epoch: 423 [40100/50000 (80%)]  \tLoss:   93.328300\trec:   66.030090\tkl:   27.298203\n",
            "====> Epoch: 423 Average train loss: 90.6043\n",
            "====> Validation set loss: 93.1249\n",
            "====> Validation set kl: 27.4913\n",
            "Epoch: 424 [  100/50000 ( 0%)]  \tLoss:   91.557663\trec:   63.544769\tkl:   28.012892\n",
            "Epoch: 424 [10100/50000 (20%)]  \tLoss:   88.490417\trec:   62.456982\tkl:   26.033434\n",
            "Epoch: 424 [20100/50000 (40%)]  \tLoss:   90.947365\trec:   62.985668\tkl:   27.961699\n",
            "Epoch: 424 [30100/50000 (60%)]  \tLoss:   95.630470\trec:   66.716652\tkl:   28.913818\n",
            "Epoch: 424 [40100/50000 (80%)]  \tLoss:   94.748634\trec:   66.184319\tkl:   28.564314\n",
            "====> Epoch: 424 Average train loss: 90.6035\n",
            "====> Validation set loss: 93.1278\n",
            "====> Validation set kl: 27.2383\n",
            "Epoch: 425 [  100/50000 ( 0%)]  \tLoss:   93.839508\trec:   65.383484\tkl:   28.456024\n",
            "Epoch: 425 [10100/50000 (20%)]  \tLoss:   89.105751\trec:   61.290916\tkl:   27.814833\n",
            "Epoch: 425 [20100/50000 (40%)]  \tLoss:   88.845230\trec:   61.454205\tkl:   27.391029\n",
            "Epoch: 425 [30100/50000 (60%)]  \tLoss:   91.224838\trec:   63.552380\tkl:   27.672455\n",
            "Epoch: 425 [40100/50000 (80%)]  \tLoss:   91.560036\trec:   64.247726\tkl:   27.312307\n",
            "====> Epoch: 425 Average train loss: 90.5740\n",
            "====> Validation set loss: 93.0068\n",
            "====> Validation set kl: 27.2645\n",
            "Epoch: 426 [  100/50000 ( 0%)]  \tLoss:   92.860916\trec:   65.231018\tkl:   27.629900\n",
            "Epoch: 426 [10100/50000 (20%)]  \tLoss:   88.679787\trec:   61.564636\tkl:   27.115150\n",
            "Epoch: 426 [20100/50000 (40%)]  \tLoss:   87.814949\trec:   61.570580\tkl:   26.244368\n",
            "Epoch: 426 [30100/50000 (60%)]  \tLoss:   88.955605\trec:   62.520977\tkl:   26.434628\n",
            "Epoch: 426 [40100/50000 (80%)]  \tLoss:   94.770485\trec:   66.218918\tkl:   28.551567\n",
            "====> Epoch: 426 Average train loss: 90.5807\n",
            "====> Validation set loss: 92.9680\n",
            "====> Validation set kl: 27.4097\n",
            "Epoch: 427 [  100/50000 ( 0%)]  \tLoss:   95.272713\trec:   66.313667\tkl:   28.959047\n",
            "Epoch: 427 [10100/50000 (20%)]  \tLoss:   92.097481\trec:   63.995651\tkl:   28.101820\n",
            "Epoch: 427 [20100/50000 (40%)]  \tLoss:   91.262947\trec:   63.916283\tkl:   27.346663\n",
            "Epoch: 427 [30100/50000 (60%)]  \tLoss:   89.976616\trec:   62.623779\tkl:   27.352840\n",
            "Epoch: 427 [40100/50000 (80%)]  \tLoss:   92.856316\trec:   66.240547\tkl:   26.615768\n",
            "====> Epoch: 427 Average train loss: 90.5552\n",
            "====> Validation set loss: 93.0737\n",
            "====> Validation set kl: 27.3001\n",
            "Epoch: 428 [  100/50000 ( 0%)]  \tLoss:   90.584167\trec:   62.893738\tkl:   27.690426\n",
            "Epoch: 428 [10100/50000 (20%)]  \tLoss:   87.074997\trec:   60.868225\tkl:   26.206766\n",
            "Epoch: 428 [20100/50000 (40%)]  \tLoss:   91.145836\trec:   62.638073\tkl:   28.507765\n",
            "Epoch: 428 [30100/50000 (60%)]  \tLoss:   92.049957\trec:   64.540871\tkl:   27.509090\n",
            "Epoch: 428 [40100/50000 (80%)]  \tLoss:   89.836647\trec:   62.820488\tkl:   27.016165\n",
            "====> Epoch: 428 Average train loss: 90.5580\n",
            "====> Validation set loss: 93.1229\n",
            "====> Validation set kl: 27.3889\n",
            "Epoch: 429 [  100/50000 ( 0%)]  \tLoss:   90.197205\trec:   63.368191\tkl:   26.829016\n",
            "Epoch: 429 [10100/50000 (20%)]  \tLoss:   88.086563\trec:   61.048225\tkl:   27.038338\n",
            "Epoch: 429 [20100/50000 (40%)]  \tLoss:   88.497871\trec:   62.036835\tkl:   26.461035\n",
            "Epoch: 429 [30100/50000 (60%)]  \tLoss:   83.344246\trec:   57.566170\tkl:   25.778076\n",
            "Epoch: 429 [40100/50000 (80%)]  \tLoss:   89.780220\trec:   62.842731\tkl:   26.937492\n",
            "====> Epoch: 429 Average train loss: 90.5497\n",
            "====> Validation set loss: 93.0407\n",
            "====> Validation set kl: 27.2548\n",
            "Epoch: 430 [  100/50000 ( 0%)]  \tLoss:   88.284744\trec:   61.125988\tkl:   27.158760\n",
            "Epoch: 430 [10100/50000 (20%)]  \tLoss:   91.061844\trec:   64.205910\tkl:   26.855930\n",
            "Epoch: 430 [20100/50000 (40%)]  \tLoss:   89.906746\trec:   63.163994\tkl:   26.742754\n",
            "Epoch: 430 [30100/50000 (60%)]  \tLoss:   92.035095\trec:   64.685226\tkl:   27.349871\n",
            "Epoch: 430 [40100/50000 (80%)]  \tLoss:   93.322403\trec:   65.046593\tkl:   28.275805\n",
            "====> Epoch: 430 Average train loss: 90.5337\n",
            "====> Validation set loss: 93.0676\n",
            "====> Validation set kl: 27.3013\n",
            "Epoch: 431 [  100/50000 ( 0%)]  \tLoss:   91.853554\trec:   64.490356\tkl:   27.363197\n",
            "Epoch: 431 [10100/50000 (20%)]  \tLoss:   90.467186\trec:   63.766094\tkl:   26.701090\n",
            "Epoch: 431 [20100/50000 (40%)]  \tLoss:   86.999313\trec:   60.012661\tkl:   26.986652\n",
            "Epoch: 431 [30100/50000 (60%)]  \tLoss:   88.929008\trec:   62.274685\tkl:   26.654325\n",
            "Epoch: 431 [40100/50000 (80%)]  \tLoss:   87.082672\trec:   60.746487\tkl:   26.336189\n",
            "====> Epoch: 431 Average train loss: 90.5216\n",
            "====> Validation set loss: 92.9937\n",
            "====> Validation set kl: 27.2416\n",
            "Epoch: 432 [  100/50000 ( 0%)]  \tLoss:   85.915878\trec:   59.787903\tkl:   26.127977\n",
            "Epoch: 432 [10100/50000 (20%)]  \tLoss:   88.229218\trec:   61.492245\tkl:   26.736967\n",
            "Epoch: 432 [20100/50000 (40%)]  \tLoss:   93.380898\trec:   66.180481\tkl:   27.200417\n",
            "Epoch: 432 [30100/50000 (60%)]  \tLoss:   87.018257\trec:   60.745251\tkl:   26.273006\n",
            "Epoch: 432 [40100/50000 (80%)]  \tLoss:   93.603592\trec:   66.659500\tkl:   26.944094\n",
            "====> Epoch: 432 Average train loss: 90.5369\n",
            "====> Validation set loss: 93.0550\n",
            "====> Validation set kl: 27.4059\n",
            "Epoch: 433 [  100/50000 ( 0%)]  \tLoss:   91.291992\trec:   64.368645\tkl:   26.923347\n",
            "Epoch: 433 [10100/50000 (20%)]  \tLoss:   94.742348\trec:   66.657387\tkl:   28.084969\n",
            "Epoch: 433 [20100/50000 (40%)]  \tLoss:   91.266129\trec:   63.809429\tkl:   27.456709\n",
            "Epoch: 433 [30100/50000 (60%)]  \tLoss:   88.226562\trec:   61.061306\tkl:   27.165249\n",
            "Epoch: 433 [40100/50000 (80%)]  \tLoss:   88.290596\trec:   61.751934\tkl:   26.538662\n",
            "====> Epoch: 433 Average train loss: 90.5135\n",
            "====> Validation set loss: 93.0341\n",
            "====> Validation set kl: 27.3301\n",
            "Epoch: 434 [  100/50000 ( 0%)]  \tLoss:   91.768105\trec:   64.168571\tkl:   27.599533\n",
            "Epoch: 434 [10100/50000 (20%)]  \tLoss:   88.197792\trec:   61.693211\tkl:   26.504585\n",
            "Epoch: 434 [20100/50000 (40%)]  \tLoss:   94.579018\trec:   66.543083\tkl:   28.035934\n",
            "Epoch: 434 [30100/50000 (60%)]  \tLoss:   87.883804\trec:   60.644802\tkl:   27.239006\n",
            "Epoch: 434 [40100/50000 (80%)]  \tLoss:   95.258247\trec:   66.357208\tkl:   28.901045\n",
            "====> Epoch: 434 Average train loss: 90.5194\n",
            "====> Validation set loss: 93.0387\n",
            "====> Validation set kl: 27.2134\n",
            "Epoch: 435 [  100/50000 ( 0%)]  \tLoss:   93.122604\trec:   64.800323\tkl:   28.322283\n",
            "Epoch: 435 [10100/50000 (20%)]  \tLoss:   88.321747\trec:   62.440544\tkl:   25.881199\n",
            "Epoch: 435 [20100/50000 (40%)]  \tLoss:   90.512535\trec:   63.301338\tkl:   27.211195\n",
            "Epoch: 435 [30100/50000 (60%)]  \tLoss:   91.282234\trec:   64.212761\tkl:   27.069469\n",
            "Epoch: 435 [40100/50000 (80%)]  \tLoss:   88.087830\trec:   61.818123\tkl:   26.269707\n",
            "====> Epoch: 435 Average train loss: 90.5117\n",
            "====> Validation set loss: 92.9375\n",
            "====> Validation set kl: 27.1401\n",
            "Epoch: 436 [  100/50000 ( 0%)]  \tLoss:   87.444420\trec:   60.455917\tkl:   26.988503\n",
            "Epoch: 436 [10100/50000 (20%)]  \tLoss:   91.661499\trec:   63.919422\tkl:   27.742075\n",
            "Epoch: 436 [20100/50000 (40%)]  \tLoss:   95.009819\trec:   66.362823\tkl:   28.646996\n",
            "Epoch: 436 [30100/50000 (60%)]  \tLoss:   90.706543\trec:   62.946865\tkl:   27.759672\n",
            "Epoch: 436 [40100/50000 (80%)]  \tLoss:   90.833473\trec:   62.743698\tkl:   28.089777\n",
            "====> Epoch: 436 Average train loss: 90.5130\n",
            "====> Validation set loss: 92.8893\n",
            "====> Validation set kl: 27.0961\n",
            "Epoch: 437 [  100/50000 ( 0%)]  \tLoss:   85.156479\trec:   59.175282\tkl:   25.981205\n",
            "Epoch: 437 [10100/50000 (20%)]  \tLoss:   93.049004\trec:   64.971664\tkl:   28.077341\n",
            "Epoch: 437 [20100/50000 (40%)]  \tLoss:   93.371758\trec:   65.180565\tkl:   28.191196\n",
            "Epoch: 437 [30100/50000 (60%)]  \tLoss:   91.159081\trec:   63.387985\tkl:   27.771088\n",
            "Epoch: 437 [40100/50000 (80%)]  \tLoss:   84.254051\trec:   57.463467\tkl:   26.790585\n",
            "====> Epoch: 437 Average train loss: 90.5056\n",
            "====> Validation set loss: 93.0210\n",
            "====> Validation set kl: 27.2127\n",
            "Epoch: 438 [  100/50000 ( 0%)]  \tLoss:   89.908234\trec:   62.835625\tkl:   27.072609\n",
            "Epoch: 438 [10100/50000 (20%)]  \tLoss:   90.488327\trec:   62.913807\tkl:   27.574518\n",
            "Epoch: 438 [20100/50000 (40%)]  \tLoss:   90.119278\trec:   62.363655\tkl:   27.755615\n",
            "Epoch: 438 [30100/50000 (60%)]  \tLoss:   89.762856\trec:   63.263348\tkl:   26.499514\n",
            "Epoch: 438 [40100/50000 (80%)]  \tLoss:   87.358101\trec:   60.878456\tkl:   26.479652\n",
            "====> Epoch: 438 Average train loss: 90.5099\n",
            "====> Validation set loss: 92.9623\n",
            "====> Validation set kl: 27.2208\n",
            "Epoch: 439 [  100/50000 ( 0%)]  \tLoss:   89.374237\trec:   62.384289\tkl:   26.989941\n",
            "Epoch: 439 [10100/50000 (20%)]  \tLoss:   90.344292\trec:   62.532787\tkl:   27.811502\n",
            "Epoch: 439 [20100/50000 (40%)]  \tLoss:   93.414383\trec:   65.532692\tkl:   27.881693\n",
            "Epoch: 439 [30100/50000 (60%)]  \tLoss:   90.614029\trec:   62.981621\tkl:   27.632412\n",
            "Epoch: 439 [40100/50000 (80%)]  \tLoss:   90.320885\trec:   62.635086\tkl:   27.685799\n",
            "====> Epoch: 439 Average train loss: 90.4859\n",
            "====> Validation set loss: 92.9922\n",
            "====> Validation set kl: 27.2516\n",
            "Epoch: 440 [  100/50000 ( 0%)]  \tLoss:   92.010857\trec:   64.356682\tkl:   27.654175\n",
            "Epoch: 440 [10100/50000 (20%)]  \tLoss:   93.614662\trec:   65.951607\tkl:   27.663061\n",
            "Epoch: 440 [20100/50000 (40%)]  \tLoss:   89.619400\trec:   62.435722\tkl:   27.183681\n",
            "Epoch: 440 [30100/50000 (60%)]  \tLoss:   91.287514\trec:   64.588493\tkl:   26.699022\n",
            "Epoch: 440 [40100/50000 (80%)]  \tLoss:   90.621246\trec:   62.598301\tkl:   28.022949\n",
            "====> Epoch: 440 Average train loss: 90.4790\n",
            "====> Validation set loss: 92.9863\n",
            "====> Validation set kl: 27.2570\n",
            "Epoch: 441 [  100/50000 ( 0%)]  \tLoss:   90.456093\trec:   63.022900\tkl:   27.433197\n",
            "Epoch: 441 [10100/50000 (20%)]  \tLoss:   88.082619\trec:   61.064541\tkl:   27.018076\n",
            "Epoch: 441 [20100/50000 (40%)]  \tLoss:   94.143066\trec:   66.004829\tkl:   28.138237\n",
            "Epoch: 441 [30100/50000 (60%)]  \tLoss:   86.631882\trec:   59.602528\tkl:   27.029352\n",
            "Epoch: 441 [40100/50000 (80%)]  \tLoss:   90.861328\trec:   63.243237\tkl:   27.618093\n",
            "====> Epoch: 441 Average train loss: 90.4808\n",
            "====> Validation set loss: 93.0332\n",
            "====> Validation set kl: 27.2716\n",
            "Epoch: 442 [  100/50000 ( 0%)]  \tLoss:   90.559509\trec:   63.107323\tkl:   27.452183\n",
            "Epoch: 442 [10100/50000 (20%)]  \tLoss:   94.273712\trec:   66.282982\tkl:   27.990726\n",
            "Epoch: 442 [20100/50000 (40%)]  \tLoss:   91.157593\trec:   64.010674\tkl:   27.146921\n",
            "Epoch: 442 [30100/50000 (60%)]  \tLoss:   91.229301\trec:   63.730564\tkl:   27.498739\n",
            "Epoch: 442 [40100/50000 (80%)]  \tLoss:   92.318550\trec:   64.236618\tkl:   28.081930\n",
            "====> Epoch: 442 Average train loss: 90.4661\n",
            "====> Validation set loss: 93.0594\n",
            "====> Validation set kl: 27.0977\n",
            "Epoch: 443 [  100/50000 ( 0%)]  \tLoss:   89.711578\trec:   61.587856\tkl:   28.123730\n",
            "Epoch: 443 [10100/50000 (20%)]  \tLoss:   88.789062\trec:   61.931118\tkl:   26.857941\n",
            "Epoch: 443 [20100/50000 (40%)]  \tLoss:   93.471901\trec:   65.983330\tkl:   27.488571\n",
            "Epoch: 443 [30100/50000 (60%)]  \tLoss:   90.514076\trec:   62.588348\tkl:   27.925737\n",
            "Epoch: 443 [40100/50000 (80%)]  \tLoss:   89.126503\trec:   62.812534\tkl:   26.313974\n",
            "====> Epoch: 443 Average train loss: 90.4914\n",
            "====> Validation set loss: 92.9944\n",
            "====> Validation set kl: 27.3908\n",
            "Epoch: 444 [  100/50000 ( 0%)]  \tLoss:   90.438484\trec:   62.793713\tkl:   27.644770\n",
            "Epoch: 444 [10100/50000 (20%)]  \tLoss:   91.604736\trec:   64.364189\tkl:   27.240549\n",
            "Epoch: 444 [20100/50000 (40%)]  \tLoss:   90.778419\trec:   62.340282\tkl:   28.438131\n",
            "Epoch: 444 [30100/50000 (60%)]  \tLoss:   90.296059\trec:   63.128307\tkl:   27.167753\n",
            "Epoch: 444 [40100/50000 (80%)]  \tLoss:   90.392197\trec:   62.807644\tkl:   27.584547\n",
            "====> Epoch: 444 Average train loss: 90.4613\n",
            "====> Validation set loss: 92.9145\n",
            "====> Validation set kl: 27.1827\n",
            "Epoch: 445 [  100/50000 ( 0%)]  \tLoss:   88.570274\trec:   61.968586\tkl:   26.601686\n",
            "Epoch: 445 [10100/50000 (20%)]  \tLoss:   93.960358\trec:   66.122490\tkl:   27.837870\n",
            "Epoch: 445 [20100/50000 (40%)]  \tLoss:   90.799324\trec:   62.803547\tkl:   27.995775\n",
            "Epoch: 445 [30100/50000 (60%)]  \tLoss:   92.061768\trec:   65.176537\tkl:   26.885229\n",
            "Epoch: 445 [40100/50000 (80%)]  \tLoss:   88.563866\trec:   61.461872\tkl:   27.101997\n",
            "====> Epoch: 445 Average train loss: 90.4664\n",
            "====> Validation set loss: 93.0186\n",
            "====> Validation set kl: 27.4085\n",
            "Epoch: 446 [  100/50000 ( 0%)]  \tLoss:   89.723846\trec:   62.815228\tkl:   26.908615\n",
            "Epoch: 446 [10100/50000 (20%)]  \tLoss:   87.559052\trec:   60.822651\tkl:   26.736399\n",
            "Epoch: 446 [20100/50000 (40%)]  \tLoss:   92.487183\trec:   64.892937\tkl:   27.594257\n",
            "Epoch: 446 [30100/50000 (60%)]  \tLoss:   94.514259\trec:   66.331230\tkl:   28.183022\n",
            "Epoch: 446 [40100/50000 (80%)]  \tLoss:   93.712784\trec:   65.442802\tkl:   28.269978\n",
            "====> Epoch: 446 Average train loss: 90.4473\n",
            "====> Validation set loss: 92.9484\n",
            "====> Validation set kl: 27.3728\n",
            "Epoch: 447 [  100/50000 ( 0%)]  \tLoss:   88.188263\trec:   60.826950\tkl:   27.361313\n",
            "Epoch: 447 [10100/50000 (20%)]  \tLoss:   91.625954\trec:   64.451660\tkl:   27.174294\n",
            "Epoch: 447 [20100/50000 (40%)]  \tLoss:   91.611084\trec:   64.517387\tkl:   27.093697\n",
            "Epoch: 447 [30100/50000 (60%)]  \tLoss:   93.641586\trec:   65.894951\tkl:   27.746643\n",
            "Epoch: 447 [40100/50000 (80%)]  \tLoss:   89.443634\trec:   61.629124\tkl:   27.814505\n",
            "====> Epoch: 447 Average train loss: 90.4540\n",
            "====> Validation set loss: 92.8939\n",
            "====> Validation set kl: 27.2917\n",
            "Epoch: 448 [  100/50000 ( 0%)]  \tLoss:   89.693520\trec:   62.300976\tkl:   27.392548\n",
            "Epoch: 448 [10100/50000 (20%)]  \tLoss:   93.030624\trec:   65.937149\tkl:   27.093473\n",
            "Epoch: 448 [20100/50000 (40%)]  \tLoss:   89.370300\trec:   61.885071\tkl:   27.485231\n",
            "Epoch: 448 [30100/50000 (60%)]  \tLoss:   88.667969\trec:   61.696362\tkl:   26.971605\n",
            "Epoch: 448 [40100/50000 (80%)]  \tLoss:   91.156570\trec:   63.746960\tkl:   27.409607\n",
            "====> Epoch: 448 Average train loss: 90.4369\n",
            "====> Validation set loss: 92.9793\n",
            "====> Validation set kl: 27.2362\n",
            "Epoch: 449 [  100/50000 ( 0%)]  \tLoss:   91.702057\trec:   64.312263\tkl:   27.389791\n",
            "Epoch: 449 [10100/50000 (20%)]  \tLoss:   91.587616\trec:   64.274979\tkl:   27.312641\n",
            "Epoch: 449 [20100/50000 (40%)]  \tLoss:   89.843338\trec:   61.756481\tkl:   28.086849\n",
            "Epoch: 449 [30100/50000 (60%)]  \tLoss:   89.992325\trec:   62.831528\tkl:   27.160793\n",
            "Epoch: 449 [40100/50000 (80%)]  \tLoss:   87.958145\trec:   61.679234\tkl:   26.278906\n",
            "====> Epoch: 449 Average train loss: 90.4226\n",
            "====> Validation set loss: 92.9618\n",
            "====> Validation set kl: 27.2278\n",
            "Epoch: 450 [  100/50000 ( 0%)]  \tLoss:   87.131989\trec:   59.720165\tkl:   27.411821\n",
            "Epoch: 450 [10100/50000 (20%)]  \tLoss:   89.216202\trec:   62.556679\tkl:   26.659521\n",
            "Epoch: 450 [20100/50000 (40%)]  \tLoss:   93.589989\trec:   66.322731\tkl:   27.267260\n",
            "Epoch: 450 [30100/50000 (60%)]  \tLoss:   93.203041\trec:   65.910568\tkl:   27.292480\n",
            "Epoch: 450 [40100/50000 (80%)]  \tLoss:   89.379845\trec:   62.701092\tkl:   26.678751\n",
            "====> Epoch: 450 Average train loss: 90.4420\n",
            "====> Validation set loss: 93.0723\n",
            "====> Validation set kl: 27.2839\n",
            "Epoch: 451 [  100/50000 ( 0%)]  \tLoss:   91.592987\trec:   64.800919\tkl:   26.792067\n",
            "Epoch: 451 [10100/50000 (20%)]  \tLoss:   89.634346\trec:   61.636738\tkl:   27.997604\n",
            "Epoch: 451 [20100/50000 (40%)]  \tLoss:   93.056755\trec:   64.492088\tkl:   28.564665\n",
            "Epoch: 451 [30100/50000 (60%)]  \tLoss:   96.733673\trec:   67.045242\tkl:   29.688425\n",
            "Epoch: 451 [40100/50000 (80%)]  \tLoss:   88.237579\trec:   62.479130\tkl:   25.758446\n",
            "====> Epoch: 451 Average train loss: 90.4385\n",
            "====> Validation set loss: 92.9367\n",
            "====> Validation set kl: 27.3462\n",
            "Epoch: 452 [  100/50000 ( 0%)]  \tLoss:   84.586052\trec:   58.773724\tkl:   25.812334\n",
            "Epoch: 452 [10100/50000 (20%)]  \tLoss:   93.395973\trec:   64.607018\tkl:   28.788950\n",
            "Epoch: 452 [20100/50000 (40%)]  \tLoss:   88.207443\trec:   61.536846\tkl:   26.670597\n",
            "Epoch: 452 [30100/50000 (60%)]  \tLoss:   89.649460\trec:   62.558056\tkl:   27.091406\n",
            "Epoch: 452 [40100/50000 (80%)]  \tLoss:   90.995567\trec:   62.763626\tkl:   28.231937\n",
            "====> Epoch: 452 Average train loss: 90.4451\n",
            "====> Validation set loss: 93.0389\n",
            "====> Validation set kl: 27.5621\n",
            "Epoch: 453 [  100/50000 ( 0%)]  \tLoss:   86.921860\trec:   59.938999\tkl:   26.982868\n",
            "Epoch: 453 [10100/50000 (20%)]  \tLoss:   89.104408\trec:   62.421532\tkl:   26.682884\n",
            "Epoch: 453 [20100/50000 (40%)]  \tLoss:   94.573868\trec:   65.923264\tkl:   28.650610\n",
            "Epoch: 453 [30100/50000 (60%)]  \tLoss:   91.885307\trec:   63.502312\tkl:   28.382998\n",
            "Epoch: 453 [40100/50000 (80%)]  \tLoss:   87.919449\trec:   60.861252\tkl:   27.058193\n",
            "====> Epoch: 453 Average train loss: 90.4102\n",
            "====> Validation set loss: 92.8962\n",
            "====> Validation set kl: 27.4297\n",
            "Epoch: 454 [  100/50000 ( 0%)]  \tLoss:   89.992531\trec:   62.414745\tkl:   27.577785\n",
            "Epoch: 454 [10100/50000 (20%)]  \tLoss:   91.639549\trec:   64.001717\tkl:   27.637835\n",
            "Epoch: 454 [20100/50000 (40%)]  \tLoss:   88.766502\trec:   61.702385\tkl:   27.064110\n",
            "Epoch: 454 [30100/50000 (60%)]  \tLoss:   88.334625\trec:   61.038143\tkl:   27.296482\n",
            "Epoch: 454 [40100/50000 (80%)]  \tLoss:   88.163208\trec:   61.473953\tkl:   26.689255\n",
            "====> Epoch: 454 Average train loss: 90.4098\n",
            "====> Validation set loss: 92.9577\n",
            "====> Validation set kl: 27.4020\n",
            "Epoch: 455 [  100/50000 ( 0%)]  \tLoss:   92.349419\trec:   64.504593\tkl:   27.844831\n",
            "Epoch: 455 [10100/50000 (20%)]  \tLoss:   89.076637\trec:   61.837929\tkl:   27.238712\n",
            "Epoch: 455 [20100/50000 (40%)]  \tLoss:   89.137871\trec:   61.723026\tkl:   27.414848\n",
            "Epoch: 455 [30100/50000 (60%)]  \tLoss:   90.136055\trec:   62.494473\tkl:   27.641586\n",
            "Epoch: 455 [40100/50000 (80%)]  \tLoss:   90.973473\trec:   63.770512\tkl:   27.202965\n",
            "====> Epoch: 455 Average train loss: 90.4006\n",
            "====> Validation set loss: 92.9802\n",
            "====> Validation set kl: 27.1823\n",
            "Epoch: 456 [  100/50000 ( 0%)]  \tLoss:   88.789108\trec:   61.430115\tkl:   27.358992\n",
            "Epoch: 456 [10100/50000 (20%)]  \tLoss:   92.336441\trec:   65.114746\tkl:   27.221699\n",
            "Epoch: 456 [20100/50000 (40%)]  \tLoss:   92.968910\trec:   64.397888\tkl:   28.571028\n",
            "Epoch: 456 [30100/50000 (60%)]  \tLoss:   92.110817\trec:   64.474045\tkl:   27.636780\n",
            "Epoch: 456 [40100/50000 (80%)]  \tLoss:   87.135353\trec:   60.097092\tkl:   27.038260\n",
            "====> Epoch: 456 Average train loss: 90.3893\n",
            "====> Validation set loss: 93.0135\n",
            "====> Validation set kl: 27.1455\n",
            "Epoch: 457 [  100/50000 ( 0%)]  \tLoss:   91.219597\trec:   64.219231\tkl:   27.000368\n",
            "Epoch: 457 [10100/50000 (20%)]  \tLoss:   91.052734\trec:   63.383602\tkl:   27.669132\n",
            "Epoch: 457 [20100/50000 (40%)]  \tLoss:   92.766304\trec:   64.165009\tkl:   28.601297\n",
            "Epoch: 457 [30100/50000 (60%)]  \tLoss:   93.220993\trec:   65.788383\tkl:   27.432602\n",
            "Epoch: 457 [40100/50000 (80%)]  \tLoss:   86.309898\trec:   59.954857\tkl:   26.355038\n",
            "====> Epoch: 457 Average train loss: 90.3968\n",
            "====> Validation set loss: 92.8867\n",
            "====> Validation set kl: 27.2716\n",
            "Epoch: 458 [  100/50000 ( 0%)]  \tLoss:   88.463600\trec:   61.919079\tkl:   26.544518\n",
            "Epoch: 458 [10100/50000 (20%)]  \tLoss:   91.267769\trec:   63.605938\tkl:   27.661835\n",
            "Epoch: 458 [20100/50000 (40%)]  \tLoss:   93.997330\trec:   66.228554\tkl:   27.768782\n",
            "Epoch: 458 [30100/50000 (60%)]  \tLoss:   92.514587\trec:   63.672470\tkl:   28.842121\n",
            "Epoch: 458 [40100/50000 (80%)]  \tLoss:   91.603188\trec:   64.351471\tkl:   27.251719\n",
            "====> Epoch: 458 Average train loss: 90.3989\n",
            "====> Validation set loss: 92.8918\n",
            "====> Validation set kl: 27.3505\n",
            "Epoch: 459 [  100/50000 ( 0%)]  \tLoss:   93.788506\trec:   65.606102\tkl:   28.182404\n",
            "Epoch: 459 [10100/50000 (20%)]  \tLoss:   83.400826\trec:   57.797432\tkl:   25.603397\n",
            "Epoch: 459 [20100/50000 (40%)]  \tLoss:   92.159531\trec:   64.540466\tkl:   27.619064\n",
            "Epoch: 459 [30100/50000 (60%)]  \tLoss:   91.296425\trec:   62.935120\tkl:   28.361307\n",
            "Epoch: 459 [40100/50000 (80%)]  \tLoss:   85.619858\trec:   58.796589\tkl:   26.823273\n",
            "====> Epoch: 459 Average train loss: 90.3751\n",
            "====> Validation set loss: 93.0304\n",
            "====> Validation set kl: 27.5062\n",
            "Epoch: 460 [  100/50000 ( 0%)]  \tLoss:   88.666603\trec:   61.895134\tkl:   26.771463\n",
            "Epoch: 460 [10100/50000 (20%)]  \tLoss:   88.955437\trec:   61.322388\tkl:   27.633051\n",
            "Epoch: 460 [20100/50000 (40%)]  \tLoss:   87.932693\trec:   60.325584\tkl:   27.607111\n",
            "Epoch: 460 [30100/50000 (60%)]  \tLoss:   87.821228\trec:   61.620663\tkl:   26.200563\n",
            "Epoch: 460 [40100/50000 (80%)]  \tLoss:   92.852783\trec:   64.823189\tkl:   28.029589\n",
            "====> Epoch: 460 Average train loss: 90.3560\n",
            "====> Validation set loss: 92.9165\n",
            "====> Validation set kl: 27.1239\n",
            "Epoch: 461 [  100/50000 ( 0%)]  \tLoss:   94.857826\trec:   66.326569\tkl:   28.531261\n",
            "Epoch: 461 [10100/50000 (20%)]  \tLoss:   91.922592\trec:   63.801010\tkl:   28.121592\n",
            "Epoch: 461 [20100/50000 (40%)]  \tLoss:   91.573456\trec:   63.805653\tkl:   27.767807\n",
            "Epoch: 461 [30100/50000 (60%)]  \tLoss:   91.178223\trec:   62.740715\tkl:   28.437508\n",
            "Epoch: 461 [40100/50000 (80%)]  \tLoss:   87.739014\trec:   60.548763\tkl:   27.190247\n",
            "====> Epoch: 461 Average train loss: 90.3582\n",
            "====> Validation set loss: 92.9485\n",
            "====> Validation set kl: 27.2281\n",
            "Epoch: 462 [  100/50000 ( 0%)]  \tLoss:   87.144272\trec:   60.401970\tkl:   26.742300\n",
            "Epoch: 462 [10100/50000 (20%)]  \tLoss:   89.140465\trec:   62.115757\tkl:   27.024715\n",
            "Epoch: 462 [20100/50000 (40%)]  \tLoss:   90.834839\trec:   63.459461\tkl:   27.375378\n",
            "Epoch: 462 [30100/50000 (60%)]  \tLoss:   91.483086\trec:   63.540997\tkl:   27.942085\n",
            "Epoch: 462 [40100/50000 (80%)]  \tLoss:   90.990334\trec:   63.271118\tkl:   27.719212\n",
            "====> Epoch: 462 Average train loss: 90.3771\n",
            "====> Validation set loss: 92.9513\n",
            "====> Validation set kl: 27.2362\n",
            "Epoch: 463 [  100/50000 ( 0%)]  \tLoss:   90.362892\trec:   63.188702\tkl:   27.174194\n",
            "Epoch: 463 [10100/50000 (20%)]  \tLoss:   88.178223\trec:   61.041824\tkl:   27.136393\n",
            "Epoch: 463 [20100/50000 (40%)]  \tLoss:   91.928535\trec:   63.920986\tkl:   28.007553\n",
            "Epoch: 463 [30100/50000 (60%)]  \tLoss:   91.578438\trec:   63.747349\tkl:   27.831093\n",
            "Epoch: 463 [40100/50000 (80%)]  \tLoss:   91.219170\trec:   63.980633\tkl:   27.238535\n",
            "====> Epoch: 463 Average train loss: 90.3501\n",
            "====> Validation set loss: 92.8796\n",
            "====> Validation set kl: 27.5757\n",
            "Epoch: 464 [  100/50000 ( 0%)]  \tLoss:   90.942696\trec:   62.790466\tkl:   28.152224\n",
            "Epoch: 464 [10100/50000 (20%)]  \tLoss:   94.394447\trec:   66.481262\tkl:   27.913191\n",
            "Epoch: 464 [20100/50000 (40%)]  \tLoss:   89.578491\trec:   62.162365\tkl:   27.416130\n",
            "Epoch: 464 [30100/50000 (60%)]  \tLoss:   91.685913\trec:   64.338066\tkl:   27.347847\n",
            "Epoch: 464 [40100/50000 (80%)]  \tLoss:   94.949493\trec:   66.647934\tkl:   28.301552\n",
            "====> Epoch: 464 Average train loss: 90.3310\n",
            "====> Validation set loss: 92.9518\n",
            "====> Validation set kl: 27.2132\n",
            "Epoch: 465 [  100/50000 ( 0%)]  \tLoss:   89.108582\trec:   62.277721\tkl:   26.830862\n",
            "Epoch: 465 [10100/50000 (20%)]  \tLoss:   90.266670\trec:   62.671577\tkl:   27.595089\n",
            "Epoch: 465 [20100/50000 (40%)]  \tLoss:   91.452461\trec:   63.873981\tkl:   27.578482\n",
            "Epoch: 465 [30100/50000 (60%)]  \tLoss:   90.939400\trec:   63.302429\tkl:   27.636971\n",
            "Epoch: 465 [40100/50000 (80%)]  \tLoss:   89.802109\trec:   62.981922\tkl:   26.820185\n",
            "====> Epoch: 465 Average train loss: 90.3410\n",
            "====> Validation set loss: 92.8899\n",
            "====> Validation set kl: 27.5815\n",
            "Epoch: 466 [  100/50000 ( 0%)]  \tLoss:   91.942612\trec:   64.169357\tkl:   27.773262\n",
            "Epoch: 466 [10100/50000 (20%)]  \tLoss:   91.908211\trec:   63.882450\tkl:   28.025759\n",
            "Epoch: 466 [20100/50000 (40%)]  \tLoss:   89.668297\trec:   62.847507\tkl:   26.820795\n",
            "Epoch: 466 [30100/50000 (60%)]  \tLoss:   91.394920\trec:   63.806141\tkl:   27.588779\n",
            "Epoch: 466 [40100/50000 (80%)]  \tLoss:   92.465736\trec:   65.301300\tkl:   27.164442\n",
            "====> Epoch: 466 Average train loss: 90.3511\n",
            "====> Validation set loss: 92.9955\n",
            "====> Validation set kl: 27.2967\n",
            "Epoch: 467 [  100/50000 ( 0%)]  \tLoss:   87.829346\trec:   61.254509\tkl:   26.574837\n",
            "Epoch: 467 [10100/50000 (20%)]  \tLoss:   84.915779\trec:   57.492722\tkl:   27.423061\n",
            "Epoch: 467 [20100/50000 (40%)]  \tLoss:   90.682480\trec:   61.926064\tkl:   28.756413\n",
            "Epoch: 467 [30100/50000 (60%)]  \tLoss:   90.771835\trec:   62.947468\tkl:   27.824364\n",
            "Epoch: 467 [40100/50000 (80%)]  \tLoss:   88.655029\trec:   61.516415\tkl:   27.138615\n",
            "====> Epoch: 467 Average train loss: 90.3250\n",
            "====> Validation set loss: 92.9053\n",
            "====> Validation set kl: 27.2477\n",
            "Epoch: 468 [  100/50000 ( 0%)]  \tLoss:   88.272774\trec:   61.930565\tkl:   26.342207\n",
            "Epoch: 468 [10100/50000 (20%)]  \tLoss:   87.372810\trec:   61.264515\tkl:   26.108294\n",
            "Epoch: 468 [20100/50000 (40%)]  \tLoss:   87.892227\trec:   61.648075\tkl:   26.244148\n",
            "Epoch: 468 [30100/50000 (60%)]  \tLoss:   92.476662\trec:   64.132469\tkl:   28.344185\n",
            "Epoch: 468 [40100/50000 (80%)]  \tLoss:   88.655830\trec:   61.529705\tkl:   27.126122\n",
            "====> Epoch: 468 Average train loss: 90.3098\n",
            "====> Validation set loss: 93.0620\n",
            "====> Validation set kl: 27.4581\n",
            "Epoch: 469 [  100/50000 ( 0%)]  \tLoss:   89.474648\trec:   62.081448\tkl:   27.393198\n",
            "Epoch: 469 [10100/50000 (20%)]  \tLoss:   91.183907\trec:   64.057442\tkl:   27.126461\n",
            "Epoch: 469 [20100/50000 (40%)]  \tLoss:   90.311180\trec:   62.300056\tkl:   28.011120\n",
            "Epoch: 469 [30100/50000 (60%)]  \tLoss:   90.030075\trec:   62.408295\tkl:   27.621784\n",
            "Epoch: 469 [40100/50000 (80%)]  \tLoss:   95.026657\trec:   66.261490\tkl:   28.765171\n",
            "====> Epoch: 469 Average train loss: 90.3173\n",
            "====> Validation set loss: 92.9925\n",
            "====> Validation set kl: 27.4845\n",
            "Epoch: 470 [  100/50000 ( 0%)]  \tLoss:   89.320671\trec:   62.196297\tkl:   27.124374\n",
            "Epoch: 470 [10100/50000 (20%)]  \tLoss:   89.764664\trec:   61.987396\tkl:   27.777275\n",
            "Epoch: 470 [20100/50000 (40%)]  \tLoss:   88.695427\trec:   61.311836\tkl:   27.383589\n",
            "Epoch: 470 [30100/50000 (60%)]  \tLoss:   88.463364\trec:   61.564720\tkl:   26.898649\n",
            "Epoch: 470 [40100/50000 (80%)]  \tLoss:   94.348038\trec:   66.798874\tkl:   27.549162\n",
            "====> Epoch: 470 Average train loss: 90.3184\n",
            "====> Validation set loss: 92.7847\n",
            "====> Validation set kl: 27.4200\n",
            "Epoch: 471 [  100/50000 ( 0%)]  \tLoss:   89.996056\trec:   61.934021\tkl:   28.062025\n",
            "Epoch: 471 [10100/50000 (20%)]  \tLoss:   87.040390\trec:   59.923664\tkl:   27.116718\n",
            "Epoch: 471 [20100/50000 (40%)]  \tLoss:   91.151192\trec:   63.831966\tkl:   27.319221\n",
            "Epoch: 471 [30100/50000 (60%)]  \tLoss:   92.676590\trec:   64.970825\tkl:   27.705767\n",
            "Epoch: 471 [40100/50000 (80%)]  \tLoss:   89.257271\trec:   62.229183\tkl:   27.028090\n",
            "====> Epoch: 471 Average train loss: 90.3225\n",
            "====> Validation set loss: 92.8894\n",
            "====> Validation set kl: 27.4036\n",
            "Epoch: 472 [  100/50000 ( 0%)]  \tLoss:   91.128174\trec:   62.997864\tkl:   28.130304\n",
            "Epoch: 472 [10100/50000 (20%)]  \tLoss:   92.413979\trec:   64.957932\tkl:   27.456055\n",
            "Epoch: 472 [20100/50000 (40%)]  \tLoss:   88.262566\trec:   61.052990\tkl:   27.209572\n",
            "Epoch: 472 [30100/50000 (60%)]  \tLoss:   91.944374\trec:   64.026016\tkl:   27.918358\n",
            "Epoch: 472 [40100/50000 (80%)]  \tLoss:   86.838028\trec:   60.299953\tkl:   26.538076\n",
            "====> Epoch: 472 Average train loss: 90.3182\n",
            "====> Validation set loss: 92.9029\n",
            "====> Validation set kl: 27.3513\n",
            "Epoch: 473 [  100/50000 ( 0%)]  \tLoss:   87.587646\trec:   61.339592\tkl:   26.248055\n",
            "Epoch: 473 [10100/50000 (20%)]  \tLoss:   88.237892\trec:   60.929852\tkl:   27.308031\n",
            "Epoch: 473 [20100/50000 (40%)]  \tLoss:   92.494705\trec:   64.608757\tkl:   27.885942\n",
            "Epoch: 473 [30100/50000 (60%)]  \tLoss:   89.780357\trec:   62.419567\tkl:   27.360790\n",
            "Epoch: 473 [40100/50000 (80%)]  \tLoss:   89.730743\trec:   62.769733\tkl:   26.961002\n",
            "====> Epoch: 473 Average train loss: 90.3169\n",
            "====> Validation set loss: 92.9556\n",
            "====> Validation set kl: 27.2536\n",
            "Epoch: 474 [  100/50000 ( 0%)]  \tLoss:   86.990387\trec:   60.429424\tkl:   26.560968\n",
            "Epoch: 474 [10100/50000 (20%)]  \tLoss:   92.163200\trec:   64.317192\tkl:   27.846010\n",
            "Epoch: 474 [20100/50000 (40%)]  \tLoss:   93.235489\trec:   65.467369\tkl:   27.768120\n",
            "Epoch: 474 [30100/50000 (60%)]  \tLoss:   87.257843\trec:   60.597431\tkl:   26.660412\n",
            "Epoch: 474 [40100/50000 (80%)]  \tLoss:   94.422623\trec:   66.188622\tkl:   28.234005\n",
            "====> Epoch: 474 Average train loss: 90.2974\n",
            "====> Validation set loss: 92.7842\n",
            "====> Validation set kl: 27.2899\n",
            "Epoch: 475 [  100/50000 ( 0%)]  \tLoss:   87.933876\trec:   61.390751\tkl:   26.543121\n",
            "Epoch: 475 [10100/50000 (20%)]  \tLoss:   92.383492\trec:   64.335236\tkl:   28.048256\n",
            "Epoch: 475 [20100/50000 (40%)]  \tLoss:   89.140846\trec:   61.266640\tkl:   27.874210\n",
            "Epoch: 475 [30100/50000 (60%)]  \tLoss:   89.240181\trec:   62.334831\tkl:   26.905354\n",
            "Epoch: 475 [40100/50000 (80%)]  \tLoss:   95.819702\trec:   67.876755\tkl:   27.942944\n",
            "====> Epoch: 475 Average train loss: 90.2944\n",
            "====> Validation set loss: 92.8829\n",
            "====> Validation set kl: 27.2982\n",
            "Epoch: 476 [  100/50000 ( 0%)]  \tLoss:   94.162811\trec:   64.707138\tkl:   29.455673\n",
            "Epoch: 476 [10100/50000 (20%)]  \tLoss:   87.429443\trec:   60.559177\tkl:   26.870262\n",
            "Epoch: 476 [20100/50000 (40%)]  \tLoss:   92.890152\trec:   65.285225\tkl:   27.604929\n",
            "Epoch: 476 [30100/50000 (60%)]  \tLoss:   88.261909\trec:   61.427856\tkl:   26.834053\n",
            "Epoch: 476 [40100/50000 (80%)]  \tLoss:   86.462654\trec:   60.194126\tkl:   26.268528\n",
            "====> Epoch: 476 Average train loss: 90.2856\n",
            "====> Validation set loss: 92.9108\n",
            "====> Validation set kl: 27.1611\n",
            "Epoch: 477 [  100/50000 ( 0%)]  \tLoss:   92.898804\trec:   65.564316\tkl:   27.334494\n",
            "Epoch: 477 [10100/50000 (20%)]  \tLoss:   87.206383\trec:   59.780399\tkl:   27.425985\n",
            "Epoch: 477 [20100/50000 (40%)]  \tLoss:   89.224297\trec:   62.533527\tkl:   26.690769\n",
            "Epoch: 477 [30100/50000 (60%)]  \tLoss:   90.244171\trec:   62.931347\tkl:   27.312824\n",
            "Epoch: 477 [40100/50000 (80%)]  \tLoss:   91.843208\trec:   64.041092\tkl:   27.802120\n",
            "====> Epoch: 477 Average train loss: 90.2867\n",
            "====> Validation set loss: 92.7941\n",
            "====> Validation set kl: 27.5200\n",
            "Epoch: 478 [  100/50000 ( 0%)]  \tLoss:   92.228065\trec:   64.207077\tkl:   28.020990\n",
            "Epoch: 478 [10100/50000 (20%)]  \tLoss:   88.815399\trec:   61.077713\tkl:   27.737682\n",
            "Epoch: 478 [20100/50000 (40%)]  \tLoss:   88.208702\trec:   61.788368\tkl:   26.420332\n",
            "Epoch: 478 [30100/50000 (60%)]  \tLoss:   90.683067\trec:   62.683964\tkl:   27.999104\n",
            "Epoch: 478 [40100/50000 (80%)]  \tLoss:   88.692909\trec:   60.884296\tkl:   27.808611\n",
            "====> Epoch: 478 Average train loss: 90.2711\n",
            "====> Validation set loss: 92.8811\n",
            "====> Validation set kl: 27.3554\n",
            "Epoch: 479 [  100/50000 ( 0%)]  \tLoss:   86.319283\trec:   60.167900\tkl:   26.151386\n",
            "Epoch: 479 [10100/50000 (20%)]  \tLoss:   89.552208\trec:   62.913242\tkl:   26.638962\n",
            "Epoch: 479 [20100/50000 (40%)]  \tLoss:   90.181404\trec:   62.891121\tkl:   27.290277\n",
            "Epoch: 479 [30100/50000 (60%)]  \tLoss:   89.270294\trec:   62.662899\tkl:   26.607391\n",
            "Epoch: 479 [40100/50000 (80%)]  \tLoss:   91.736046\trec:   64.186981\tkl:   27.549063\n",
            "====> Epoch: 479 Average train loss: 90.2749\n",
            "====> Validation set loss: 92.8774\n",
            "====> Validation set kl: 27.1935\n",
            "Epoch: 480 [  100/50000 ( 0%)]  \tLoss:   90.773354\trec:   63.308159\tkl:   27.465197\n",
            "Epoch: 480 [10100/50000 (20%)]  \tLoss:   92.013252\trec:   64.585793\tkl:   27.427460\n",
            "Epoch: 480 [20100/50000 (40%)]  \tLoss:   91.313927\trec:   63.463020\tkl:   27.850904\n",
            "Epoch: 480 [30100/50000 (60%)]  \tLoss:   93.860664\trec:   66.160454\tkl:   27.700205\n",
            "Epoch: 480 [40100/50000 (80%)]  \tLoss:   91.743668\trec:   64.351860\tkl:   27.391806\n",
            "====> Epoch: 480 Average train loss: 90.2721\n",
            "====> Validation set loss: 92.8010\n",
            "====> Validation set kl: 27.5498\n",
            "Epoch: 481 [  100/50000 ( 0%)]  \tLoss:   84.988731\trec:   58.504196\tkl:   26.484526\n",
            "Epoch: 481 [10100/50000 (20%)]  \tLoss:   92.013199\trec:   64.118073\tkl:   27.895132\n",
            "Epoch: 481 [20100/50000 (40%)]  \tLoss:   93.314034\trec:   65.077087\tkl:   28.236946\n",
            "Epoch: 481 [30100/50000 (60%)]  \tLoss:   91.607285\trec:   63.834606\tkl:   27.772673\n",
            "Epoch: 481 [40100/50000 (80%)]  \tLoss:   92.458183\trec:   64.021271\tkl:   28.436918\n",
            "====> Epoch: 481 Average train loss: 90.2451\n",
            "====> Validation set loss: 92.7877\n",
            "====> Validation set kl: 27.2291\n",
            "Epoch: 482 [  100/50000 ( 0%)]  \tLoss:   90.460564\trec:   63.349609\tkl:   27.110962\n",
            "Epoch: 482 [10100/50000 (20%)]  \tLoss:   91.364647\trec:   63.646191\tkl:   27.718462\n",
            "Epoch: 482 [20100/50000 (40%)]  \tLoss:   86.902588\trec:   60.351917\tkl:   26.550671\n",
            "Epoch: 482 [30100/50000 (60%)]  \tLoss:   88.892830\trec:   61.693661\tkl:   27.199171\n",
            "Epoch: 482 [40100/50000 (80%)]  \tLoss:   91.039467\trec:   63.299500\tkl:   27.739973\n",
            "====> Epoch: 482 Average train loss: 90.2444\n",
            "====> Validation set loss: 92.8555\n",
            "====> Validation set kl: 27.4861\n",
            "Epoch: 483 [  100/50000 ( 0%)]  \tLoss:   91.407654\trec:   63.876980\tkl:   27.530678\n",
            "Epoch: 483 [10100/50000 (20%)]  \tLoss:   93.853203\trec:   65.667404\tkl:   28.185795\n",
            "Epoch: 483 [20100/50000 (40%)]  \tLoss:   92.698158\trec:   64.860611\tkl:   27.837545\n",
            "Epoch: 483 [30100/50000 (60%)]  \tLoss:   89.159111\trec:   61.784580\tkl:   27.374531\n",
            "Epoch: 483 [40100/50000 (80%)]  \tLoss:   86.265739\trec:   59.457088\tkl:   26.808651\n",
            "====> Epoch: 483 Average train loss: 90.2320\n",
            "====> Validation set loss: 92.8114\n",
            "====> Validation set kl: 27.6004\n",
            "Epoch: 484 [  100/50000 ( 0%)]  \tLoss:   87.042030\trec:   59.756725\tkl:   27.285305\n",
            "Epoch: 484 [10100/50000 (20%)]  \tLoss:   89.287651\trec:   62.162937\tkl:   27.124722\n",
            "Epoch: 484 [20100/50000 (40%)]  \tLoss:   90.080177\trec:   62.444851\tkl:   27.635317\n",
            "Epoch: 484 [30100/50000 (60%)]  \tLoss:   92.446251\trec:   65.182060\tkl:   27.264187\n",
            "Epoch: 484 [40100/50000 (80%)]  \tLoss:   91.139389\trec:   64.701622\tkl:   26.437767\n",
            "====> Epoch: 484 Average train loss: 90.2483\n",
            "====> Validation set loss: 92.8649\n",
            "====> Validation set kl: 27.7032\n",
            "Epoch: 485 [  100/50000 ( 0%)]  \tLoss:   87.232597\trec:   59.526707\tkl:   27.705891\n",
            "Epoch: 485 [10100/50000 (20%)]  \tLoss:   95.335548\trec:   67.353455\tkl:   27.982094\n",
            "Epoch: 485 [20100/50000 (40%)]  \tLoss:   87.621002\trec:   60.450283\tkl:   27.170723\n",
            "Epoch: 485 [30100/50000 (60%)]  \tLoss:   90.592758\trec:   62.995632\tkl:   27.597128\n",
            "Epoch: 485 [40100/50000 (80%)]  \tLoss:   93.852089\trec:   66.008156\tkl:   27.843935\n",
            "====> Epoch: 485 Average train loss: 90.2479\n",
            "====> Validation set loss: 92.8556\n",
            "====> Validation set kl: 27.1628\n",
            "Epoch: 486 [  100/50000 ( 0%)]  \tLoss:   89.624763\trec:   62.163799\tkl:   27.460960\n",
            "Epoch: 486 [10100/50000 (20%)]  \tLoss:   88.185097\trec:   61.673481\tkl:   26.511620\n",
            "Epoch: 486 [20100/50000 (40%)]  \tLoss:   89.847801\trec:   62.545898\tkl:   27.301901\n",
            "Epoch: 486 [30100/50000 (60%)]  \tLoss:   90.935593\trec:   63.665905\tkl:   27.269690\n",
            "Epoch: 486 [40100/50000 (80%)]  \tLoss:   87.287224\trec:   60.633514\tkl:   26.653708\n",
            "====> Epoch: 486 Average train loss: 90.2269\n",
            "====> Validation set loss: 92.9294\n",
            "====> Validation set kl: 27.4512\n",
            "Epoch: 487 [  100/50000 ( 0%)]  \tLoss:   89.424881\trec:   61.851707\tkl:   27.573168\n",
            "Epoch: 487 [10100/50000 (20%)]  \tLoss:   87.664726\trec:   60.541103\tkl:   27.123619\n",
            "Epoch: 487 [20100/50000 (40%)]  \tLoss:   93.338310\trec:   65.665245\tkl:   27.673065\n",
            "Epoch: 487 [30100/50000 (60%)]  \tLoss:   93.079323\trec:   64.921082\tkl:   28.158239\n",
            "Epoch: 487 [40100/50000 (80%)]  \tLoss:   85.550255\trec:   59.006145\tkl:   26.544106\n",
            "====> Epoch: 487 Average train loss: 90.2316\n",
            "====> Validation set loss: 92.8033\n",
            "====> Validation set kl: 27.3660\n",
            "Epoch: 488 [  100/50000 ( 0%)]  \tLoss:   87.681030\trec:   61.442085\tkl:   26.238945\n",
            "Epoch: 488 [10100/50000 (20%)]  \tLoss:   92.612595\trec:   64.740028\tkl:   27.872570\n",
            "Epoch: 488 [20100/50000 (40%)]  \tLoss:   91.579689\trec:   63.446033\tkl:   28.133646\n",
            "Epoch: 488 [30100/50000 (60%)]  \tLoss:   90.281250\trec:   62.912392\tkl:   27.368862\n",
            "Epoch: 488 [40100/50000 (80%)]  \tLoss:   92.494118\trec:   65.219688\tkl:   27.274437\n",
            "====> Epoch: 488 Average train loss: 90.2313\n",
            "====> Validation set loss: 92.8577\n",
            "====> Validation set kl: 27.5418\n",
            "Epoch: 489 [  100/50000 ( 0%)]  \tLoss:   87.045425\trec:   59.570595\tkl:   27.474838\n",
            "Epoch: 489 [10100/50000 (20%)]  \tLoss:   92.458282\trec:   64.882042\tkl:   27.576242\n",
            "Epoch: 489 [20100/50000 (40%)]  \tLoss:   89.607475\trec:   62.237194\tkl:   27.370283\n",
            "Epoch: 489 [30100/50000 (60%)]  \tLoss:   87.631348\trec:   61.337170\tkl:   26.294180\n",
            "Epoch: 489 [40100/50000 (80%)]  \tLoss:   94.214882\trec:   65.993820\tkl:   28.221054\n",
            "====> Epoch: 489 Average train loss: 90.2166\n",
            "====> Validation set loss: 92.8681\n",
            "====> Validation set kl: 27.3147\n",
            "Epoch: 490 [  100/50000 ( 0%)]  \tLoss:   91.810463\trec:   64.244431\tkl:   27.566040\n",
            "Epoch: 490 [10100/50000 (20%)]  \tLoss:   89.735176\trec:   62.779266\tkl:   26.955908\n",
            "Epoch: 490 [20100/50000 (40%)]  \tLoss:   89.138741\trec:   62.162830\tkl:   26.975904\n",
            "Epoch: 490 [30100/50000 (60%)]  \tLoss:   83.457169\trec:   56.848866\tkl:   26.608295\n",
            "Epoch: 490 [40100/50000 (80%)]  \tLoss:   92.044922\trec:   64.548782\tkl:   27.496134\n",
            "====> Epoch: 490 Average train loss: 90.1887\n",
            "====> Validation set loss: 92.8667\n",
            "====> Validation set kl: 27.5739\n",
            "Epoch: 491 [  100/50000 ( 0%)]  \tLoss:   86.671440\trec:   59.026005\tkl:   27.645443\n",
            "Epoch: 491 [10100/50000 (20%)]  \tLoss:   88.785507\trec:   61.577049\tkl:   27.208456\n",
            "Epoch: 491 [20100/50000 (40%)]  \tLoss:   92.000359\trec:   64.254120\tkl:   27.746237\n",
            "Epoch: 491 [30100/50000 (60%)]  \tLoss:   91.998848\trec:   64.500572\tkl:   27.498270\n",
            "Epoch: 491 [40100/50000 (80%)]  \tLoss:   89.261230\trec:   61.353680\tkl:   27.907543\n",
            "====> Epoch: 491 Average train loss: 90.1752\n",
            "====> Validation set loss: 92.7868\n",
            "====> Validation set kl: 27.2546\n",
            "Epoch: 492 [  100/50000 ( 0%)]  \tLoss:   94.921547\trec:   67.153465\tkl:   27.768085\n",
            "Epoch: 492 [10100/50000 (20%)]  \tLoss:   89.084755\trec:   61.522972\tkl:   27.561781\n",
            "Epoch: 492 [20100/50000 (40%)]  \tLoss:   83.416054\trec:   56.736729\tkl:   26.679325\n",
            "Epoch: 492 [30100/50000 (60%)]  \tLoss:   93.727417\trec:   65.542351\tkl:   28.185066\n",
            "Epoch: 492 [40100/50000 (80%)]  \tLoss:   90.569130\trec:   62.357338\tkl:   28.211792\n",
            "====> Epoch: 492 Average train loss: 90.2009\n",
            "====> Validation set loss: 92.9402\n",
            "====> Validation set kl: 27.3555\n",
            "Epoch: 493 [  100/50000 ( 0%)]  \tLoss:   90.766411\trec:   63.393147\tkl:   27.373268\n",
            "Epoch: 493 [10100/50000 (20%)]  \tLoss:   94.241875\trec:   65.937256\tkl:   28.304613\n",
            "Epoch: 493 [20100/50000 (40%)]  \tLoss:   91.462799\trec:   63.882214\tkl:   27.580585\n",
            "Epoch: 493 [30100/50000 (60%)]  \tLoss:   84.559006\trec:   58.067787\tkl:   26.491219\n",
            "Epoch: 493 [40100/50000 (80%)]  \tLoss:   91.551270\trec:   63.581345\tkl:   27.969921\n",
            "====> Epoch: 493 Average train loss: 90.2350\n",
            "====> Validation set loss: 92.8543\n",
            "====> Validation set kl: 27.3952\n",
            "Epoch: 494 [  100/50000 ( 0%)]  \tLoss:   87.618927\trec:   60.036278\tkl:   27.582642\n",
            "Epoch: 494 [10100/50000 (20%)]  \tLoss:   90.058670\trec:   62.854599\tkl:   27.204069\n",
            "Epoch: 494 [20100/50000 (40%)]  \tLoss:   90.064743\trec:   62.218601\tkl:   27.846148\n",
            "Epoch: 494 [30100/50000 (60%)]  \tLoss:   87.652031\trec:   60.678402\tkl:   26.973627\n",
            "Epoch: 494 [40100/50000 (80%)]  \tLoss:   87.967712\trec:   60.922302\tkl:   27.045410\n",
            "====> Epoch: 494 Average train loss: 90.1893\n",
            "====> Validation set loss: 92.7992\n",
            "====> Validation set kl: 27.3150\n",
            "Epoch: 495 [  100/50000 ( 0%)]  \tLoss:   92.792511\trec:   64.488991\tkl:   28.303518\n",
            "Epoch: 495 [10100/50000 (20%)]  \tLoss:   92.293556\trec:   64.533371\tkl:   27.760180\n",
            "Epoch: 495 [20100/50000 (40%)]  \tLoss:   88.915733\trec:   61.468487\tkl:   27.447248\n",
            "Epoch: 495 [30100/50000 (60%)]  \tLoss:   90.466377\trec:   63.516891\tkl:   26.949482\n",
            "Epoch: 495 [40100/50000 (80%)]  \tLoss:   93.698074\trec:   66.186790\tkl:   27.511284\n",
            "====> Epoch: 495 Average train loss: 90.1804\n",
            "====> Validation set loss: 92.8698\n",
            "====> Validation set kl: 27.2333\n",
            "Epoch: 496 [  100/50000 ( 0%)]  \tLoss:   89.602676\trec:   63.602665\tkl:   26.000008\n",
            "Epoch: 496 [10100/50000 (20%)]  \tLoss:   88.848114\trec:   61.784657\tkl:   27.063459\n",
            "Epoch: 496 [20100/50000 (40%)]  \tLoss:   94.057098\trec:   66.616959\tkl:   27.440136\n",
            "Epoch: 496 [30100/50000 (60%)]  \tLoss:   90.600037\trec:   64.151955\tkl:   26.448082\n",
            "Epoch: 496 [40100/50000 (80%)]  \tLoss:   90.297340\trec:   62.980335\tkl:   27.317007\n",
            "====> Epoch: 496 Average train loss: 90.1855\n",
            "====> Validation set loss: 92.8654\n",
            "====> Validation set kl: 27.6154\n",
            "Epoch: 497 [  100/50000 ( 0%)]  \tLoss:   91.892067\trec:   63.730839\tkl:   28.161230\n",
            "Epoch: 497 [10100/50000 (20%)]  \tLoss:   91.812653\trec:   63.136234\tkl:   28.676426\n",
            "Epoch: 497 [20100/50000 (40%)]  \tLoss:   91.798096\trec:   63.829967\tkl:   27.968126\n",
            "Epoch: 497 [30100/50000 (60%)]  \tLoss:   91.460854\trec:   62.868343\tkl:   28.592514\n",
            "Epoch: 497 [40100/50000 (80%)]  \tLoss:   95.489937\trec:   66.779694\tkl:   28.710239\n",
            "====> Epoch: 497 Average train loss: 90.1949\n",
            "====> Validation set loss: 92.8879\n",
            "====> Validation set kl: 27.4448\n",
            "Epoch: 498 [  100/50000 ( 0%)]  \tLoss:   90.517593\trec:   63.578659\tkl:   26.938932\n",
            "Epoch: 498 [10100/50000 (20%)]  \tLoss:   86.802589\trec:   59.916576\tkl:   26.886009\n",
            "Epoch: 498 [20100/50000 (40%)]  \tLoss:   90.705429\trec:   63.038120\tkl:   27.667305\n",
            "Epoch: 498 [30100/50000 (60%)]  \tLoss:   91.572205\trec:   64.428589\tkl:   27.143608\n",
            "Epoch: 498 [40100/50000 (80%)]  \tLoss:   86.805389\trec:   59.659271\tkl:   27.146118\n",
            "====> Epoch: 498 Average train loss: 90.1904\n",
            "====> Validation set loss: 92.7780\n",
            "====> Validation set kl: 27.5322\n",
            "Epoch: 499 [  100/50000 ( 0%)]  \tLoss:   87.546783\trec:   60.800491\tkl:   26.746294\n",
            "Epoch: 499 [10100/50000 (20%)]  \tLoss:   87.198433\trec:   59.911480\tkl:   27.286955\n",
            "Epoch: 499 [20100/50000 (40%)]  \tLoss:   90.994400\trec:   63.885361\tkl:   27.109039\n",
            "Epoch: 499 [30100/50000 (60%)]  \tLoss:   88.114761\trec:   60.614990\tkl:   27.499779\n",
            "Epoch: 499 [40100/50000 (80%)]  \tLoss:   85.536324\trec:   58.588474\tkl:   26.947853\n",
            "====> Epoch: 499 Average train loss: 90.1666\n",
            "====> Validation set loss: 92.8627\n",
            "====> Validation set kl: 27.5808\n",
            "Epoch: 500 [  100/50000 ( 0%)]  \tLoss:   92.578285\trec:   64.586510\tkl:   27.991774\n",
            "Epoch: 500 [10100/50000 (20%)]  \tLoss:   86.043152\trec:   59.469696\tkl:   26.573454\n",
            "Epoch: 500 [20100/50000 (40%)]  \tLoss:   93.192467\trec:   64.907394\tkl:   28.285074\n",
            "Epoch: 500 [30100/50000 (60%)]  \tLoss:   91.064629\trec:   63.462536\tkl:   27.602085\n",
            "Epoch: 500 [40100/50000 (80%)]  \tLoss:   85.582970\trec:   59.641102\tkl:   25.941868\n",
            "====> Epoch: 500 Average train loss: 90.1477\n",
            "====> Validation set loss: 92.9425\n",
            "====> Validation set kl: 27.2929\n",
            "Epoch: 501 [  100/50000 ( 0%)]  \tLoss:   94.163055\trec:   65.890976\tkl:   28.272078\n",
            "Epoch: 501 [10100/50000 (20%)]  \tLoss:   91.090118\trec:   63.470600\tkl:   27.619516\n",
            "Epoch: 501 [20100/50000 (40%)]  \tLoss:   89.216606\trec:   62.093269\tkl:   27.123337\n",
            "Epoch: 501 [30100/50000 (60%)]  \tLoss:   92.658234\trec:   64.875519\tkl:   27.782707\n",
            "Epoch: 501 [40100/50000 (80%)]  \tLoss:   90.408905\trec:   63.206718\tkl:   27.202185\n",
            "====> Epoch: 501 Average train loss: 90.1620\n",
            "====> Validation set loss: 92.8636\n",
            "====> Validation set kl: 27.3607\n",
            "Epoch: 502 [  100/50000 ( 0%)]  \tLoss:   87.349800\trec:   59.898064\tkl:   27.451733\n",
            "Epoch: 502 [10100/50000 (20%)]  \tLoss:   89.777588\trec:   63.150696\tkl:   26.626892\n",
            "Epoch: 502 [20100/50000 (40%)]  \tLoss:   87.213989\trec:   60.580379\tkl:   26.633615\n",
            "Epoch: 502 [30100/50000 (60%)]  \tLoss:   88.350769\trec:   62.363716\tkl:   25.987055\n",
            "Epoch: 502 [40100/50000 (80%)]  \tLoss:   85.909645\trec:   59.179256\tkl:   26.730391\n",
            "====> Epoch: 502 Average train loss: 90.1634\n",
            "====> Validation set loss: 92.8417\n",
            "====> Validation set kl: 27.4303\n",
            "Epoch: 503 [  100/50000 ( 0%)]  \tLoss:   91.761269\trec:   64.277168\tkl:   27.484091\n",
            "Epoch: 503 [10100/50000 (20%)]  \tLoss:   87.229233\trec:   60.509857\tkl:   26.719383\n",
            "Epoch: 503 [20100/50000 (40%)]  \tLoss:   89.161293\trec:   61.717968\tkl:   27.443327\n",
            "Epoch: 503 [30100/50000 (60%)]  \tLoss:   92.517929\trec:   65.350121\tkl:   27.167803\n",
            "Epoch: 503 [40100/50000 (80%)]  \tLoss:   89.676460\trec:   62.070980\tkl:   27.605486\n",
            "====> Epoch: 503 Average train loss: 90.1596\n",
            "====> Validation set loss: 92.7918\n",
            "====> Validation set kl: 27.3917\n",
            "Epoch: 504 [  100/50000 ( 0%)]  \tLoss:   91.961220\trec:   64.588982\tkl:   27.372238\n",
            "Epoch: 504 [10100/50000 (20%)]  \tLoss:   91.407265\trec:   63.998806\tkl:   27.408457\n",
            "Epoch: 504 [20100/50000 (40%)]  \tLoss:   91.817696\trec:   63.841507\tkl:   27.976191\n",
            "Epoch: 504 [30100/50000 (60%)]  \tLoss:   88.769196\trec:   61.603683\tkl:   27.165512\n",
            "Epoch: 504 [40100/50000 (80%)]  \tLoss:   88.162582\trec:   61.066216\tkl:   27.096371\n",
            "====> Epoch: 504 Average train loss: 90.1253\n",
            "====> Validation set loss: 92.7608\n",
            "====> Validation set kl: 27.5210\n",
            "Epoch: 505 [  100/50000 ( 0%)]  \tLoss:   97.757759\trec:   69.390701\tkl:   28.367062\n",
            "Epoch: 505 [10100/50000 (20%)]  \tLoss:   90.112000\trec:   62.403465\tkl:   27.708534\n",
            "Epoch: 505 [20100/50000 (40%)]  \tLoss:   88.593468\trec:   61.122959\tkl:   27.470510\n",
            "Epoch: 505 [30100/50000 (60%)]  \tLoss:   89.113503\trec:   61.433044\tkl:   27.680460\n",
            "Epoch: 505 [40100/50000 (80%)]  \tLoss:   89.904816\trec:   62.162861\tkl:   27.741955\n",
            "====> Epoch: 505 Average train loss: 90.1239\n",
            "====> Validation set loss: 92.9116\n",
            "====> Validation set kl: 27.5572\n",
            "Epoch: 506 [  100/50000 ( 0%)]  \tLoss:   87.033463\trec:   59.796795\tkl:   27.236670\n",
            "Epoch: 506 [10100/50000 (20%)]  \tLoss:   92.089149\trec:   63.706341\tkl:   28.382809\n",
            "Epoch: 506 [20100/50000 (40%)]  \tLoss:   92.224205\trec:   64.974754\tkl:   27.249453\n",
            "Epoch: 506 [30100/50000 (60%)]  \tLoss:   88.185532\trec:   61.208942\tkl:   26.976591\n",
            "Epoch: 506 [40100/50000 (80%)]  \tLoss:   86.157791\trec:   59.632156\tkl:   26.525637\n",
            "====> Epoch: 506 Average train loss: 90.1399\n",
            "====> Validation set loss: 92.6640\n",
            "====> Validation set kl: 27.4388\n",
            "Epoch: 507 [  100/50000 ( 0%)]  \tLoss:   95.119179\trec:   67.056305\tkl:   28.062868\n",
            "Epoch: 507 [10100/50000 (20%)]  \tLoss:   88.193985\trec:   61.506462\tkl:   26.687513\n",
            "Epoch: 507 [20100/50000 (40%)]  \tLoss:   88.579147\trec:   61.857002\tkl:   26.722151\n",
            "Epoch: 507 [30100/50000 (60%)]  \tLoss:   89.807770\trec:   62.940563\tkl:   26.867201\n",
            "Epoch: 507 [40100/50000 (80%)]  \tLoss:   91.726593\trec:   64.000259\tkl:   27.726326\n",
            "====> Epoch: 507 Average train loss: 90.0966\n",
            "====> Validation set loss: 92.7461\n",
            "====> Validation set kl: 27.2425\n",
            "Epoch: 508 [  100/50000 ( 0%)]  \tLoss:   88.897964\trec:   62.535778\tkl:   26.362183\n",
            "Epoch: 508 [10100/50000 (20%)]  \tLoss:   88.096306\trec:   60.745869\tkl:   27.350439\n",
            "Epoch: 508 [20100/50000 (40%)]  \tLoss:   87.770279\trec:   61.236755\tkl:   26.533522\n",
            "Epoch: 508 [30100/50000 (60%)]  \tLoss:   90.246735\trec:   61.624775\tkl:   28.621965\n",
            "Epoch: 508 [40100/50000 (80%)]  \tLoss:   91.740585\trec:   63.646141\tkl:   28.094448\n",
            "====> Epoch: 508 Average train loss: 90.1315\n",
            "====> Validation set loss: 92.9272\n",
            "====> Validation set kl: 27.4877\n",
            "Epoch: 509 [  100/50000 ( 0%)]  \tLoss:   91.816948\trec:   64.401482\tkl:   27.415474\n",
            "Epoch: 509 [10100/50000 (20%)]  \tLoss:   90.548843\trec:   62.626991\tkl:   27.921860\n",
            "Epoch: 509 [20100/50000 (40%)]  \tLoss:   90.666611\trec:   63.695122\tkl:   26.971489\n",
            "Epoch: 509 [30100/50000 (60%)]  \tLoss:   86.970886\trec:   60.150726\tkl:   26.820158\n",
            "Epoch: 509 [40100/50000 (80%)]  \tLoss:   93.173164\trec:   65.070244\tkl:   28.102919\n",
            "====> Epoch: 509 Average train loss: 90.1379\n",
            "====> Validation set loss: 92.8022\n",
            "====> Validation set kl: 27.3475\n",
            "Epoch: 510 [  100/50000 ( 0%)]  \tLoss:   94.575050\trec:   66.037857\tkl:   28.537189\n",
            "Epoch: 510 [10100/50000 (20%)]  \tLoss:   88.367165\trec:   61.275036\tkl:   27.092125\n",
            "Epoch: 510 [20100/50000 (40%)]  \tLoss:   91.648575\trec:   63.962517\tkl:   27.686056\n",
            "Epoch: 510 [30100/50000 (60%)]  \tLoss:   86.250389\trec:   59.723305\tkl:   26.527079\n",
            "Epoch: 510 [40100/50000 (80%)]  \tLoss:   88.372192\trec:   61.902733\tkl:   26.469461\n",
            "====> Epoch: 510 Average train loss: 90.1249\n",
            "====> Validation set loss: 92.7566\n",
            "====> Validation set kl: 27.5662\n",
            "Epoch: 511 [  100/50000 ( 0%)]  \tLoss:   90.686783\trec:   63.284569\tkl:   27.402218\n",
            "Epoch: 511 [10100/50000 (20%)]  \tLoss:   90.155899\trec:   62.776005\tkl:   27.379890\n",
            "Epoch: 511 [20100/50000 (40%)]  \tLoss:   89.111298\trec:   61.435722\tkl:   27.675577\n",
            "Epoch: 511 [30100/50000 (60%)]  \tLoss:   88.037033\trec:   60.635628\tkl:   27.401403\n",
            "Epoch: 511 [40100/50000 (80%)]  \tLoss:   87.859795\trec:   60.716507\tkl:   27.143286\n",
            "====> Epoch: 511 Average train loss: 90.1208\n",
            "====> Validation set loss: 92.8535\n",
            "====> Validation set kl: 27.3533\n",
            "Epoch: 512 [  100/50000 ( 0%)]  \tLoss:   88.620285\trec:   61.173523\tkl:   27.446754\n",
            "Epoch: 512 [10100/50000 (20%)]  \tLoss:   90.657715\trec:   63.401989\tkl:   27.255716\n",
            "Epoch: 512 [20100/50000 (40%)]  \tLoss:   90.191582\trec:   62.282684\tkl:   27.908892\n",
            "Epoch: 512 [30100/50000 (60%)]  \tLoss:   86.987671\trec:   60.021336\tkl:   26.966337\n",
            "Epoch: 512 [40100/50000 (80%)]  \tLoss:   88.673531\trec:   61.261635\tkl:   27.411900\n",
            "====> Epoch: 512 Average train loss: 90.1213\n",
            "====> Validation set loss: 92.8506\n",
            "====> Validation set kl: 27.3446\n",
            "Epoch: 513 [  100/50000 ( 0%)]  \tLoss:   91.816811\trec:   63.652634\tkl:   28.164175\n",
            "Epoch: 513 [10100/50000 (20%)]  \tLoss:   91.344254\trec:   63.371128\tkl:   27.973135\n",
            "Epoch: 513 [20100/50000 (40%)]  \tLoss:   91.810425\trec:   63.805920\tkl:   28.004509\n",
            "Epoch: 513 [30100/50000 (60%)]  \tLoss:   85.035675\trec:   58.079914\tkl:   26.955757\n",
            "Epoch: 513 [40100/50000 (80%)]  \tLoss:   89.011902\trec:   62.381950\tkl:   26.629951\n",
            "====> Epoch: 513 Average train loss: 90.0773\n",
            "====> Validation set loss: 92.8123\n",
            "====> Validation set kl: 27.1678\n",
            "Epoch: 514 [  100/50000 ( 0%)]  \tLoss:   90.320770\trec:   63.496895\tkl:   26.823879\n",
            "Epoch: 514 [10100/50000 (20%)]  \tLoss:   92.004990\trec:   64.167374\tkl:   27.837614\n",
            "Epoch: 514 [20100/50000 (40%)]  \tLoss:   94.879623\trec:   67.517876\tkl:   27.361748\n",
            "Epoch: 514 [30100/50000 (60%)]  \tLoss:   92.242653\trec:   64.751183\tkl:   27.491474\n",
            "Epoch: 514 [40100/50000 (80%)]  \tLoss:   92.819031\trec:   64.277138\tkl:   28.541891\n",
            "====> Epoch: 514 Average train loss: 90.1279\n",
            "====> Validation set loss: 92.7763\n",
            "====> Validation set kl: 27.6387\n",
            "Epoch: 515 [  100/50000 ( 0%)]  \tLoss:   90.832153\trec:   62.465801\tkl:   28.366356\n",
            "Epoch: 515 [10100/50000 (20%)]  \tLoss:   92.163261\trec:   64.153107\tkl:   28.010155\n",
            "Epoch: 515 [20100/50000 (40%)]  \tLoss:   87.719162\trec:   60.334595\tkl:   27.384567\n",
            "Epoch: 515 [30100/50000 (60%)]  \tLoss:   92.246452\trec:   64.829201\tkl:   27.417248\n",
            "Epoch: 515 [40100/50000 (80%)]  \tLoss:   87.173439\trec:   59.724121\tkl:   27.449318\n",
            "====> Epoch: 515 Average train loss: 90.0817\n",
            "====> Validation set loss: 92.8067\n",
            "====> Validation set kl: 27.4833\n",
            "Epoch: 516 [  100/50000 ( 0%)]  \tLoss:   88.557625\trec:   60.398308\tkl:   28.159313\n",
            "Epoch: 516 [10100/50000 (20%)]  \tLoss:   88.930450\trec:   61.875088\tkl:   27.055355\n",
            "Epoch: 516 [20100/50000 (40%)]  \tLoss:   91.453438\trec:   64.389694\tkl:   27.063742\n",
            "Epoch: 516 [30100/50000 (60%)]  \tLoss:   90.266373\trec:   62.690899\tkl:   27.575480\n",
            "Epoch: 516 [40100/50000 (80%)]  \tLoss:   89.101784\trec:   61.702835\tkl:   27.398949\n",
            "====> Epoch: 516 Average train loss: 90.1004\n",
            "====> Validation set loss: 92.7305\n",
            "====> Validation set kl: 27.2395\n",
            "Epoch: 517 [  100/50000 ( 0%)]  \tLoss:   89.131638\trec:   62.256001\tkl:   26.875639\n",
            "Epoch: 517 [10100/50000 (20%)]  \tLoss:   90.510933\trec:   63.064388\tkl:   27.446547\n",
            "Epoch: 517 [20100/50000 (40%)]  \tLoss:   90.358124\trec:   62.771263\tkl:   27.586864\n",
            "Epoch: 517 [30100/50000 (60%)]  \tLoss:   86.395447\trec:   59.365292\tkl:   27.030151\n",
            "Epoch: 517 [40100/50000 (80%)]  \tLoss:   91.703926\trec:   63.508308\tkl:   28.195612\n",
            "====> Epoch: 517 Average train loss: 90.0739\n",
            "====> Validation set loss: 92.7881\n",
            "====> Validation set kl: 27.3663\n",
            "Epoch: 518 [  100/50000 ( 0%)]  \tLoss:   94.287048\trec:   65.985603\tkl:   28.301443\n",
            "Epoch: 518 [10100/50000 (20%)]  \tLoss:   92.302017\trec:   64.329987\tkl:   27.972033\n",
            "Epoch: 518 [20100/50000 (40%)]  \tLoss:   89.306679\trec:   62.490742\tkl:   26.815939\n",
            "Epoch: 518 [30100/50000 (60%)]  \tLoss:   88.858452\trec:   61.487988\tkl:   27.370474\n",
            "Epoch: 518 [40100/50000 (80%)]  \tLoss:   87.268921\trec:   59.457687\tkl:   27.811230\n",
            "====> Epoch: 518 Average train loss: 90.0678\n",
            "====> Validation set loss: 92.7594\n",
            "====> Validation set kl: 27.5094\n",
            "Epoch: 519 [  100/50000 ( 0%)]  \tLoss:   81.667336\trec:   56.554222\tkl:   25.113111\n",
            "Epoch: 519 [10100/50000 (20%)]  \tLoss:   90.932480\trec:   63.527946\tkl:   27.404535\n",
            "Epoch: 519 [20100/50000 (40%)]  \tLoss:   87.080963\trec:   58.778748\tkl:   28.302216\n",
            "Epoch: 519 [30100/50000 (60%)]  \tLoss:   93.207245\trec:   64.686523\tkl:   28.520727\n",
            "Epoch: 519 [40100/50000 (80%)]  \tLoss:   92.126823\trec:   63.310059\tkl:   28.816769\n",
            "====> Epoch: 519 Average train loss: 90.0561\n",
            "====> Validation set loss: 92.7504\n",
            "====> Validation set kl: 27.4731\n",
            "Epoch: 520 [  100/50000 ( 0%)]  \tLoss:   87.837212\trec:   60.431961\tkl:   27.405256\n",
            "Epoch: 520 [10100/50000 (20%)]  \tLoss:   89.918076\trec:   62.950565\tkl:   26.967508\n",
            "Epoch: 520 [20100/50000 (40%)]  \tLoss:   88.360390\trec:   61.547810\tkl:   26.812572\n",
            "Epoch: 520 [30100/50000 (60%)]  \tLoss:   90.096596\trec:   63.192009\tkl:   26.904589\n",
            "Epoch: 520 [40100/50000 (80%)]  \tLoss:   89.719742\trec:   61.514599\tkl:   28.205141\n",
            "====> Epoch: 520 Average train loss: 90.0429\n",
            "====> Validation set loss: 92.8054\n",
            "====> Validation set kl: 27.6044\n",
            "Epoch: 521 [  100/50000 ( 0%)]  \tLoss:   87.702911\trec:   60.935013\tkl:   26.767891\n",
            "Epoch: 521 [10100/50000 (20%)]  \tLoss:   91.357292\trec:   63.197205\tkl:   28.160089\n",
            "Epoch: 521 [20100/50000 (40%)]  \tLoss:   89.832001\trec:   61.670212\tkl:   28.161789\n",
            "Epoch: 521 [30100/50000 (60%)]  \tLoss:   94.144890\trec:   66.423965\tkl:   27.720924\n",
            "Epoch: 521 [40100/50000 (80%)]  \tLoss:   89.609581\trec:   61.693542\tkl:   27.916037\n",
            "====> Epoch: 521 Average train loss: 90.0557\n",
            "====> Validation set loss: 92.8089\n",
            "====> Validation set kl: 27.5175\n",
            "Epoch: 522 [  100/50000 ( 0%)]  \tLoss:   85.490837\trec:   58.742332\tkl:   26.748510\n",
            "Epoch: 522 [10100/50000 (20%)]  \tLoss:   89.187256\trec:   61.197922\tkl:   27.989332\n",
            "Epoch: 522 [20100/50000 (40%)]  \tLoss:   90.457451\trec:   63.504040\tkl:   26.953405\n",
            "Epoch: 522 [30100/50000 (60%)]  \tLoss:   89.258415\trec:   62.388428\tkl:   26.869995\n",
            "Epoch: 522 [40100/50000 (80%)]  \tLoss:   87.861206\trec:   59.737606\tkl:   28.123598\n",
            "====> Epoch: 522 Average train loss: 90.0721\n",
            "====> Validation set loss: 92.7659\n",
            "====> Validation set kl: 27.3104\n",
            "Epoch: 523 [  100/50000 ( 0%)]  \tLoss:   90.266479\trec:   62.435661\tkl:   27.830820\n",
            "Epoch: 523 [10100/50000 (20%)]  \tLoss:   90.399765\trec:   62.876541\tkl:   27.523224\n",
            "Epoch: 523 [20100/50000 (40%)]  \tLoss:   89.253693\trec:   61.062805\tkl:   28.190884\n",
            "Epoch: 523 [30100/50000 (60%)]  \tLoss:   90.303436\trec:   63.353462\tkl:   26.949970\n",
            "Epoch: 523 [40100/50000 (80%)]  \tLoss:   92.016830\trec:   63.709351\tkl:   28.307486\n",
            "====> Epoch: 523 Average train loss: 90.0478\n",
            "====> Validation set loss: 92.6947\n",
            "====> Validation set kl: 27.4814\n",
            "Epoch: 524 [  100/50000 ( 0%)]  \tLoss:   87.739861\trec:   61.366508\tkl:   26.373352\n",
            "Epoch: 524 [10100/50000 (20%)]  \tLoss:   89.718712\trec:   62.273926\tkl:   27.444782\n",
            "Epoch: 524 [20100/50000 (40%)]  \tLoss:   89.658936\trec:   61.774696\tkl:   27.884239\n",
            "Epoch: 524 [30100/50000 (60%)]  \tLoss:   90.413300\trec:   62.469616\tkl:   27.943686\n",
            "Epoch: 524 [40100/50000 (80%)]  \tLoss:   92.073608\trec:   64.863144\tkl:   27.210466\n",
            "====> Epoch: 524 Average train loss: 90.0645\n",
            "====> Validation set loss: 92.6638\n",
            "====> Validation set kl: 27.4091\n",
            "Epoch: 525 [  100/50000 ( 0%)]  \tLoss:   90.754738\trec:   63.538036\tkl:   27.216702\n",
            "Epoch: 525 [10100/50000 (20%)]  \tLoss:   91.763161\trec:   63.753887\tkl:   28.009281\n",
            "Epoch: 525 [20100/50000 (40%)]  \tLoss:   92.000587\trec:   63.579113\tkl:   28.421465\n",
            "Epoch: 525 [30100/50000 (60%)]  \tLoss:   90.763474\trec:   63.538036\tkl:   27.225433\n",
            "Epoch: 525 [40100/50000 (80%)]  \tLoss:   89.585205\trec:   62.694328\tkl:   26.890873\n",
            "====> Epoch: 525 Average train loss: 90.0433\n",
            "====> Validation set loss: 92.6906\n",
            "====> Validation set kl: 27.5403\n",
            "Epoch: 526 [  100/50000 ( 0%)]  \tLoss:   86.947456\trec:   60.512074\tkl:   26.435390\n",
            "Epoch: 526 [10100/50000 (20%)]  \tLoss:   86.421501\trec:   59.121197\tkl:   27.300306\n",
            "Epoch: 526 [20100/50000 (40%)]  \tLoss:   85.613014\trec:   58.383797\tkl:   27.229218\n",
            "Epoch: 526 [30100/50000 (60%)]  \tLoss:   91.120819\trec:   63.551552\tkl:   27.569271\n",
            "Epoch: 526 [40100/50000 (80%)]  \tLoss:   91.951874\trec:   64.430573\tkl:   27.521305\n",
            "====> Epoch: 526 Average train loss: 90.0225\n",
            "====> Validation set loss: 92.6727\n",
            "====> Validation set kl: 27.4625\n",
            "Epoch: 527 [  100/50000 ( 0%)]  \tLoss:   90.808990\trec:   62.580307\tkl:   28.228685\n",
            "Epoch: 527 [10100/50000 (20%)]  \tLoss:   90.933044\trec:   62.811951\tkl:   28.121094\n",
            "Epoch: 527 [20100/50000 (40%)]  \tLoss:   86.796249\trec:   60.507244\tkl:   26.289009\n",
            "Epoch: 527 [30100/50000 (60%)]  \tLoss:   88.933563\trec:   61.413509\tkl:   27.520050\n",
            "Epoch: 527 [40100/50000 (80%)]  \tLoss:   90.477188\trec:   62.477295\tkl:   27.999889\n",
            "====> Epoch: 527 Average train loss: 90.0212\n",
            "====> Validation set loss: 92.8155\n",
            "====> Validation set kl: 27.5664\n",
            "Epoch: 528 [  100/50000 ( 0%)]  \tLoss:   91.404015\trec:   63.488895\tkl:   27.915117\n",
            "Epoch: 528 [10100/50000 (20%)]  \tLoss:   86.611343\trec:   59.701767\tkl:   26.909580\n",
            "Epoch: 528 [20100/50000 (40%)]  \tLoss:   89.983505\trec:   62.731071\tkl:   27.252432\n",
            "Epoch: 528 [30100/50000 (60%)]  \tLoss:   92.300262\trec:   64.781075\tkl:   27.519192\n",
            "Epoch: 528 [40100/50000 (80%)]  \tLoss:   87.699364\trec:   60.346077\tkl:   27.353285\n",
            "====> Epoch: 528 Average train loss: 90.0368\n",
            "====> Validation set loss: 92.7948\n",
            "====> Validation set kl: 27.5128\n",
            "Epoch: 529 [  100/50000 ( 0%)]  \tLoss:   96.668533\trec:   67.732635\tkl:   28.935892\n",
            "Epoch: 529 [10100/50000 (20%)]  \tLoss:   88.703995\trec:   61.491550\tkl:   27.212440\n",
            "Epoch: 529 [20100/50000 (40%)]  \tLoss:   88.695679\trec:   62.157471\tkl:   26.538218\n",
            "Epoch: 529 [30100/50000 (60%)]  \tLoss:   91.398689\trec:   63.502449\tkl:   27.896235\n",
            "Epoch: 529 [40100/50000 (80%)]  \tLoss:   90.706490\trec:   63.677620\tkl:   27.028872\n",
            "====> Epoch: 529 Average train loss: 90.0219\n",
            "====> Validation set loss: 92.7488\n",
            "====> Validation set kl: 27.3682\n",
            "Epoch: 530 [  100/50000 ( 0%)]  \tLoss:   89.169533\trec:   61.035603\tkl:   28.133923\n",
            "Epoch: 530 [10100/50000 (20%)]  \tLoss:   90.671257\trec:   63.566639\tkl:   27.104616\n",
            "Epoch: 530 [20100/50000 (40%)]  \tLoss:   88.061523\trec:   61.160530\tkl:   26.900988\n",
            "Epoch: 530 [30100/50000 (60%)]  \tLoss:   87.756088\trec:   61.485043\tkl:   26.271048\n",
            "Epoch: 530 [40100/50000 (80%)]  \tLoss:   87.700768\trec:   60.598076\tkl:   27.102692\n",
            "====> Epoch: 530 Average train loss: 90.0162\n",
            "====> Validation set loss: 92.6883\n",
            "====> Validation set kl: 27.5689\n",
            "Epoch: 531 [  100/50000 ( 0%)]  \tLoss:   89.700226\trec:   62.575966\tkl:   27.124258\n",
            "Epoch: 531 [10100/50000 (20%)]  \tLoss:   90.893135\trec:   62.367245\tkl:   28.525890\n",
            "Epoch: 531 [20100/50000 (40%)]  \tLoss:   87.118263\trec:   59.873360\tkl:   27.244907\n",
            "Epoch: 531 [30100/50000 (60%)]  \tLoss:   86.220184\trec:   59.473255\tkl:   26.746927\n",
            "Epoch: 531 [40100/50000 (80%)]  \tLoss:   90.803047\trec:   63.188477\tkl:   27.614573\n",
            "====> Epoch: 531 Average train loss: 90.0251\n",
            "====> Validation set loss: 92.7145\n",
            "====> Validation set kl: 27.5991\n",
            "Epoch: 532 [  100/50000 ( 0%)]  \tLoss:   86.835564\trec:   60.046875\tkl:   26.788689\n",
            "Epoch: 532 [10100/50000 (20%)]  \tLoss:   87.818375\trec:   60.399158\tkl:   27.419216\n",
            "Epoch: 532 [20100/50000 (40%)]  \tLoss:   90.488243\trec:   63.301884\tkl:   27.186352\n",
            "Epoch: 532 [30100/50000 (60%)]  \tLoss:   82.730820\trec:   57.285294\tkl:   25.445526\n",
            "Epoch: 532 [40100/50000 (80%)]  \tLoss:   90.072479\trec:   62.926880\tkl:   27.145596\n",
            "====> Epoch: 532 Average train loss: 90.0311\n",
            "====> Validation set loss: 92.7383\n",
            "====> Validation set kl: 27.3116\n",
            "Epoch: 533 [  100/50000 ( 0%)]  \tLoss:   91.771675\trec:   63.840584\tkl:   27.931087\n",
            "Epoch: 533 [10100/50000 (20%)]  \tLoss:   92.074966\trec:   63.602276\tkl:   28.472692\n",
            "Epoch: 533 [20100/50000 (40%)]  \tLoss:   90.805740\trec:   63.081142\tkl:   27.724594\n",
            "Epoch: 533 [30100/50000 (60%)]  \tLoss:   91.496216\trec:   62.819851\tkl:   28.676369\n",
            "Epoch: 533 [40100/50000 (80%)]  \tLoss:   89.430138\trec:   62.610241\tkl:   26.819893\n",
            "====> Epoch: 533 Average train loss: 90.0146\n",
            "====> Validation set loss: 92.7906\n",
            "====> Validation set kl: 27.3643\n",
            "Epoch: 534 [  100/50000 ( 0%)]  \tLoss:   92.185966\trec:   64.025749\tkl:   28.160213\n",
            "Epoch: 534 [10100/50000 (20%)]  \tLoss:   91.936951\trec:   64.327644\tkl:   27.609304\n",
            "Epoch: 534 [20100/50000 (40%)]  \tLoss:   88.287720\trec:   61.184559\tkl:   27.103167\n",
            "Epoch: 534 [30100/50000 (60%)]  \tLoss:   90.111755\trec:   62.492729\tkl:   27.619028\n",
            "Epoch: 534 [40100/50000 (80%)]  \tLoss:   87.781715\trec:   60.459705\tkl:   27.322016\n",
            "====> Epoch: 534 Average train loss: 89.9984\n",
            "====> Validation set loss: 92.7416\n",
            "====> Validation set kl: 27.3528\n",
            "Epoch: 535 [  100/50000 ( 0%)]  \tLoss:   92.484062\trec:   65.494637\tkl:   26.989418\n",
            "Epoch: 535 [10100/50000 (20%)]  \tLoss:   90.675606\trec:   62.879551\tkl:   27.796049\n",
            "Epoch: 535 [20100/50000 (40%)]  \tLoss:   90.206818\trec:   62.819656\tkl:   27.387156\n",
            "Epoch: 535 [30100/50000 (60%)]  \tLoss:   92.880898\trec:   64.196159\tkl:   28.684736\n",
            "Epoch: 535 [40100/50000 (80%)]  \tLoss:   87.431541\trec:   59.873718\tkl:   27.557819\n",
            "====> Epoch: 535 Average train loss: 89.9758\n",
            "====> Validation set loss: 92.6561\n",
            "====> Validation set kl: 27.4815\n",
            "Epoch: 536 [  100/50000 ( 0%)]  \tLoss:   89.889381\trec:   61.860741\tkl:   28.028639\n",
            "Epoch: 536 [10100/50000 (20%)]  \tLoss:   95.115028\trec:   67.292938\tkl:   27.822086\n",
            "Epoch: 536 [20100/50000 (40%)]  \tLoss:   87.459366\trec:   61.191929\tkl:   26.267435\n",
            "Epoch: 536 [30100/50000 (60%)]  \tLoss:   85.182526\trec:   59.001343\tkl:   26.181183\n",
            "Epoch: 536 [40100/50000 (80%)]  \tLoss:   90.228516\trec:   63.039677\tkl:   27.188833\n",
            "====> Epoch: 536 Average train loss: 89.9941\n",
            "====> Validation set loss: 92.6356\n",
            "====> Validation set kl: 27.6184\n",
            "Epoch: 537 [  100/50000 ( 0%)]  \tLoss:   87.174355\trec:   60.088448\tkl:   27.085905\n",
            "Epoch: 537 [10100/50000 (20%)]  \tLoss:   87.661385\trec:   60.047363\tkl:   27.614027\n",
            "Epoch: 537 [20100/50000 (40%)]  \tLoss:   85.918327\trec:   59.436523\tkl:   26.481804\n",
            "Epoch: 537 [30100/50000 (60%)]  \tLoss:   90.854019\trec:   63.150959\tkl:   27.703058\n",
            "Epoch: 537 [40100/50000 (80%)]  \tLoss:   94.330368\trec:   65.476631\tkl:   28.853735\n",
            "====> Epoch: 537 Average train loss: 89.9975\n",
            "====> Validation set loss: 92.7509\n",
            "====> Validation set kl: 27.3825\n",
            "Epoch: 538 [  100/50000 ( 0%)]  \tLoss:   87.685623\trec:   60.271927\tkl:   27.413700\n",
            "Epoch: 538 [10100/50000 (20%)]  \tLoss:   94.304024\trec:   66.012032\tkl:   28.291986\n",
            "Epoch: 538 [20100/50000 (40%)]  \tLoss:   88.950790\trec:   61.667217\tkl:   27.283573\n",
            "Epoch: 538 [30100/50000 (60%)]  \tLoss:   90.322647\trec:   62.560635\tkl:   27.762011\n",
            "Epoch: 538 [40100/50000 (80%)]  \tLoss:   87.527237\trec:   59.322502\tkl:   28.204733\n",
            "====> Epoch: 538 Average train loss: 89.9748\n",
            "====> Validation set loss: 92.6891\n",
            "====> Validation set kl: 27.6616\n",
            "Epoch: 539 [  100/50000 ( 0%)]  \tLoss:   91.733452\trec:   63.679588\tkl:   28.053867\n",
            "Epoch: 539 [10100/50000 (20%)]  \tLoss:   90.391342\trec:   63.536873\tkl:   26.854467\n",
            "Epoch: 539 [20100/50000 (40%)]  \tLoss:   87.311462\trec:   59.946590\tkl:   27.364868\n",
            "Epoch: 539 [30100/50000 (60%)]  \tLoss:   93.168472\trec:   64.967247\tkl:   28.201225\n",
            "Epoch: 539 [40100/50000 (80%)]  \tLoss:   90.398239\trec:   62.651531\tkl:   27.746706\n",
            "====> Epoch: 539 Average train loss: 89.9971\n",
            "====> Validation set loss: 92.7159\n",
            "====> Validation set kl: 27.7755\n",
            "Epoch: 540 [  100/50000 ( 0%)]  \tLoss:   85.656960\trec:   58.840420\tkl:   26.816540\n",
            "Epoch: 540 [10100/50000 (20%)]  \tLoss:   90.991051\trec:   63.146496\tkl:   27.844551\n",
            "Epoch: 540 [20100/50000 (40%)]  \tLoss:   87.511658\trec:   59.357742\tkl:   28.153917\n",
            "Epoch: 540 [30100/50000 (60%)]  \tLoss:   87.775543\trec:   61.165615\tkl:   26.609936\n",
            "Epoch: 540 [40100/50000 (80%)]  \tLoss:   86.720779\trec:   59.762741\tkl:   26.958031\n",
            "====> Epoch: 540 Average train loss: 89.9751\n",
            "====> Validation set loss: 92.7025\n",
            "====> Validation set kl: 27.6210\n",
            "Epoch: 541 [  100/50000 ( 0%)]  \tLoss:   89.891365\trec:   62.417313\tkl:   27.474056\n",
            "Epoch: 541 [10100/50000 (20%)]  \tLoss:   89.062431\trec:   61.449814\tkl:   27.612614\n",
            "Epoch: 541 [20100/50000 (40%)]  \tLoss:   91.233757\trec:   63.666039\tkl:   27.567719\n",
            "Epoch: 541 [30100/50000 (60%)]  \tLoss:   91.313560\trec:   63.974922\tkl:   27.338640\n",
            "Epoch: 541 [40100/50000 (80%)]  \tLoss:   89.208687\trec:   62.666298\tkl:   26.542387\n",
            "====> Epoch: 541 Average train loss: 89.9594\n",
            "====> Validation set loss: 92.6426\n",
            "====> Validation set kl: 27.5442\n",
            "Epoch: 542 [  100/50000 ( 0%)]  \tLoss:   89.880867\trec:   62.994438\tkl:   26.886433\n",
            "Epoch: 542 [10100/50000 (20%)]  \tLoss:   85.996544\trec:   58.726250\tkl:   27.270298\n",
            "Epoch: 542 [20100/50000 (40%)]  \tLoss:   92.157631\trec:   64.137901\tkl:   28.019737\n",
            "Epoch: 542 [30100/50000 (60%)]  \tLoss:   91.513855\trec:   63.579868\tkl:   27.933989\n",
            "Epoch: 542 [40100/50000 (80%)]  \tLoss:   86.735718\trec:   60.085854\tkl:   26.649868\n",
            "====> Epoch: 542 Average train loss: 89.9888\n",
            "====> Validation set loss: 92.7701\n",
            "====> Validation set kl: 27.2948\n",
            "Epoch: 543 [  100/50000 ( 0%)]  \tLoss:   95.127914\trec:   67.146515\tkl:   27.981398\n",
            "Epoch: 543 [10100/50000 (20%)]  \tLoss:   87.815582\trec:   60.486473\tkl:   27.329115\n",
            "Epoch: 543 [20100/50000 (40%)]  \tLoss:   91.572281\trec:   63.316601\tkl:   28.255678\n",
            "Epoch: 543 [30100/50000 (60%)]  \tLoss:   90.527573\trec:   63.423309\tkl:   27.104261\n",
            "Epoch: 543 [40100/50000 (80%)]  \tLoss:   92.349709\trec:   64.351761\tkl:   27.997944\n",
            "====> Epoch: 543 Average train loss: 89.9468\n",
            "====> Validation set loss: 92.6983\n",
            "====> Validation set kl: 27.6219\n",
            "Epoch: 544 [  100/50000 ( 0%)]  \tLoss:   91.195007\trec:   62.890839\tkl:   28.304169\n",
            "Epoch: 544 [10100/50000 (20%)]  \tLoss:   93.438766\trec:   64.643364\tkl:   28.795406\n",
            "Epoch: 544 [20100/50000 (40%)]  \tLoss:   91.647247\trec:   63.545986\tkl:   28.101259\n",
            "Epoch: 544 [30100/50000 (60%)]  \tLoss:   89.167282\trec:   62.116970\tkl:   27.050312\n",
            "Epoch: 544 [40100/50000 (80%)]  \tLoss:   89.179825\trec:   61.279438\tkl:   27.900391\n",
            "====> Epoch: 544 Average train loss: 89.9359\n",
            "====> Validation set loss: 92.6351\n",
            "====> Validation set kl: 27.4503\n",
            "Epoch: 545 [  100/50000 ( 0%)]  \tLoss:   84.375000\trec:   58.327305\tkl:   26.047689\n",
            "Epoch: 545 [10100/50000 (20%)]  \tLoss:   86.932671\trec:   60.254730\tkl:   26.677944\n",
            "Epoch: 545 [20100/50000 (40%)]  \tLoss:   89.313248\trec:   62.379559\tkl:   26.933691\n",
            "Epoch: 545 [30100/50000 (60%)]  \tLoss:   90.305428\trec:   62.963505\tkl:   27.341927\n",
            "Epoch: 545 [40100/50000 (80%)]  \tLoss:   89.910957\trec:   61.554180\tkl:   28.356779\n",
            "====> Epoch: 545 Average train loss: 89.9606\n",
            "====> Validation set loss: 92.7241\n",
            "====> Validation set kl: 27.5394\n",
            "Epoch: 546 [  100/50000 ( 0%)]  \tLoss:   86.450134\trec:   58.861717\tkl:   27.588417\n",
            "Epoch: 546 [10100/50000 (20%)]  \tLoss:   91.053825\trec:   62.499393\tkl:   28.554434\n",
            "Epoch: 546 [20100/50000 (40%)]  \tLoss:   91.495445\trec:   64.245972\tkl:   27.249477\n",
            "Epoch: 546 [30100/50000 (60%)]  \tLoss:   94.218750\trec:   65.264595\tkl:   28.954145\n",
            "Epoch: 546 [40100/50000 (80%)]  \tLoss:   91.754745\trec:   64.364746\tkl:   27.389999\n",
            "====> Epoch: 546 Average train loss: 89.9398\n",
            "====> Validation set loss: 92.6073\n",
            "====> Validation set kl: 27.2097\n",
            "Epoch: 547 [  100/50000 ( 0%)]  \tLoss:   86.335548\trec:   59.500778\tkl:   26.834768\n",
            "Epoch: 547 [10100/50000 (20%)]  \tLoss:   95.917847\trec:   67.009712\tkl:   28.908144\n",
            "Epoch: 547 [20100/50000 (40%)]  \tLoss:   88.726044\trec:   60.992050\tkl:   27.733992\n",
            "Epoch: 547 [30100/50000 (60%)]  \tLoss:   87.445412\trec:   60.439003\tkl:   27.006405\n",
            "Epoch: 547 [40100/50000 (80%)]  \tLoss:   90.325195\trec:   62.834671\tkl:   27.490526\n",
            "====> Epoch: 547 Average train loss: 89.9409\n",
            "====> Validation set loss: 92.5606\n",
            "====> Validation set kl: 27.4817\n",
            "Epoch: 548 [  100/50000 ( 0%)]  \tLoss:   86.684914\trec:   59.331482\tkl:   27.353428\n",
            "Epoch: 548 [10100/50000 (20%)]  \tLoss:   93.156532\trec:   65.683784\tkl:   27.472746\n",
            "Epoch: 548 [20100/50000 (40%)]  \tLoss:   85.602692\trec:   59.045185\tkl:   26.557507\n",
            "Epoch: 548 [30100/50000 (60%)]  \tLoss:   94.241875\trec:   65.821243\tkl:   28.420631\n",
            "Epoch: 548 [40100/50000 (80%)]  \tLoss:   91.776840\trec:   63.351883\tkl:   28.424957\n",
            "====> Epoch: 548 Average train loss: 89.9444\n",
            "====> Validation set loss: 92.7611\n",
            "====> Validation set kl: 27.5323\n",
            "Epoch: 549 [  100/50000 ( 0%)]  \tLoss:   89.978729\trec:   62.248699\tkl:   27.730034\n",
            "Epoch: 549 [10100/50000 (20%)]  \tLoss:   86.618172\trec:   59.527840\tkl:   27.090334\n",
            "Epoch: 549 [20100/50000 (40%)]  \tLoss:   84.526794\trec:   57.734657\tkl:   26.792141\n",
            "Epoch: 549 [30100/50000 (60%)]  \tLoss:   91.652863\trec:   63.985229\tkl:   27.667631\n",
            "Epoch: 549 [40100/50000 (80%)]  \tLoss:   87.716232\trec:   60.078823\tkl:   27.637402\n",
            "====> Epoch: 549 Average train loss: 89.9364\n",
            "====> Validation set loss: 92.7112\n",
            "====> Validation set kl: 27.5270\n",
            "Epoch: 550 [  100/50000 ( 0%)]  \tLoss:   92.213188\trec:   64.662201\tkl:   27.550991\n",
            "Epoch: 550 [10100/50000 (20%)]  \tLoss:   89.615593\trec:   61.902683\tkl:   27.712910\n",
            "Epoch: 550 [20100/50000 (40%)]  \tLoss:   88.746864\trec:   61.354462\tkl:   27.392403\n",
            "Epoch: 550 [30100/50000 (60%)]  \tLoss:   88.346626\trec:   61.010498\tkl:   27.336132\n",
            "Epoch: 550 [40100/50000 (80%)]  \tLoss:   93.081726\trec:   64.937920\tkl:   28.143808\n",
            "====> Epoch: 550 Average train loss: 89.9195\n",
            "====> Validation set loss: 92.7299\n",
            "====> Validation set kl: 27.1908\n",
            "Epoch: 551 [  100/50000 ( 0%)]  \tLoss:   91.059517\trec:   63.679501\tkl:   27.380022\n",
            "Epoch: 551 [10100/50000 (20%)]  \tLoss:   92.783966\trec:   64.306458\tkl:   28.477501\n",
            "Epoch: 551 [20100/50000 (40%)]  \tLoss:   90.345352\trec:   61.912754\tkl:   28.432596\n",
            "Epoch: 551 [30100/50000 (60%)]  \tLoss:   94.452286\trec:   66.621017\tkl:   27.831272\n",
            "Epoch: 551 [40100/50000 (80%)]  \tLoss:   94.072723\trec:   65.719582\tkl:   28.353142\n",
            "====> Epoch: 551 Average train loss: 89.9202\n",
            "====> Validation set loss: 92.6582\n",
            "====> Validation set kl: 27.5479\n",
            "Epoch: 552 [  100/50000 ( 0%)]  \tLoss:   90.476387\trec:   62.838398\tkl:   27.637985\n",
            "Epoch: 552 [10100/50000 (20%)]  \tLoss:   88.688927\trec:   60.633770\tkl:   28.055153\n",
            "Epoch: 552 [20100/50000 (40%)]  \tLoss:   93.767517\trec:   64.891937\tkl:   28.875584\n",
            "Epoch: 552 [30100/50000 (60%)]  \tLoss:   93.598244\trec:   65.510246\tkl:   28.087992\n",
            "Epoch: 552 [40100/50000 (80%)]  \tLoss:   90.078522\trec:   62.265400\tkl:   27.813124\n",
            "====> Epoch: 552 Average train loss: 89.9186\n",
            "====> Validation set loss: 92.6921\n",
            "====> Validation set kl: 27.4377\n",
            "Epoch: 553 [  100/50000 ( 0%)]  \tLoss:   90.559021\trec:   63.034492\tkl:   27.524530\n",
            "Epoch: 553 [10100/50000 (20%)]  \tLoss:   90.449821\trec:   63.594540\tkl:   26.855280\n",
            "Epoch: 553 [20100/50000 (40%)]  \tLoss:   90.803581\trec:   62.945705\tkl:   27.857872\n",
            "Epoch: 553 [30100/50000 (60%)]  \tLoss:   91.531372\trec:   63.926514\tkl:   27.604862\n",
            "Epoch: 553 [40100/50000 (80%)]  \tLoss:   92.071968\trec:   64.132935\tkl:   27.939028\n",
            "====> Epoch: 553 Average train loss: 89.9044\n",
            "====> Validation set loss: 92.6958\n",
            "====> Validation set kl: 27.5582\n",
            "Epoch: 554 [  100/50000 ( 0%)]  \tLoss:   88.556160\trec:   61.470360\tkl:   27.085802\n",
            "Epoch: 554 [10100/50000 (20%)]  \tLoss:   85.975929\trec:   60.061768\tkl:   25.914160\n",
            "Epoch: 554 [20100/50000 (40%)]  \tLoss:   91.665054\trec:   64.266212\tkl:   27.398844\n",
            "Epoch: 554 [30100/50000 (60%)]  \tLoss:   89.022911\trec:   61.234646\tkl:   27.788265\n",
            "Epoch: 554 [40100/50000 (80%)]  \tLoss:   89.834450\trec:   62.634933\tkl:   27.199516\n",
            "====> Epoch: 554 Average train loss: 89.9200\n",
            "====> Validation set loss: 92.7637\n",
            "====> Validation set kl: 27.8220\n",
            "Epoch: 555 [  100/50000 ( 0%)]  \tLoss:   88.663620\trec:   61.126209\tkl:   27.537411\n",
            "Epoch: 555 [10100/50000 (20%)]  \tLoss:   90.068810\trec:   62.535423\tkl:   27.533388\n",
            "Epoch: 555 [20100/50000 (40%)]  \tLoss:   91.493439\trec:   62.920078\tkl:   28.573355\n",
            "Epoch: 555 [30100/50000 (60%)]  \tLoss:   93.017365\trec:   64.854340\tkl:   28.163021\n",
            "Epoch: 555 [40100/50000 (80%)]  \tLoss:   89.343468\trec:   61.868309\tkl:   27.475155\n",
            "====> Epoch: 555 Average train loss: 89.9133\n",
            "====> Validation set loss: 92.7603\n",
            "====> Validation set kl: 27.5755\n",
            "Epoch: 556 [  100/50000 ( 0%)]  \tLoss:   90.548965\trec:   62.562370\tkl:   27.986589\n",
            "Epoch: 556 [10100/50000 (20%)]  \tLoss:   84.797882\trec:   58.430977\tkl:   26.366905\n",
            "Epoch: 556 [20100/50000 (40%)]  \tLoss:   88.204842\trec:   60.755077\tkl:   27.449762\n",
            "Epoch: 556 [30100/50000 (60%)]  \tLoss:   88.375473\trec:   60.557030\tkl:   27.818449\n",
            "Epoch: 556 [40100/50000 (80%)]  \tLoss:   88.767685\trec:   61.383984\tkl:   27.383701\n",
            "====> Epoch: 556 Average train loss: 89.9160\n",
            "====> Validation set loss: 92.7198\n",
            "====> Validation set kl: 27.4948\n",
            "Epoch: 557 [  100/50000 ( 0%)]  \tLoss:   87.843903\trec:   61.300213\tkl:   26.543694\n",
            "Epoch: 557 [10100/50000 (20%)]  \tLoss:   89.316032\trec:   61.754639\tkl:   27.561401\n",
            "Epoch: 557 [20100/50000 (40%)]  \tLoss:   87.802124\trec:   60.448139\tkl:   27.353991\n",
            "Epoch: 557 [30100/50000 (60%)]  \tLoss:   85.100235\trec:   58.447998\tkl:   26.652233\n",
            "Epoch: 557 [40100/50000 (80%)]  \tLoss:   86.483658\trec:   59.998066\tkl:   26.485592\n",
            "====> Epoch: 557 Average train loss: 89.9051\n",
            "====> Validation set loss: 92.6254\n",
            "====> Validation set kl: 27.4944\n",
            "Epoch: 558 [  100/50000 ( 0%)]  \tLoss:   89.264069\trec:   62.026600\tkl:   27.237473\n",
            "Epoch: 558 [10100/50000 (20%)]  \tLoss:   93.602440\trec:   65.472755\tkl:   28.129686\n",
            "Epoch: 558 [20100/50000 (40%)]  \tLoss:   91.548912\trec:   62.930042\tkl:   28.618874\n",
            "Epoch: 558 [30100/50000 (60%)]  \tLoss:   88.666862\trec:   61.373699\tkl:   27.293163\n",
            "Epoch: 558 [40100/50000 (80%)]  \tLoss:   90.316483\trec:   63.744610\tkl:   26.571869\n",
            "====> Epoch: 558 Average train loss: 89.9025\n",
            "====> Validation set loss: 92.6238\n",
            "====> Validation set kl: 27.5142\n",
            "Epoch: 559 [  100/50000 ( 0%)]  \tLoss:   87.169083\trec:   59.835651\tkl:   27.333422\n",
            "Epoch: 559 [10100/50000 (20%)]  \tLoss:   87.236603\trec:   59.582436\tkl:   27.654160\n",
            "Epoch: 559 [20100/50000 (40%)]  \tLoss:   89.039764\trec:   62.188446\tkl:   26.851318\n",
            "Epoch: 559 [30100/50000 (60%)]  \tLoss:   92.756462\trec:   64.426262\tkl:   28.330194\n",
            "Epoch: 559 [40100/50000 (80%)]  \tLoss:   91.927979\trec:   63.889812\tkl:   28.038166\n",
            "====> Epoch: 559 Average train loss: 89.8996\n",
            "====> Validation set loss: 92.6174\n",
            "====> Validation set kl: 27.4965\n",
            "Epoch: 560 [  100/50000 ( 0%)]  \tLoss:   90.490509\trec:   62.726849\tkl:   27.763651\n",
            "Epoch: 560 [10100/50000 (20%)]  \tLoss:   88.552193\trec:   61.416054\tkl:   27.136143\n",
            "Epoch: 560 [20100/50000 (40%)]  \tLoss:   91.916382\trec:   63.539558\tkl:   28.376823\n",
            "Epoch: 560 [30100/50000 (60%)]  \tLoss:   92.616661\trec:   64.660149\tkl:   27.956509\n",
            "Epoch: 560 [40100/50000 (80%)]  \tLoss:   90.202965\trec:   63.997280\tkl:   26.205685\n",
            "====> Epoch: 560 Average train loss: 89.8881\n",
            "====> Validation set loss: 92.5753\n",
            "====> Validation set kl: 27.4979\n",
            "Epoch: 561 [  100/50000 ( 0%)]  \tLoss:   87.782417\trec:   61.374226\tkl:   26.408188\n",
            "Epoch: 561 [10100/50000 (20%)]  \tLoss:   87.043808\trec:   60.508652\tkl:   26.535152\n",
            "Epoch: 561 [20100/50000 (40%)]  \tLoss:   87.496689\trec:   60.666306\tkl:   26.830383\n",
            "Epoch: 561 [30100/50000 (60%)]  \tLoss:   84.111679\trec:   58.065693\tkl:   26.045982\n",
            "Epoch: 561 [40100/50000 (80%)]  \tLoss:   88.310402\trec:   61.434822\tkl:   26.875572\n",
            "====> Epoch: 561 Average train loss: 89.8994\n",
            "====> Validation set loss: 92.5288\n",
            "====> Validation set kl: 27.5357\n",
            "Epoch: 562 [  100/50000 ( 0%)]  \tLoss:   85.942841\trec:   58.901775\tkl:   27.041063\n",
            "Epoch: 562 [10100/50000 (20%)]  \tLoss:   89.282059\trec:   61.607918\tkl:   27.674143\n",
            "Epoch: 562 [20100/50000 (40%)]  \tLoss:   91.593903\trec:   64.517654\tkl:   27.076244\n",
            "Epoch: 562 [30100/50000 (60%)]  \tLoss:   93.048134\trec:   65.197121\tkl:   27.851017\n",
            "Epoch: 562 [40100/50000 (80%)]  \tLoss:   90.071342\trec:   62.769638\tkl:   27.301708\n",
            "====> Epoch: 562 Average train loss: 89.8774\n",
            "====> Validation set loss: 92.5839\n",
            "====> Validation set kl: 27.5770\n",
            "Epoch: 563 [  100/50000 ( 0%)]  \tLoss:   88.225182\trec:   61.347107\tkl:   26.878075\n",
            "Epoch: 563 [10100/50000 (20%)]  \tLoss:   90.634537\trec:   63.381481\tkl:   27.253056\n",
            "Epoch: 563 [20100/50000 (40%)]  \tLoss:   95.103317\trec:   66.728210\tkl:   28.375107\n",
            "Epoch: 563 [30100/50000 (60%)]  \tLoss:   92.036102\trec:   63.241756\tkl:   28.794342\n",
            "Epoch: 563 [40100/50000 (80%)]  \tLoss:   91.140289\trec:   63.606472\tkl:   27.533817\n",
            "====> Epoch: 563 Average train loss: 89.8864\n",
            "====> Validation set loss: 92.7055\n",
            "====> Validation set kl: 27.6631\n",
            "Epoch: 564 [  100/50000 ( 0%)]  \tLoss:   90.560951\trec:   63.254795\tkl:   27.306164\n",
            "Epoch: 564 [10100/50000 (20%)]  \tLoss:   91.703178\trec:   64.315155\tkl:   27.388031\n",
            "Epoch: 564 [20100/50000 (40%)]  \tLoss:   91.941635\trec:   63.749947\tkl:   28.191698\n",
            "Epoch: 564 [30100/50000 (60%)]  \tLoss:   87.654297\trec:   60.217968\tkl:   27.436325\n",
            "Epoch: 564 [40100/50000 (80%)]  \tLoss:   94.670181\trec:   66.549614\tkl:   28.120567\n",
            "====> Epoch: 564 Average train loss: 89.8599\n",
            "====> Validation set loss: 92.6409\n",
            "====> Validation set kl: 27.6053\n",
            "Epoch: 565 [  100/50000 ( 0%)]  \tLoss:   89.770065\trec:   63.109257\tkl:   26.660807\n",
            "Epoch: 565 [10100/50000 (20%)]  \tLoss:   91.149628\trec:   62.395111\tkl:   28.754517\n",
            "Epoch: 565 [20100/50000 (40%)]  \tLoss:   91.129395\trec:   62.901611\tkl:   28.227779\n",
            "Epoch: 565 [30100/50000 (60%)]  \tLoss:   88.764618\trec:   61.923309\tkl:   26.841311\n",
            "Epoch: 565 [40100/50000 (80%)]  \tLoss:   91.379150\trec:   63.431171\tkl:   27.947975\n",
            "====> Epoch: 565 Average train loss: 89.8641\n",
            "====> Validation set loss: 92.6723\n",
            "====> Validation set kl: 27.3384\n",
            "Epoch: 566 [  100/50000 ( 0%)]  \tLoss:   88.284843\trec:   62.071804\tkl:   26.213036\n",
            "Epoch: 566 [10100/50000 (20%)]  \tLoss:   89.810913\trec:   62.469612\tkl:   27.341303\n",
            "Epoch: 566 [20100/50000 (40%)]  \tLoss:   88.711792\trec:   61.465305\tkl:   27.246490\n",
            "Epoch: 566 [30100/50000 (60%)]  \tLoss:   90.640663\trec:   63.155186\tkl:   27.485483\n",
            "Epoch: 566 [40100/50000 (80%)]  \tLoss:   88.660202\trec:   62.100677\tkl:   26.559528\n",
            "====> Epoch: 566 Average train loss: 89.8685\n",
            "====> Validation set loss: 92.6217\n",
            "====> Validation set kl: 27.4402\n",
            "Epoch: 567 [  100/50000 ( 0%)]  \tLoss:   87.539429\trec:   60.590801\tkl:   26.948629\n",
            "Epoch: 567 [10100/50000 (20%)]  \tLoss:   90.938774\trec:   62.734989\tkl:   28.203791\n",
            "Epoch: 567 [20100/50000 (40%)]  \tLoss:   87.773071\trec:   60.769939\tkl:   27.003132\n",
            "Epoch: 567 [30100/50000 (60%)]  \tLoss:   91.826225\trec:   63.667381\tkl:   28.158850\n",
            "Epoch: 567 [40100/50000 (80%)]  \tLoss:   92.705780\trec:   64.258377\tkl:   28.447405\n",
            "====> Epoch: 567 Average train loss: 89.8795\n",
            "====> Validation set loss: 92.5809\n",
            "====> Validation set kl: 27.4579\n",
            "Epoch: 568 [  100/50000 ( 0%)]  \tLoss:   90.645157\trec:   62.460388\tkl:   28.184771\n",
            "Epoch: 568 [10100/50000 (20%)]  \tLoss:   94.112442\trec:   65.546707\tkl:   28.565737\n",
            "Epoch: 568 [20100/50000 (40%)]  \tLoss:   89.276764\trec:   62.095604\tkl:   27.181160\n",
            "Epoch: 568 [30100/50000 (60%)]  \tLoss:   94.794647\trec:   67.212646\tkl:   27.581993\n",
            "Epoch: 568 [40100/50000 (80%)]  \tLoss:   89.012794\trec:   61.297302\tkl:   27.715485\n",
            "====> Epoch: 568 Average train loss: 89.8375\n",
            "====> Validation set loss: 92.6084\n",
            "====> Validation set kl: 27.6629\n",
            "Epoch: 569 [  100/50000 ( 0%)]  \tLoss:   90.181679\trec:   62.196712\tkl:   27.984970\n",
            "Epoch: 569 [10100/50000 (20%)]  \tLoss:   91.087631\trec:   63.522137\tkl:   27.565498\n",
            "Epoch: 569 [20100/50000 (40%)]  \tLoss:   91.068985\trec:   64.321754\tkl:   26.747221\n",
            "Epoch: 569 [30100/50000 (60%)]  \tLoss:   88.807091\trec:   60.464207\tkl:   28.342875\n",
            "Epoch: 569 [40100/50000 (80%)]  \tLoss:   90.045792\trec:   62.353516\tkl:   27.692272\n",
            "====> Epoch: 569 Average train loss: 89.8619\n",
            "====> Validation set loss: 92.6672\n",
            "====> Validation set kl: 27.3570\n",
            "Epoch: 570 [  100/50000 ( 0%)]  \tLoss:   85.461769\trec:   58.771904\tkl:   26.689865\n",
            "Epoch: 570 [10100/50000 (20%)]  \tLoss:   91.317902\trec:   62.692528\tkl:   28.625370\n",
            "Epoch: 570 [20100/50000 (40%)]  \tLoss:   90.342461\trec:   63.064873\tkl:   27.277584\n",
            "Epoch: 570 [30100/50000 (60%)]  \tLoss:   91.555840\trec:   63.716335\tkl:   27.839497\n",
            "Epoch: 570 [40100/50000 (80%)]  \tLoss:   86.995064\trec:   59.969666\tkl:   27.025398\n",
            "====> Epoch: 570 Average train loss: 89.8361\n",
            "====> Validation set loss: 92.6565\n",
            "====> Validation set kl: 27.5971\n",
            "Epoch: 571 [  100/50000 ( 0%)]  \tLoss:   91.270370\trec:   63.096123\tkl:   28.174248\n",
            "Epoch: 571 [10100/50000 (20%)]  \tLoss:   90.619370\trec:   63.069050\tkl:   27.550323\n",
            "Epoch: 571 [20100/50000 (40%)]  \tLoss:   89.497574\trec:   61.160164\tkl:   28.337416\n",
            "Epoch: 571 [30100/50000 (60%)]  \tLoss:   88.853981\trec:   61.751102\tkl:   27.102880\n",
            "Epoch: 571 [40100/50000 (80%)]  \tLoss:   91.845360\trec:   63.886826\tkl:   27.958536\n",
            "====> Epoch: 571 Average train loss: 89.8472\n",
            "====> Validation set loss: 92.6929\n",
            "====> Validation set kl: 27.6448\n",
            "Epoch: 572 [  100/50000 ( 0%)]  \tLoss:   84.925346\trec:   58.703304\tkl:   26.222040\n",
            "Epoch: 572 [10100/50000 (20%)]  \tLoss:   88.372589\trec:   60.564999\tkl:   27.807585\n",
            "Epoch: 572 [20100/50000 (40%)]  \tLoss:   85.722908\trec:   58.253948\tkl:   27.468960\n",
            "Epoch: 572 [30100/50000 (60%)]  \tLoss:   88.164474\trec:   61.971546\tkl:   26.192928\n",
            "Epoch: 572 [40100/50000 (80%)]  \tLoss:   89.320465\trec:   61.674862\tkl:   27.645599\n",
            "====> Epoch: 572 Average train loss: 89.8453\n",
            "====> Validation set loss: 92.6215\n",
            "====> Validation set kl: 27.5742\n",
            "Epoch: 573 [  100/50000 ( 0%)]  \tLoss:   90.229080\trec:   62.103352\tkl:   28.125727\n",
            "Epoch: 573 [10100/50000 (20%)]  \tLoss:   90.902657\trec:   63.885918\tkl:   27.016743\n",
            "Epoch: 573 [20100/50000 (40%)]  \tLoss:   89.831093\trec:   61.891132\tkl:   27.939955\n",
            "Epoch: 573 [30100/50000 (60%)]  \tLoss:   86.170387\trec:   59.907158\tkl:   26.263237\n",
            "Epoch: 573 [40100/50000 (80%)]  \tLoss:   88.354668\trec:   61.588818\tkl:   26.765848\n",
            "====> Epoch: 573 Average train loss: 89.8287\n",
            "====> Validation set loss: 92.6511\n",
            "====> Validation set kl: 27.4533\n",
            "Epoch: 574 [  100/50000 ( 0%)]  \tLoss:   87.633087\trec:   60.077061\tkl:   27.556030\n",
            "Epoch: 574 [10100/50000 (20%)]  \tLoss:   90.168983\trec:   61.602821\tkl:   28.566166\n",
            "Epoch: 574 [20100/50000 (40%)]  \tLoss:   87.436363\trec:   60.137520\tkl:   27.298841\n",
            "Epoch: 574 [30100/50000 (60%)]  \tLoss:   90.021797\trec:   62.281963\tkl:   27.739838\n",
            "Epoch: 574 [40100/50000 (80%)]  \tLoss:   92.049530\trec:   63.549744\tkl:   28.499783\n",
            "====> Epoch: 574 Average train loss: 89.8302\n",
            "====> Validation set loss: 92.6984\n",
            "====> Validation set kl: 27.4865\n",
            "Epoch: 575 [  100/50000 ( 0%)]  \tLoss:   89.756538\trec:   61.442951\tkl:   28.313589\n",
            "Epoch: 575 [10100/50000 (20%)]  \tLoss:   86.946823\trec:   60.572109\tkl:   26.374716\n",
            "Epoch: 575 [20100/50000 (40%)]  \tLoss:   87.843552\trec:   60.490555\tkl:   27.353003\n",
            "Epoch: 575 [30100/50000 (60%)]  \tLoss:   90.290321\trec:   62.974445\tkl:   27.315876\n",
            "Epoch: 575 [40100/50000 (80%)]  \tLoss:   92.935722\trec:   64.270699\tkl:   28.665018\n",
            "====> Epoch: 575 Average train loss: 89.8236\n",
            "====> Validation set loss: 92.5768\n",
            "====> Validation set kl: 27.5171\n",
            "Epoch: 576 [  100/50000 ( 0%)]  \tLoss:   89.093361\trec:   61.736698\tkl:   27.356659\n",
            "Epoch: 576 [10100/50000 (20%)]  \tLoss:   87.533203\trec:   60.668915\tkl:   26.864286\n",
            "Epoch: 576 [20100/50000 (40%)]  \tLoss:   90.841248\trec:   62.600105\tkl:   28.241140\n",
            "Epoch: 576 [30100/50000 (60%)]  \tLoss:   90.312363\trec:   62.389961\tkl:   27.922403\n",
            "Epoch: 576 [40100/50000 (80%)]  \tLoss:   92.594902\trec:   64.323051\tkl:   28.271847\n",
            "====> Epoch: 576 Average train loss: 89.8202\n",
            "====> Validation set loss: 92.6113\n",
            "====> Validation set kl: 27.7964\n",
            "Epoch: 577 [  100/50000 ( 0%)]  \tLoss:   92.183357\trec:   63.750526\tkl:   28.432835\n",
            "Epoch: 577 [10100/50000 (20%)]  \tLoss:   90.130859\trec:   63.312973\tkl:   26.817888\n",
            "Epoch: 577 [20100/50000 (40%)]  \tLoss:   90.805870\trec:   63.024914\tkl:   27.780954\n",
            "Epoch: 577 [30100/50000 (60%)]  \tLoss:   95.449356\trec:   67.428680\tkl:   28.020668\n",
            "Epoch: 577 [40100/50000 (80%)]  \tLoss:   92.879578\trec:   64.892342\tkl:   27.987238\n",
            "====> Epoch: 577 Average train loss: 89.8019\n",
            "====> Validation set loss: 92.6365\n",
            "====> Validation set kl: 27.6491\n",
            "Epoch: 578 [  100/50000 ( 0%)]  \tLoss:   87.796913\trec:   59.974854\tkl:   27.822058\n",
            "Epoch: 578 [10100/50000 (20%)]  \tLoss:   88.299881\trec:   61.378685\tkl:   26.921190\n",
            "Epoch: 578 [20100/50000 (40%)]  \tLoss:   93.982674\trec:   65.251076\tkl:   28.731602\n",
            "Epoch: 578 [30100/50000 (60%)]  \tLoss:   90.497917\trec:   62.725208\tkl:   27.772707\n",
            "Epoch: 578 [40100/50000 (80%)]  \tLoss:   91.825073\trec:   63.458385\tkl:   28.366690\n",
            "====> Epoch: 578 Average train loss: 89.8207\n",
            "====> Validation set loss: 92.6218\n",
            "====> Validation set kl: 27.4167\n",
            "Epoch: 579 [  100/50000 ( 0%)]  \tLoss:   88.611015\trec:   61.106533\tkl:   27.504482\n",
            "Epoch: 579 [10100/50000 (20%)]  \tLoss:   88.609253\trec:   60.864971\tkl:   27.744282\n",
            "Epoch: 579 [20100/50000 (40%)]  \tLoss:   90.237984\trec:   61.584457\tkl:   28.653534\n",
            "Epoch: 579 [30100/50000 (60%)]  \tLoss:   87.488121\trec:   60.319363\tkl:   27.168764\n",
            "Epoch: 579 [40100/50000 (80%)]  \tLoss:   92.973907\trec:   65.178185\tkl:   27.795717\n",
            "====> Epoch: 579 Average train loss: 89.8090\n",
            "====> Validation set loss: 92.5517\n",
            "====> Validation set kl: 27.6789\n",
            "Epoch: 580 [  100/50000 ( 0%)]  \tLoss:   91.457794\trec:   63.309364\tkl:   28.148432\n",
            "Epoch: 580 [10100/50000 (20%)]  \tLoss:   87.843689\trec:   60.247116\tkl:   27.596567\n",
            "Epoch: 580 [20100/50000 (40%)]  \tLoss:   88.721367\trec:   61.023083\tkl:   27.698286\n",
            "Epoch: 580 [30100/50000 (60%)]  \tLoss:   90.485023\trec:   62.438095\tkl:   28.046936\n",
            "Epoch: 580 [40100/50000 (80%)]  \tLoss:   91.932137\trec:   63.782352\tkl:   28.149788\n",
            "====> Epoch: 580 Average train loss: 89.8174\n",
            "====> Validation set loss: 92.5747\n",
            "====> Validation set kl: 27.6479\n",
            "Epoch: 581 [  100/50000 ( 0%)]  \tLoss:   91.674919\trec:   62.182354\tkl:   29.492573\n",
            "Epoch: 581 [10100/50000 (20%)]  \tLoss:   88.219467\trec:   61.197372\tkl:   27.022095\n",
            "Epoch: 581 [20100/50000 (40%)]  \tLoss:   88.467049\trec:   60.878719\tkl:   27.588335\n",
            "Epoch: 581 [30100/50000 (60%)]  \tLoss:   88.704971\trec:   61.507748\tkl:   27.197218\n",
            "Epoch: 581 [40100/50000 (80%)]  \tLoss:   92.551071\trec:   64.409966\tkl:   28.141108\n",
            "====> Epoch: 581 Average train loss: 89.8197\n",
            "====> Validation set loss: 92.5856\n",
            "====> Validation set kl: 27.6834\n",
            "Epoch: 582 [  100/50000 ( 0%)]  \tLoss:   89.303719\trec:   61.120529\tkl:   28.183187\n",
            "Epoch: 582 [10100/50000 (20%)]  \tLoss:   91.194099\trec:   63.399178\tkl:   27.794916\n",
            "Epoch: 582 [20100/50000 (40%)]  \tLoss:   92.227165\trec:   63.657944\tkl:   28.569221\n",
            "Epoch: 582 [30100/50000 (60%)]  \tLoss:   91.423233\trec:   63.231644\tkl:   28.191589\n",
            "Epoch: 582 [40100/50000 (80%)]  \tLoss:   89.713585\trec:   62.692829\tkl:   27.020748\n",
            "====> Epoch: 582 Average train loss: 89.7977\n",
            "====> Validation set loss: 92.6499\n",
            "====> Validation set kl: 27.5876\n",
            "Epoch: 583 [  100/50000 ( 0%)]  \tLoss:   88.294846\trec:   61.431789\tkl:   26.863047\n",
            "Epoch: 583 [10100/50000 (20%)]  \tLoss:   88.105438\trec:   61.235332\tkl:   26.870104\n",
            "Epoch: 583 [20100/50000 (40%)]  \tLoss:   90.780449\trec:   62.283066\tkl:   28.497385\n",
            "Epoch: 583 [30100/50000 (60%)]  \tLoss:   88.915298\trec:   61.985630\tkl:   26.929670\n",
            "Epoch: 583 [40100/50000 (80%)]  \tLoss:   84.848419\trec:   57.661282\tkl:   27.187134\n",
            "====> Epoch: 583 Average train loss: 89.7927\n",
            "====> Validation set loss: 92.5470\n",
            "====> Validation set kl: 27.5624\n",
            "Epoch: 584 [  100/50000 ( 0%)]  \tLoss:   89.591011\trec:   61.353115\tkl:   28.237894\n",
            "Epoch: 584 [10100/50000 (20%)]  \tLoss:   94.270096\trec:   65.589806\tkl:   28.680292\n",
            "Epoch: 584 [20100/50000 (40%)]  \tLoss:   89.475807\trec:   61.687702\tkl:   27.788107\n",
            "Epoch: 584 [30100/50000 (60%)]  \tLoss:   88.287155\trec:   60.788300\tkl:   27.498854\n",
            "Epoch: 584 [40100/50000 (80%)]  \tLoss:   87.524338\trec:   60.217625\tkl:   27.306704\n",
            "====> Epoch: 584 Average train loss: 89.7899\n",
            "====> Validation set loss: 92.5960\n",
            "====> Validation set kl: 27.5956\n",
            "Epoch: 585 [  100/50000 ( 0%)]  \tLoss:   87.724266\trec:   60.827137\tkl:   26.897129\n",
            "Epoch: 585 [10100/50000 (20%)]  \tLoss:   88.380165\trec:   61.576679\tkl:   26.803486\n",
            "Epoch: 585 [20100/50000 (40%)]  \tLoss:   92.442680\trec:   64.280037\tkl:   28.162645\n",
            "Epoch: 585 [30100/50000 (60%)]  \tLoss:   90.772682\trec:   62.512592\tkl:   28.260094\n",
            "Epoch: 585 [40100/50000 (80%)]  \tLoss:   90.087105\trec:   61.905838\tkl:   28.181271\n",
            "====> Epoch: 585 Average train loss: 89.7859\n",
            "====> Validation set loss: 92.7443\n",
            "====> Validation set kl: 27.5503\n",
            "Epoch: 586 [  100/50000 ( 0%)]  \tLoss:   86.961891\trec:   59.977783\tkl:   26.984108\n",
            "Epoch: 586 [10100/50000 (20%)]  \tLoss:   91.166733\trec:   62.872627\tkl:   28.294106\n",
            "Epoch: 586 [20100/50000 (40%)]  \tLoss:   89.855583\trec:   62.586853\tkl:   27.268730\n",
            "Epoch: 586 [30100/50000 (60%)]  \tLoss:   90.202507\trec:   63.070427\tkl:   27.132080\n",
            "Epoch: 586 [40100/50000 (80%)]  \tLoss:   92.403107\trec:   64.307198\tkl:   28.095903\n",
            "====> Epoch: 586 Average train loss: 89.7919\n",
            "====> Validation set loss: 92.6438\n",
            "====> Validation set kl: 27.6820\n",
            "Epoch: 587 [  100/50000 ( 0%)]  \tLoss:   90.257027\trec:   62.386200\tkl:   27.870829\n",
            "Epoch: 587 [10100/50000 (20%)]  \tLoss:   89.222176\trec:   61.801392\tkl:   27.420784\n",
            "Epoch: 587 [20100/50000 (40%)]  \tLoss:   87.616524\trec:   60.410400\tkl:   27.206125\n",
            "Epoch: 587 [30100/50000 (60%)]  \tLoss:   90.342781\trec:   61.967983\tkl:   28.374800\n",
            "Epoch: 587 [40100/50000 (80%)]  \tLoss:   89.772652\trec:   62.183125\tkl:   27.589533\n",
            "====> Epoch: 587 Average train loss: 89.7796\n",
            "====> Validation set loss: 92.6661\n",
            "====> Validation set kl: 27.6067\n",
            "Epoch: 588 [  100/50000 ( 0%)]  \tLoss:   87.422646\trec:   59.905293\tkl:   27.517353\n",
            "Epoch: 588 [10100/50000 (20%)]  \tLoss:   89.254448\trec:   61.651112\tkl:   27.603334\n",
            "Epoch: 588 [20100/50000 (40%)]  \tLoss:   92.834999\trec:   65.340645\tkl:   27.494358\n",
            "Epoch: 588 [30100/50000 (60%)]  \tLoss:   89.557411\trec:   62.058739\tkl:   27.498671\n",
            "Epoch: 588 [40100/50000 (80%)]  \tLoss:   89.078491\trec:   61.406704\tkl:   27.671789\n",
            "====> Epoch: 588 Average train loss: 89.7646\n",
            "====> Validation set loss: 92.5390\n",
            "====> Validation set kl: 27.5399\n",
            "Epoch: 589 [  100/50000 ( 0%)]  \tLoss:   93.483727\trec:   65.343803\tkl:   28.139921\n",
            "Epoch: 589 [10100/50000 (20%)]  \tLoss:   89.243614\trec:   62.592564\tkl:   26.651045\n",
            "Epoch: 589 [20100/50000 (40%)]  \tLoss:   88.044014\trec:   61.452244\tkl:   26.591770\n",
            "Epoch: 589 [30100/50000 (60%)]  \tLoss:   89.343719\trec:   62.741001\tkl:   26.602718\n",
            "Epoch: 589 [40100/50000 (80%)]  \tLoss:   88.132668\trec:   61.638470\tkl:   26.494196\n",
            "====> Epoch: 589 Average train loss: 89.7655\n",
            "====> Validation set loss: 92.6285\n",
            "====> Validation set kl: 27.6912\n",
            "Epoch: 590 [  100/50000 ( 0%)]  \tLoss:   90.727051\trec:   62.055099\tkl:   28.671944\n",
            "Epoch: 590 [10100/50000 (20%)]  \tLoss:   88.364433\trec:   60.647205\tkl:   27.717220\n",
            "Epoch: 590 [20100/50000 (40%)]  \tLoss:   91.180809\trec:   63.844406\tkl:   27.336399\n",
            "Epoch: 590 [30100/50000 (60%)]  \tLoss:   89.715820\trec:   61.312878\tkl:   28.402941\n",
            "Epoch: 590 [40100/50000 (80%)]  \tLoss:   90.225548\trec:   61.956581\tkl:   28.268965\n",
            "====> Epoch: 590 Average train loss: 89.7721\n",
            "====> Validation set loss: 92.6403\n",
            "====> Validation set kl: 27.6938\n",
            "Epoch: 591 [  100/50000 ( 0%)]  \tLoss:   91.431709\trec:   63.060528\tkl:   28.371183\n",
            "Epoch: 591 [10100/50000 (20%)]  \tLoss:   90.347977\trec:   62.420048\tkl:   27.927927\n",
            "Epoch: 591 [20100/50000 (40%)]  \tLoss:   88.722267\trec:   61.161003\tkl:   27.561256\n",
            "Epoch: 591 [30100/50000 (60%)]  \tLoss:   87.584229\trec:   60.564602\tkl:   27.019621\n",
            "Epoch: 591 [40100/50000 (80%)]  \tLoss:   88.385040\trec:   61.038445\tkl:   27.346592\n",
            "====> Epoch: 591 Average train loss: 89.7589\n",
            "====> Validation set loss: 92.6662\n",
            "====> Validation set kl: 27.6075\n",
            "Epoch: 592 [  100/50000 ( 0%)]  \tLoss:   87.246040\trec:   60.383457\tkl:   26.862585\n",
            "Epoch: 592 [10100/50000 (20%)]  \tLoss:   93.582481\trec:   64.906403\tkl:   28.676079\n",
            "Epoch: 592 [20100/50000 (40%)]  \tLoss:   89.366257\trec:   61.753994\tkl:   27.612265\n",
            "Epoch: 592 [30100/50000 (60%)]  \tLoss:   88.583649\trec:   61.137600\tkl:   27.446047\n",
            "Epoch: 592 [40100/50000 (80%)]  \tLoss:   90.372849\trec:   63.515732\tkl:   26.857113\n",
            "====> Epoch: 592 Average train loss: 89.7804\n",
            "====> Validation set loss: 92.5631\n",
            "====> Validation set kl: 27.4068\n",
            "Epoch: 593 [  100/50000 ( 0%)]  \tLoss:   86.076149\trec:   59.816185\tkl:   26.259960\n",
            "Epoch: 593 [10100/50000 (20%)]  \tLoss:   87.418770\trec:   59.476814\tkl:   27.941957\n",
            "Epoch: 593 [20100/50000 (40%)]  \tLoss:   91.947586\trec:   63.650017\tkl:   28.297565\n",
            "Epoch: 593 [30100/50000 (60%)]  \tLoss:   92.518394\trec:   64.335617\tkl:   28.182787\n",
            "Epoch: 593 [40100/50000 (80%)]  \tLoss:   92.084892\trec:   63.916836\tkl:   28.168058\n",
            "====> Epoch: 593 Average train loss: 89.7451\n",
            "====> Validation set loss: 92.5955\n",
            "====> Validation set kl: 27.3566\n",
            "Epoch: 594 [  100/50000 ( 0%)]  \tLoss:   83.075668\trec:   57.012215\tkl:   26.063456\n",
            "Epoch: 594 [10100/50000 (20%)]  \tLoss:   91.257866\trec:   62.903934\tkl:   28.353937\n",
            "Epoch: 594 [20100/50000 (40%)]  \tLoss:   87.291130\trec:   60.265614\tkl:   27.025522\n",
            "Epoch: 594 [30100/50000 (60%)]  \tLoss:   88.872887\trec:   61.615051\tkl:   27.257841\n",
            "Epoch: 594 [40100/50000 (80%)]  \tLoss:   87.362831\trec:   59.717197\tkl:   27.645634\n",
            "====> Epoch: 594 Average train loss: 89.7669\n",
            "====> Validation set loss: 92.6003\n",
            "====> Validation set kl: 27.5245\n",
            "Epoch: 595 [  100/50000 ( 0%)]  \tLoss:   89.523140\trec:   61.682686\tkl:   27.840458\n",
            "Epoch: 595 [10100/50000 (20%)]  \tLoss:   92.943863\trec:   65.163139\tkl:   27.780722\n",
            "Epoch: 595 [20100/50000 (40%)]  \tLoss:   91.170586\trec:   64.753395\tkl:   26.417192\n",
            "Epoch: 595 [30100/50000 (60%)]  \tLoss:   94.630730\trec:   66.029045\tkl:   28.601688\n",
            "Epoch: 595 [40100/50000 (80%)]  \tLoss:   88.273140\trec:   61.276028\tkl:   26.997110\n",
            "====> Epoch: 595 Average train loss: 89.7446\n",
            "====> Validation set loss: 92.6090\n",
            "====> Validation set kl: 27.5368\n",
            "Epoch: 596 [  100/50000 ( 0%)]  \tLoss:   84.284058\trec:   57.977840\tkl:   26.306221\n",
            "Epoch: 596 [10100/50000 (20%)]  \tLoss:   88.022369\trec:   60.712811\tkl:   27.309563\n",
            "Epoch: 596 [20100/50000 (40%)]  \tLoss:   88.084541\trec:   60.821404\tkl:   27.263134\n",
            "Epoch: 596 [30100/50000 (60%)]  \tLoss:   88.988388\trec:   61.480267\tkl:   27.508118\n",
            "Epoch: 596 [40100/50000 (80%)]  \tLoss:   89.234047\trec:   61.902988\tkl:   27.331064\n",
            "====> Epoch: 596 Average train loss: 89.7616\n",
            "====> Validation set loss: 92.4624\n",
            "====> Validation set kl: 27.6371\n",
            "Epoch: 597 [  100/50000 ( 0%)]  \tLoss:   90.144958\trec:   62.209621\tkl:   27.935341\n",
            "Epoch: 597 [10100/50000 (20%)]  \tLoss:   90.296211\trec:   62.332451\tkl:   27.963762\n",
            "Epoch: 597 [20100/50000 (40%)]  \tLoss:   91.833405\trec:   63.893780\tkl:   27.939631\n",
            "Epoch: 597 [30100/50000 (60%)]  \tLoss:   90.879959\trec:   62.640614\tkl:   28.239349\n",
            "Epoch: 597 [40100/50000 (80%)]  \tLoss:   87.733627\trec:   60.669506\tkl:   27.064121\n",
            "====> Epoch: 597 Average train loss: 89.7265\n",
            "====> Validation set loss: 92.5198\n",
            "====> Validation set kl: 27.7415\n",
            "Epoch: 598 [  100/50000 ( 0%)]  \tLoss:   85.176971\trec:   58.952831\tkl:   26.224140\n",
            "Epoch: 598 [10100/50000 (20%)]  \tLoss:   91.788589\trec:   63.678112\tkl:   28.110477\n",
            "Epoch: 598 [20100/50000 (40%)]  \tLoss:   88.229332\trec:   60.707073\tkl:   27.522264\n",
            "Epoch: 598 [30100/50000 (60%)]  \tLoss:   93.072647\trec:   64.508102\tkl:   28.564548\n",
            "Epoch: 598 [40100/50000 (80%)]  \tLoss:   90.199608\trec:   63.189316\tkl:   27.010298\n",
            "====> Epoch: 598 Average train loss: 89.7345\n",
            "====> Validation set loss: 92.6456\n",
            "====> Validation set kl: 27.6038\n",
            "Epoch: 599 [  100/50000 ( 0%)]  \tLoss:   86.175552\trec:   59.735920\tkl:   26.439632\n",
            "Epoch: 599 [10100/50000 (20%)]  \tLoss:   88.138756\trec:   60.195934\tkl:   27.942823\n",
            "Epoch: 599 [20100/50000 (40%)]  \tLoss:   86.285622\trec:   60.019482\tkl:   26.266142\n",
            "Epoch: 599 [30100/50000 (60%)]  \tLoss:   90.737595\trec:   63.052479\tkl:   27.685120\n",
            "Epoch: 599 [40100/50000 (80%)]  \tLoss:   89.274628\trec:   61.793438\tkl:   27.481188\n",
            "====> Epoch: 599 Average train loss: 89.7269\n",
            "====> Validation set loss: 92.6239\n",
            "====> Validation set kl: 27.7460\n",
            "Epoch: 600 [  100/50000 ( 0%)]  \tLoss:   88.106529\trec:   59.758102\tkl:   28.348427\n",
            "Epoch: 600 [10100/50000 (20%)]  \tLoss:   88.860184\trec:   61.806728\tkl:   27.053459\n",
            "Epoch: 600 [20100/50000 (40%)]  \tLoss:   89.415993\trec:   62.360321\tkl:   27.055674\n",
            "Epoch: 600 [30100/50000 (60%)]  \tLoss:   87.733398\trec:   60.464783\tkl:   27.268610\n",
            "Epoch: 600 [40100/50000 (80%)]  \tLoss:   88.140427\trec:   61.337425\tkl:   26.803007\n",
            "====> Epoch: 600 Average train loss: 89.7244\n",
            "====> Validation set loss: 92.5618\n",
            "====> Validation set kl: 27.4006\n",
            "Epoch: 601 [  100/50000 ( 0%)]  \tLoss:   89.733261\trec:   61.534252\tkl:   28.199013\n",
            "Epoch: 601 [10100/50000 (20%)]  \tLoss:   93.291161\trec:   65.493980\tkl:   27.797184\n",
            "Epoch: 601 [20100/50000 (40%)]  \tLoss:   90.591835\trec:   62.595673\tkl:   27.996164\n",
            "Epoch: 601 [30100/50000 (60%)]  \tLoss:   87.475250\trec:   60.487114\tkl:   26.988136\n",
            "Epoch: 601 [40100/50000 (80%)]  \tLoss:   84.927704\trec:   58.385132\tkl:   26.542572\n",
            "====> Epoch: 601 Average train loss: 89.7404\n",
            "====> Validation set loss: 92.7221\n",
            "====> Validation set kl: 27.5680\n",
            "Epoch: 602 [  100/50000 ( 0%)]  \tLoss:   87.405457\trec:   60.474842\tkl:   26.930613\n",
            "Epoch: 602 [10100/50000 (20%)]  \tLoss:   87.410156\trec:   59.977715\tkl:   27.432442\n",
            "Epoch: 602 [20100/50000 (40%)]  \tLoss:   90.434898\trec:   62.472557\tkl:   27.962337\n",
            "Epoch: 602 [30100/50000 (60%)]  \tLoss:   92.033424\trec:   63.650303\tkl:   28.383127\n",
            "Epoch: 602 [40100/50000 (80%)]  \tLoss:   88.679031\trec:   61.218948\tkl:   27.460085\n",
            "====> Epoch: 602 Average train loss: 89.7303\n",
            "====> Validation set loss: 92.6020\n",
            "====> Validation set kl: 27.5094\n",
            "Epoch: 603 [  100/50000 ( 0%)]  \tLoss:   89.997490\trec:   62.349995\tkl:   27.647491\n",
            "Epoch: 603 [10100/50000 (20%)]  \tLoss:   93.960503\trec:   65.460846\tkl:   28.499662\n",
            "Epoch: 603 [20100/50000 (40%)]  \tLoss:   90.595718\trec:   63.675320\tkl:   26.920401\n",
            "Epoch: 603 [30100/50000 (60%)]  \tLoss:   89.487938\trec:   61.434803\tkl:   28.053137\n",
            "Epoch: 603 [40100/50000 (80%)]  \tLoss:   93.568474\trec:   65.611282\tkl:   27.957191\n",
            "====> Epoch: 603 Average train loss: 89.7237\n",
            "====> Validation set loss: 92.6858\n",
            "====> Validation set kl: 27.6729\n",
            "Epoch: 604 [  100/50000 ( 0%)]  \tLoss:   90.634850\trec:   63.161518\tkl:   27.473335\n",
            "Epoch: 604 [10100/50000 (20%)]  \tLoss:   89.460487\trec:   61.165817\tkl:   28.294670\n",
            "Epoch: 604 [20100/50000 (40%)]  \tLoss:   90.663643\trec:   62.983719\tkl:   27.679922\n",
            "Epoch: 604 [30100/50000 (60%)]  \tLoss:   90.556847\trec:   62.683613\tkl:   27.873232\n",
            "Epoch: 604 [40100/50000 (80%)]  \tLoss:   87.685768\trec:   60.448776\tkl:   27.236994\n",
            "====> Epoch: 604 Average train loss: 89.7154\n",
            "====> Validation set loss: 92.6001\n",
            "====> Validation set kl: 27.5948\n",
            "Epoch: 605 [  100/50000 ( 0%)]  \tLoss:   90.245033\trec:   62.752178\tkl:   27.492855\n",
            "Epoch: 605 [10100/50000 (20%)]  \tLoss:   90.719582\trec:   63.001053\tkl:   27.718523\n",
            "Epoch: 605 [20100/50000 (40%)]  \tLoss:   90.370934\trec:   62.061844\tkl:   28.309093\n",
            "Epoch: 605 [30100/50000 (60%)]  \tLoss:   89.611122\trec:   61.722885\tkl:   27.888235\n",
            "Epoch: 605 [40100/50000 (80%)]  \tLoss:   93.642059\trec:   65.124054\tkl:   28.518007\n",
            "====> Epoch: 605 Average train loss: 89.6956\n",
            "====> Validation set loss: 92.5963\n",
            "====> Validation set kl: 27.8696\n",
            "Epoch: 606 [  100/50000 ( 0%)]  \tLoss:   91.581055\trec:   63.463699\tkl:   28.117355\n",
            "Epoch: 606 [10100/50000 (20%)]  \tLoss:   90.967392\trec:   63.493408\tkl:   27.473982\n",
            "Epoch: 606 [20100/50000 (40%)]  \tLoss:   88.898582\trec:   61.094646\tkl:   27.803932\n",
            "Epoch: 606 [30100/50000 (60%)]  \tLoss:   87.055878\trec:   59.543915\tkl:   27.511965\n",
            "Epoch: 606 [40100/50000 (80%)]  \tLoss:   87.266228\trec:   60.195400\tkl:   27.070831\n",
            "====> Epoch: 606 Average train loss: 89.7009\n",
            "====> Validation set loss: 92.6842\n",
            "====> Validation set kl: 27.6028\n",
            "Epoch: 607 [  100/50000 ( 0%)]  \tLoss:   93.058510\trec:   65.059654\tkl:   27.998857\n",
            "Epoch: 607 [10100/50000 (20%)]  \tLoss:   86.271255\trec:   59.301277\tkl:   26.969982\n",
            "Epoch: 607 [20100/50000 (40%)]  \tLoss:   90.629921\trec:   62.703964\tkl:   27.925961\n",
            "Epoch: 607 [30100/50000 (60%)]  \tLoss:   89.776268\trec:   62.100170\tkl:   27.676094\n",
            "Epoch: 607 [40100/50000 (80%)]  \tLoss:   88.270660\trec:   60.687603\tkl:   27.583059\n",
            "====> Epoch: 607 Average train loss: 89.7050\n",
            "====> Validation set loss: 92.6137\n",
            "====> Validation set kl: 27.6553\n",
            "Epoch: 608 [  100/50000 ( 0%)]  \tLoss:   88.405319\trec:   61.078403\tkl:   27.326921\n",
            "Epoch: 608 [10100/50000 (20%)]  \tLoss:   88.761177\trec:   62.414032\tkl:   26.347145\n",
            "Epoch: 608 [20100/50000 (40%)]  \tLoss:   91.346367\trec:   63.245018\tkl:   28.101353\n",
            "Epoch: 608 [30100/50000 (60%)]  \tLoss:   90.584190\trec:   63.408882\tkl:   27.175304\n",
            "Epoch: 608 [40100/50000 (80%)]  \tLoss:   88.789314\trec:   61.888485\tkl:   26.900826\n",
            "====> Epoch: 608 Average train loss: 89.6989\n",
            "====> Validation set loss: 92.5850\n",
            "====> Validation set kl: 27.6830\n",
            "Epoch: 609 [  100/50000 ( 0%)]  \tLoss:   92.189842\trec:   64.288414\tkl:   27.901421\n",
            "Epoch: 609 [10100/50000 (20%)]  \tLoss:   92.599609\trec:   64.516899\tkl:   28.082705\n",
            "Epoch: 609 [20100/50000 (40%)]  \tLoss:   89.245834\trec:   61.579247\tkl:   27.666588\n",
            "Epoch: 609 [30100/50000 (60%)]  \tLoss:   91.741562\trec:   63.790241\tkl:   27.951317\n",
            "Epoch: 609 [40100/50000 (80%)]  \tLoss:   87.384445\trec:   59.686909\tkl:   27.697531\n",
            "====> Epoch: 609 Average train loss: 89.7020\n",
            "====> Validation set loss: 92.6300\n",
            "====> Validation set kl: 27.6577\n",
            "Epoch: 610 [  100/50000 ( 0%)]  \tLoss:   87.476616\trec:   60.195332\tkl:   27.281294\n",
            "Epoch: 610 [10100/50000 (20%)]  \tLoss:   89.708252\trec:   61.475945\tkl:   28.232304\n",
            "Epoch: 610 [20100/50000 (40%)]  \tLoss:   91.112335\trec:   62.780621\tkl:   28.331711\n",
            "Epoch: 610 [30100/50000 (60%)]  \tLoss:   92.326591\trec:   63.763866\tkl:   28.562723\n",
            "Epoch: 610 [40100/50000 (80%)]  \tLoss:   92.429649\trec:   63.685101\tkl:   28.744543\n",
            "====> Epoch: 610 Average train loss: 89.6783\n",
            "====> Validation set loss: 92.5704\n",
            "====> Validation set kl: 27.4906\n",
            "Epoch: 611 [  100/50000 ( 0%)]  \tLoss:   85.806969\trec:   59.033215\tkl:   26.773754\n",
            "Epoch: 611 [10100/50000 (20%)]  \tLoss:   91.148102\trec:   62.191532\tkl:   28.956570\n",
            "Epoch: 611 [20100/50000 (40%)]  \tLoss:   89.054253\trec:   61.751991\tkl:   27.302259\n",
            "Epoch: 611 [30100/50000 (60%)]  \tLoss:   88.580154\trec:   60.484524\tkl:   28.095633\n",
            "Epoch: 611 [40100/50000 (80%)]  \tLoss:   89.551094\trec:   62.512451\tkl:   27.038645\n",
            "====> Epoch: 611 Average train loss: 89.6728\n",
            "====> Validation set loss: 92.5542\n",
            "====> Validation set kl: 27.5547\n",
            "Epoch: 612 [  100/50000 ( 0%)]  \tLoss:   90.027725\trec:   62.109325\tkl:   27.918400\n",
            "Epoch: 612 [10100/50000 (20%)]  \tLoss:   90.780807\trec:   63.184402\tkl:   27.596409\n",
            "Epoch: 612 [20100/50000 (40%)]  \tLoss:   92.392563\trec:   64.185829\tkl:   28.206738\n",
            "Epoch: 612 [30100/50000 (60%)]  \tLoss:   87.689392\trec:   61.096699\tkl:   26.592697\n",
            "Epoch: 612 [40100/50000 (80%)]  \tLoss:   89.354950\trec:   61.145077\tkl:   28.209873\n",
            "====> Epoch: 612 Average train loss: 89.6795\n",
            "====> Validation set loss: 92.6506\n",
            "====> Validation set kl: 27.5448\n",
            "Epoch: 613 [  100/50000 ( 0%)]  \tLoss:   89.463661\trec:   62.207840\tkl:   27.255821\n",
            "Epoch: 613 [10100/50000 (20%)]  \tLoss:   86.107391\trec:   59.779789\tkl:   26.327599\n",
            "Epoch: 613 [20100/50000 (40%)]  \tLoss:   89.715927\trec:   62.851902\tkl:   26.864021\n",
            "Epoch: 613 [30100/50000 (60%)]  \tLoss:   89.696983\trec:   61.991413\tkl:   27.705568\n",
            "Epoch: 613 [40100/50000 (80%)]  \tLoss:   87.165077\trec:   59.862343\tkl:   27.302731\n",
            "====> Epoch: 613 Average train loss: 89.6846\n",
            "====> Validation set loss: 92.5738\n",
            "====> Validation set kl: 27.6983\n",
            "Epoch: 614 [  100/50000 ( 0%)]  \tLoss:   91.923134\trec:   64.076073\tkl:   27.847057\n",
            "Epoch: 614 [10100/50000 (20%)]  \tLoss:   87.941978\trec:   60.532509\tkl:   27.409472\n",
            "Epoch: 614 [20100/50000 (40%)]  \tLoss:   95.155533\trec:   66.165504\tkl:   28.990034\n",
            "Epoch: 614 [30100/50000 (60%)]  \tLoss:   89.168884\trec:   62.264969\tkl:   26.903915\n",
            "Epoch: 614 [40100/50000 (80%)]  \tLoss:   89.829796\trec:   62.418499\tkl:   27.411295\n",
            "====> Epoch: 614 Average train loss: 89.6545\n",
            "====> Validation set loss: 92.5971\n",
            "====> Validation set kl: 27.7107\n",
            "Epoch: 615 [  100/50000 ( 0%)]  \tLoss:   87.766266\trec:   60.030937\tkl:   27.735334\n",
            "Epoch: 615 [10100/50000 (20%)]  \tLoss:   92.575996\trec:   64.350479\tkl:   28.225508\n",
            "Epoch: 615 [20100/50000 (40%)]  \tLoss:   86.317909\trec:   59.050564\tkl:   27.267347\n",
            "Epoch: 615 [30100/50000 (60%)]  \tLoss:   91.291382\trec:   62.982773\tkl:   28.308613\n",
            "Epoch: 615 [40100/50000 (80%)]  \tLoss:   88.080711\trec:   61.335487\tkl:   26.745224\n",
            "====> Epoch: 615 Average train loss: 89.6850\n",
            "====> Validation set loss: 92.5375\n",
            "====> Validation set kl: 27.5893\n",
            "Epoch: 616 [  100/50000 ( 0%)]  \tLoss:   90.008560\trec:   62.535595\tkl:   27.472969\n",
            "Epoch: 616 [10100/50000 (20%)]  \tLoss:   89.424507\trec:   60.934433\tkl:   28.490072\n",
            "Epoch: 616 [20100/50000 (40%)]  \tLoss:   90.197655\trec:   61.943279\tkl:   28.254370\n",
            "Epoch: 616 [30100/50000 (60%)]  \tLoss:   89.368126\trec:   62.356670\tkl:   27.011452\n",
            "Epoch: 616 [40100/50000 (80%)]  \tLoss:   86.891159\trec:   60.809002\tkl:   26.082157\n",
            "====> Epoch: 616 Average train loss: 89.6643\n",
            "====> Validation set loss: 92.5987\n",
            "====> Validation set kl: 27.6460\n",
            "Epoch: 617 [  100/50000 ( 0%)]  \tLoss:   86.945030\trec:   59.955750\tkl:   26.989275\n",
            "Epoch: 617 [10100/50000 (20%)]  \tLoss:   83.998581\trec:   58.399712\tkl:   25.598873\n",
            "Epoch: 617 [20100/50000 (40%)]  \tLoss:   87.795410\trec:   60.797600\tkl:   26.997805\n",
            "Epoch: 617 [30100/50000 (60%)]  \tLoss:   86.916100\trec:   59.589130\tkl:   27.326973\n",
            "Epoch: 617 [40100/50000 (80%)]  \tLoss:   88.399239\trec:   60.713135\tkl:   27.686098\n",
            "====> Epoch: 617 Average train loss: 89.6581\n",
            "====> Validation set loss: 92.5379\n",
            "====> Validation set kl: 27.4294\n",
            "Epoch: 618 [  100/50000 ( 0%)]  \tLoss:   90.936142\trec:   62.326923\tkl:   28.609215\n",
            "Epoch: 618 [10100/50000 (20%)]  \tLoss:   89.053963\trec:   61.536358\tkl:   27.517609\n",
            "Epoch: 618 [20100/50000 (40%)]  \tLoss:   83.138962\trec:   57.031239\tkl:   26.107729\n",
            "Epoch: 618 [30100/50000 (60%)]  \tLoss:   88.408592\trec:   61.220295\tkl:   27.188295\n",
            "Epoch: 618 [40100/50000 (80%)]  \tLoss:   88.836197\trec:   61.109379\tkl:   27.726820\n",
            "====> Epoch: 618 Average train loss: 89.6607\n",
            "====> Validation set loss: 92.6042\n",
            "====> Validation set kl: 27.5702\n",
            "Epoch: 619 [  100/50000 ( 0%)]  \tLoss:   87.983368\trec:   60.296650\tkl:   27.686718\n",
            "Epoch: 619 [10100/50000 (20%)]  \tLoss:   94.162598\trec:   65.336006\tkl:   28.826595\n",
            "Epoch: 619 [20100/50000 (40%)]  \tLoss:   89.087051\trec:   61.753891\tkl:   27.333157\n",
            "Epoch: 619 [30100/50000 (60%)]  \tLoss:   92.634422\trec:   63.823147\tkl:   28.811274\n",
            "Epoch: 619 [40100/50000 (80%)]  \tLoss:   91.816582\trec:   64.599136\tkl:   27.217436\n",
            "====> Epoch: 619 Average train loss: 89.6783\n",
            "====> Validation set loss: 92.5426\n",
            "====> Validation set kl: 27.4984\n",
            "Epoch: 620 [  100/50000 ( 0%)]  \tLoss:   90.497635\trec:   62.478397\tkl:   28.019239\n",
            "Epoch: 620 [10100/50000 (20%)]  \tLoss:   93.938286\trec:   65.687828\tkl:   28.250458\n",
            "Epoch: 620 [20100/50000 (40%)]  \tLoss:   90.316933\trec:   62.573174\tkl:   27.743765\n",
            "Epoch: 620 [30100/50000 (60%)]  \tLoss:   89.423691\trec:   62.065018\tkl:   27.358677\n",
            "Epoch: 620 [40100/50000 (80%)]  \tLoss:   87.966759\trec:   60.377235\tkl:   27.589518\n",
            "====> Epoch: 620 Average train loss: 89.6604\n",
            "====> Validation set loss: 92.5135\n",
            "====> Validation set kl: 27.6535\n",
            "Epoch: 621 [  100/50000 ( 0%)]  \tLoss:   89.335915\trec:   61.446400\tkl:   27.889517\n",
            "Epoch: 621 [10100/50000 (20%)]  \tLoss:   87.937653\trec:   61.208080\tkl:   26.729570\n",
            "Epoch: 621 [20100/50000 (40%)]  \tLoss:   88.158569\trec:   59.946014\tkl:   28.212555\n",
            "Epoch: 621 [30100/50000 (60%)]  \tLoss:   89.349937\trec:   61.630131\tkl:   27.719814\n",
            "Epoch: 621 [40100/50000 (80%)]  \tLoss:   87.895859\trec:   61.456356\tkl:   26.439497\n",
            "====> Epoch: 621 Average train loss: 89.6474\n",
            "====> Validation set loss: 92.6299\n",
            "====> Validation set kl: 27.6821\n",
            "Epoch: 622 [  100/50000 ( 0%)]  \tLoss:   87.013390\trec:   59.084316\tkl:   27.929071\n",
            "Epoch: 622 [10100/50000 (20%)]  \tLoss:   89.080505\trec:   61.580849\tkl:   27.499657\n",
            "Epoch: 622 [20100/50000 (40%)]  \tLoss:   88.995659\trec:   61.475559\tkl:   27.520107\n",
            "Epoch: 622 [30100/50000 (60%)]  \tLoss:   88.517792\trec:   61.039158\tkl:   27.478628\n",
            "Epoch: 622 [40100/50000 (80%)]  \tLoss:   90.336060\trec:   62.181423\tkl:   28.154638\n",
            "====> Epoch: 622 Average train loss: 89.6414\n",
            "====> Validation set loss: 92.6223\n",
            "====> Validation set kl: 27.5548\n",
            "Epoch: 623 [  100/50000 ( 0%)]  \tLoss:   90.854057\trec:   62.489441\tkl:   28.364624\n",
            "Epoch: 623 [10100/50000 (20%)]  \tLoss:   91.303925\trec:   63.435516\tkl:   27.868404\n",
            "Epoch: 623 [20100/50000 (40%)]  \tLoss:   87.161934\trec:   59.669323\tkl:   27.492611\n",
            "Epoch: 623 [30100/50000 (60%)]  \tLoss:   89.407829\trec:   61.471794\tkl:   27.936037\n",
            "Epoch: 623 [40100/50000 (80%)]  \tLoss:   82.934395\trec:   56.442322\tkl:   26.492065\n",
            "====> Epoch: 623 Average train loss: 89.6576\n",
            "====> Validation set loss: 92.5437\n",
            "====> Validation set kl: 27.5531\n",
            "Epoch: 624 [  100/50000 ( 0%)]  \tLoss:   89.345131\trec:   61.950996\tkl:   27.394140\n",
            "Epoch: 624 [10100/50000 (20%)]  \tLoss:   89.096451\trec:   60.375980\tkl:   28.720476\n",
            "Epoch: 624 [20100/50000 (40%)]  \tLoss:   92.118629\trec:   63.990242\tkl:   28.128393\n",
            "Epoch: 624 [30100/50000 (60%)]  \tLoss:   89.974396\trec:   62.101826\tkl:   27.872568\n",
            "Epoch: 624 [40100/50000 (80%)]  \tLoss:   90.083260\trec:   61.814316\tkl:   28.268942\n",
            "====> Epoch: 624 Average train loss: 89.6642\n",
            "====> Validation set loss: 92.5066\n",
            "====> Validation set kl: 27.6715\n",
            "Epoch: 625 [  100/50000 ( 0%)]  \tLoss:   93.584236\trec:   64.021118\tkl:   29.563112\n",
            "Epoch: 625 [10100/50000 (20%)]  \tLoss:   87.940262\trec:   60.789330\tkl:   27.150930\n",
            "Epoch: 625 [20100/50000 (40%)]  \tLoss:   85.381172\trec:   58.512997\tkl:   26.868174\n",
            "Epoch: 625 [30100/50000 (60%)]  \tLoss:   88.216148\trec:   60.579979\tkl:   27.636169\n",
            "Epoch: 625 [40100/50000 (80%)]  \tLoss:   91.724869\trec:   63.426655\tkl:   28.298218\n",
            "====> Epoch: 625 Average train loss: 89.6123\n",
            "====> Validation set loss: 92.5937\n",
            "====> Validation set kl: 27.6457\n",
            "Epoch: 626 [  100/50000 ( 0%)]  \tLoss:   87.569908\trec:   60.149441\tkl:   27.420467\n",
            "Epoch: 626 [10100/50000 (20%)]  \tLoss:   86.768951\trec:   60.431644\tkl:   26.337311\n",
            "Epoch: 626 [20100/50000 (40%)]  \tLoss:   88.570137\trec:   61.615398\tkl:   26.954731\n",
            "Epoch: 626 [30100/50000 (60%)]  \tLoss:   90.574318\trec:   62.947392\tkl:   27.626923\n",
            "Epoch: 626 [40100/50000 (80%)]  \tLoss:   90.674843\trec:   63.481995\tkl:   27.192841\n",
            "====> Epoch: 626 Average train loss: 89.6288\n",
            "====> Validation set loss: 92.4766\n",
            "====> Validation set kl: 27.5240\n",
            "Epoch: 627 [  100/50000 ( 0%)]  \tLoss:   88.902344\trec:   62.340405\tkl:   26.561934\n",
            "Epoch: 627 [10100/50000 (20%)]  \tLoss:   93.055992\trec:   64.757515\tkl:   28.298479\n",
            "Epoch: 627 [20100/50000 (40%)]  \tLoss:   88.710495\trec:   60.467098\tkl:   28.243401\n",
            "Epoch: 627 [30100/50000 (60%)]  \tLoss:   91.014648\trec:   63.719521\tkl:   27.295126\n",
            "Epoch: 627 [40100/50000 (80%)]  \tLoss:   89.700974\trec:   61.833340\tkl:   27.867638\n",
            "====> Epoch: 627 Average train loss: 89.6433\n",
            "====> Validation set loss: 92.5726\n",
            "====> Validation set kl: 27.5774\n",
            "Epoch: 628 [  100/50000 ( 0%)]  \tLoss:   85.685806\trec:   59.152351\tkl:   26.533457\n",
            "Epoch: 628 [10100/50000 (20%)]  \tLoss:   90.300270\trec:   61.884159\tkl:   28.416107\n",
            "Epoch: 628 [20100/50000 (40%)]  \tLoss:   90.822174\trec:   62.885876\tkl:   27.936298\n",
            "Epoch: 628 [30100/50000 (60%)]  \tLoss:   94.288826\trec:   65.889618\tkl:   28.399206\n",
            "Epoch: 628 [40100/50000 (80%)]  \tLoss:   86.123154\trec:   59.447338\tkl:   26.675812\n",
            "====> Epoch: 628 Average train loss: 89.6346\n",
            "====> Validation set loss: 92.5422\n",
            "====> Validation set kl: 27.5744\n",
            "Epoch: 629 [  100/50000 ( 0%)]  \tLoss:   90.139587\trec:   63.094170\tkl:   27.045422\n",
            "Epoch: 629 [10100/50000 (20%)]  \tLoss:   91.898750\trec:   62.777206\tkl:   29.121544\n",
            "Epoch: 629 [20100/50000 (40%)]  \tLoss:   90.419960\trec:   62.067261\tkl:   28.352701\n",
            "Epoch: 629 [30100/50000 (60%)]  \tLoss:   88.311501\trec:   60.175388\tkl:   28.136112\n",
            "Epoch: 629 [40100/50000 (80%)]  \tLoss:   90.010841\trec:   61.935104\tkl:   28.075731\n",
            "====> Epoch: 629 Average train loss: 89.6311\n",
            "====> Validation set loss: 92.5400\n",
            "====> Validation set kl: 27.5689\n",
            "Epoch: 630 [  100/50000 ( 0%)]  \tLoss:   88.161987\trec:   60.402119\tkl:   27.759874\n",
            "Epoch: 630 [10100/50000 (20%)]  \tLoss:   91.352135\trec:   63.203587\tkl:   28.148550\n",
            "Epoch: 630 [20100/50000 (40%)]  \tLoss:   90.132599\trec:   62.186836\tkl:   27.945757\n",
            "Epoch: 630 [30100/50000 (60%)]  \tLoss:   89.157631\trec:   61.869072\tkl:   27.288565\n",
            "Epoch: 630 [40100/50000 (80%)]  \tLoss:   90.763412\trec:   63.156757\tkl:   27.606657\n",
            "====> Epoch: 630 Average train loss: 89.6026\n",
            "====> Validation set loss: 92.6302\n",
            "====> Validation set kl: 27.6926\n",
            "Epoch: 631 [  100/50000 ( 0%)]  \tLoss:   89.688034\trec:   61.625599\tkl:   28.062439\n",
            "Epoch: 631 [10100/50000 (20%)]  \tLoss:   90.863258\trec:   62.246067\tkl:   28.617195\n",
            "Epoch: 631 [20100/50000 (40%)]  \tLoss:   89.125282\trec:   61.848946\tkl:   27.276340\n",
            "Epoch: 631 [30100/50000 (60%)]  \tLoss:   90.254250\trec:   62.855293\tkl:   27.398952\n",
            "Epoch: 631 [40100/50000 (80%)]  \tLoss:   91.066513\trec:   63.454651\tkl:   27.611860\n",
            "====> Epoch: 631 Average train loss: 89.6301\n",
            "====> Validation set loss: 92.5940\n",
            "====> Validation set kl: 27.5910\n",
            "Epoch: 632 [  100/50000 ( 0%)]  \tLoss:   88.649666\trec:   62.313389\tkl:   26.336279\n",
            "Epoch: 632 [10100/50000 (20%)]  \tLoss:   90.732536\trec:   62.132172\tkl:   28.600368\n",
            "Epoch: 632 [20100/50000 (40%)]  \tLoss:   92.127541\trec:   63.701141\tkl:   28.426394\n",
            "Epoch: 632 [30100/50000 (60%)]  \tLoss:   90.422310\trec:   62.690765\tkl:   27.731546\n",
            "Epoch: 632 [40100/50000 (80%)]  \tLoss:   88.206299\trec:   60.302841\tkl:   27.903460\n",
            "====> Epoch: 632 Average train loss: 89.6330\n",
            "====> Validation set loss: 92.5443\n",
            "====> Validation set kl: 27.6878\n",
            "Epoch: 633 [  100/50000 ( 0%)]  \tLoss:   89.798981\trec:   62.151039\tkl:   27.647945\n",
            "Epoch: 633 [10100/50000 (20%)]  \tLoss:   93.389091\trec:   65.701035\tkl:   27.688059\n",
            "Epoch: 633 [20100/50000 (40%)]  \tLoss:   92.088066\trec:   64.329491\tkl:   27.758568\n",
            "Epoch: 633 [30100/50000 (60%)]  \tLoss:   83.832451\trec:   57.848251\tkl:   25.984196\n",
            "Epoch: 633 [40100/50000 (80%)]  \tLoss:   93.614136\trec:   64.848732\tkl:   28.765408\n",
            "====> Epoch: 633 Average train loss: 89.6353\n",
            "====> Validation set loss: 92.5758\n",
            "====> Validation set kl: 27.6050\n",
            "Epoch: 634 [  100/50000 ( 0%)]  \tLoss:   87.762085\trec:   60.551151\tkl:   27.210941\n",
            "Epoch: 634 [10100/50000 (20%)]  \tLoss:   86.035141\trec:   58.859413\tkl:   27.175732\n",
            "Epoch: 634 [20100/50000 (40%)]  \tLoss:   91.949051\trec:   64.278976\tkl:   27.670074\n",
            "Epoch: 634 [30100/50000 (60%)]  \tLoss:   88.807442\trec:   61.226189\tkl:   27.581247\n",
            "Epoch: 634 [40100/50000 (80%)]  \tLoss:   89.569962\trec:   61.442928\tkl:   28.127028\n",
            "====> Epoch: 634 Average train loss: 89.6169\n",
            "====> Validation set loss: 92.4772\n",
            "====> Validation set kl: 27.6630\n",
            "Epoch: 635 [  100/50000 ( 0%)]  \tLoss:   87.315331\trec:   59.914745\tkl:   27.400591\n",
            "Epoch: 635 [10100/50000 (20%)]  \tLoss:   91.551674\trec:   63.575485\tkl:   27.976191\n",
            "Epoch: 635 [20100/50000 (40%)]  \tLoss:   90.247559\trec:   62.385578\tkl:   27.861973\n",
            "Epoch: 635 [30100/50000 (60%)]  \tLoss:   88.880348\trec:   61.209183\tkl:   27.671162\n",
            "Epoch: 635 [40100/50000 (80%)]  \tLoss:   86.621040\trec:   59.801609\tkl:   26.819435\n",
            "====> Epoch: 635 Average train loss: 89.5994\n",
            "====> Validation set loss: 92.5946\n",
            "====> Validation set kl: 27.7638\n",
            "Epoch: 636 [  100/50000 ( 0%)]  \tLoss:   92.931541\trec:   64.554581\tkl:   28.376957\n",
            "Epoch: 636 [10100/50000 (20%)]  \tLoss:   94.362724\trec:   66.329811\tkl:   28.032909\n",
            "Epoch: 636 [20100/50000 (40%)]  \tLoss:   91.053619\trec:   62.886826\tkl:   28.166794\n",
            "Epoch: 636 [30100/50000 (60%)]  \tLoss:   83.510864\trec:   57.538231\tkl:   25.972635\n",
            "Epoch: 636 [40100/50000 (80%)]  \tLoss:   86.304283\trec:   59.741615\tkl:   26.562668\n",
            "====> Epoch: 636 Average train loss: 89.5850\n",
            "====> Validation set loss: 92.6051\n",
            "====> Validation set kl: 27.5570\n",
            "Epoch: 637 [  100/50000 ( 0%)]  \tLoss:   86.933601\trec:   59.385609\tkl:   27.547995\n",
            "Epoch: 637 [10100/50000 (20%)]  \tLoss:   89.336563\trec:   62.042156\tkl:   27.294407\n",
            "Epoch: 637 [20100/50000 (40%)]  \tLoss:   94.058258\trec:   66.358971\tkl:   27.699287\n",
            "Epoch: 637 [30100/50000 (60%)]  \tLoss:   88.269386\trec:   60.255119\tkl:   28.014259\n",
            "Epoch: 637 [40100/50000 (80%)]  \tLoss:   90.759254\trec:   63.099911\tkl:   27.659346\n",
            "====> Epoch: 637 Average train loss: 89.5881\n",
            "====> Validation set loss: 92.5675\n",
            "====> Validation set kl: 27.5717\n",
            "Epoch: 638 [  100/50000 ( 0%)]  \tLoss:   90.191719\trec:   62.413532\tkl:   27.778183\n",
            "Epoch: 638 [10100/50000 (20%)]  \tLoss:   91.448395\trec:   62.087090\tkl:   29.361311\n",
            "Epoch: 638 [20100/50000 (40%)]  \tLoss:   87.968018\trec:   60.477852\tkl:   27.490166\n",
            "Epoch: 638 [30100/50000 (60%)]  \tLoss:   86.623154\trec:   59.705070\tkl:   26.918081\n",
            "Epoch: 638 [40100/50000 (80%)]  \tLoss:   89.568184\trec:   62.443962\tkl:   27.124216\n",
            "====> Epoch: 638 Average train loss: 89.5997\n",
            "====> Validation set loss: 92.5699\n",
            "====> Validation set kl: 27.6112\n",
            "Epoch: 639 [  100/50000 ( 0%)]  \tLoss:   86.284370\trec:   59.678905\tkl:   26.605473\n",
            "Epoch: 639 [10100/50000 (20%)]  \tLoss:   88.697197\trec:   61.661118\tkl:   27.036081\n",
            "Epoch: 639 [20100/50000 (40%)]  \tLoss:   91.729645\trec:   64.457809\tkl:   27.271837\n",
            "Epoch: 639 [30100/50000 (60%)]  \tLoss:   89.518875\trec:   61.741123\tkl:   27.777750\n",
            "Epoch: 639 [40100/50000 (80%)]  \tLoss:   91.110748\trec:   62.842270\tkl:   28.268480\n",
            "====> Epoch: 639 Average train loss: 89.5769\n",
            "====> Validation set loss: 92.5781\n",
            "====> Validation set kl: 27.5445\n",
            "Epoch: 640 [  100/50000 ( 0%)]  \tLoss:   92.142929\trec:   64.395988\tkl:   27.746941\n",
            "Epoch: 640 [10100/50000 (20%)]  \tLoss:   95.240021\trec:   66.043854\tkl:   29.196161\n",
            "Epoch: 640 [20100/50000 (40%)]  \tLoss:   90.236794\trec:   62.201855\tkl:   28.034943\n",
            "Epoch: 640 [30100/50000 (60%)]  \tLoss:   92.903961\trec:   63.406704\tkl:   29.497255\n",
            "Epoch: 640 [40100/50000 (80%)]  \tLoss:   93.278885\trec:   64.569023\tkl:   28.709866\n",
            "====> Epoch: 640 Average train loss: 89.5933\n",
            "====> Validation set loss: 92.6331\n",
            "====> Validation set kl: 27.6269\n",
            "Epoch: 641 [  100/50000 ( 0%)]  \tLoss:   91.585938\trec:   63.713745\tkl:   27.872196\n",
            "Epoch: 641 [10100/50000 (20%)]  \tLoss:   89.688332\trec:   62.189823\tkl:   27.498505\n",
            "Epoch: 641 [20100/50000 (40%)]  \tLoss:   85.500977\trec:   58.319405\tkl:   27.181576\n",
            "Epoch: 641 [30100/50000 (60%)]  \tLoss:   88.846863\trec:   62.240467\tkl:   26.606396\n",
            "Epoch: 641 [40100/50000 (80%)]  \tLoss:   90.395386\trec:   62.941376\tkl:   27.454018\n",
            "====> Epoch: 641 Average train loss: 89.5836\n",
            "====> Validation set loss: 92.6285\n",
            "====> Validation set kl: 27.6435\n",
            "Epoch: 642 [  100/50000 ( 0%)]  \tLoss:   88.089821\trec:   60.264179\tkl:   27.825642\n",
            "Epoch: 642 [10100/50000 (20%)]  \tLoss:   85.781792\trec:   58.925007\tkl:   26.856787\n",
            "Epoch: 642 [20100/50000 (40%)]  \tLoss:   90.220802\trec:   62.304577\tkl:   27.916218\n",
            "Epoch: 642 [30100/50000 (60%)]  \tLoss:   88.052940\trec:   60.991596\tkl:   27.061342\n",
            "Epoch: 642 [40100/50000 (80%)]  \tLoss:   86.311539\trec:   58.753353\tkl:   27.558193\n",
            "====> Epoch: 642 Average train loss: 89.5767\n",
            "====> Validation set loss: 92.5514\n",
            "====> Validation set kl: 27.7697\n",
            "Epoch: 643 [  100/50000 ( 0%)]  \tLoss:   84.859879\trec:   57.868767\tkl:   26.991116\n",
            "Epoch: 643 [10100/50000 (20%)]  \tLoss:   92.445961\trec:   64.643448\tkl:   27.802521\n",
            "Epoch: 643 [20100/50000 (40%)]  \tLoss:   86.708084\trec:   60.102917\tkl:   26.605171\n",
            "Epoch: 643 [30100/50000 (60%)]  \tLoss:   97.435974\trec:   67.866096\tkl:   29.569880\n",
            "Epoch: 643 [40100/50000 (80%)]  \tLoss:   90.834412\trec:   62.595058\tkl:   28.239349\n",
            "====> Epoch: 643 Average train loss: 89.5761\n",
            "====> Validation set loss: 92.5255\n",
            "====> Validation set kl: 27.5493\n",
            "Epoch: 644 [  100/50000 ( 0%)]  \tLoss:   86.219032\trec:   58.549053\tkl:   27.669979\n",
            "Epoch: 644 [10100/50000 (20%)]  \tLoss:   90.323105\trec:   63.638561\tkl:   26.684544\n",
            "Epoch: 644 [20100/50000 (40%)]  \tLoss:   88.732887\trec:   61.099087\tkl:   27.633802\n",
            "Epoch: 644 [30100/50000 (60%)]  \tLoss:   87.707283\trec:   61.121624\tkl:   26.585659\n",
            "Epoch: 644 [40100/50000 (80%)]  \tLoss:   90.067703\trec:   61.865448\tkl:   28.202255\n",
            "====> Epoch: 644 Average train loss: 89.5627\n",
            "====> Validation set loss: 92.6116\n",
            "====> Validation set kl: 27.6529\n",
            "Epoch: 645 [  100/50000 ( 0%)]  \tLoss:   91.399536\trec:   64.221169\tkl:   27.178366\n",
            "Epoch: 645 [10100/50000 (20%)]  \tLoss:   89.304794\trec:   60.777229\tkl:   28.527563\n",
            "Epoch: 645 [20100/50000 (40%)]  \tLoss:   88.173370\trec:   61.004951\tkl:   27.168417\n",
            "Epoch: 645 [30100/50000 (60%)]  \tLoss:   89.892311\trec:   62.493465\tkl:   27.398844\n",
            "Epoch: 645 [40100/50000 (80%)]  \tLoss:   83.783104\trec:   57.583504\tkl:   26.199604\n",
            "====> Epoch: 645 Average train loss: 89.5503\n",
            "====> Validation set loss: 92.6527\n",
            "====> Validation set kl: 27.7750\n",
            "Epoch: 646 [  100/50000 ( 0%)]  \tLoss:   93.463593\trec:   64.984512\tkl:   28.479076\n",
            "Epoch: 646 [10100/50000 (20%)]  \tLoss:   88.738327\trec:   60.493328\tkl:   28.244999\n",
            "Epoch: 646 [20100/50000 (40%)]  \tLoss:   88.192734\trec:   59.964050\tkl:   28.228683\n",
            "Epoch: 646 [30100/50000 (60%)]  \tLoss:   89.291870\trec:   61.890331\tkl:   27.401545\n",
            "Epoch: 646 [40100/50000 (80%)]  \tLoss:   88.618073\trec:   61.372444\tkl:   27.245628\n",
            "====> Epoch: 646 Average train loss: 89.5819\n",
            "====> Validation set loss: 92.4524\n",
            "====> Validation set kl: 27.5486\n",
            "Epoch: 647 [  100/50000 ( 0%)]  \tLoss:   87.175415\trec:   60.196892\tkl:   26.978525\n",
            "Epoch: 647 [10100/50000 (20%)]  \tLoss:   87.208130\trec:   60.265163\tkl:   26.942970\n",
            "Epoch: 647 [20100/50000 (40%)]  \tLoss:   89.150719\trec:   61.809608\tkl:   27.341110\n",
            "Epoch: 647 [30100/50000 (60%)]  \tLoss:   85.949081\trec:   59.186436\tkl:   26.762651\n",
            "Epoch: 647 [40100/50000 (80%)]  \tLoss:   91.154938\trec:   62.524841\tkl:   28.630093\n",
            "====> Epoch: 647 Average train loss: 89.5652\n",
            "====> Validation set loss: 92.4994\n",
            "====> Validation set kl: 27.6214\n",
            "Epoch: 648 [  100/50000 ( 0%)]  \tLoss:   92.745781\trec:   64.696701\tkl:   28.049076\n",
            "Epoch: 648 [10100/50000 (20%)]  \tLoss:   91.456764\trec:   63.316074\tkl:   28.140696\n",
            "Epoch: 648 [20100/50000 (40%)]  \tLoss:   88.435211\trec:   60.639339\tkl:   27.795868\n",
            "Epoch: 648 [30100/50000 (60%)]  \tLoss:   86.030136\trec:   59.648418\tkl:   26.381714\n",
            "Epoch: 648 [40100/50000 (80%)]  \tLoss:   93.098679\trec:   64.532448\tkl:   28.566227\n",
            "====> Epoch: 648 Average train loss: 89.5506\n",
            "====> Validation set loss: 92.4765\n",
            "====> Validation set kl: 27.4085\n",
            "Epoch: 649 [  100/50000 ( 0%)]  \tLoss:   91.173706\trec:   62.595028\tkl:   28.578676\n",
            "Epoch: 649 [10100/50000 (20%)]  \tLoss:   89.764198\trec:   62.199726\tkl:   27.564470\n",
            "Epoch: 649 [20100/50000 (40%)]  \tLoss:   91.810173\trec:   63.788311\tkl:   28.021864\n",
            "Epoch: 649 [30100/50000 (60%)]  \tLoss:   88.897400\trec:   61.200371\tkl:   27.697025\n",
            "Epoch: 649 [40100/50000 (80%)]  \tLoss:   87.772629\trec:   60.291767\tkl:   27.480856\n",
            "====> Epoch: 649 Average train loss: 89.5376\n",
            "====> Validation set loss: 92.5557\n",
            "====> Validation set kl: 27.5096\n",
            "Epoch: 650 [  100/50000 ( 0%)]  \tLoss:   88.368828\trec:   61.132782\tkl:   27.236040\n",
            "Epoch: 650 [10100/50000 (20%)]  \tLoss:   87.915642\trec:   59.838448\tkl:   28.077202\n",
            "Epoch: 650 [20100/50000 (40%)]  \tLoss:   90.322975\trec:   62.349178\tkl:   27.973795\n",
            "Epoch: 650 [30100/50000 (60%)]  \tLoss:   90.135742\trec:   62.326435\tkl:   27.809303\n",
            "Epoch: 650 [40100/50000 (80%)]  \tLoss:   89.994003\trec:   63.085381\tkl:   26.908625\n",
            "====> Epoch: 650 Average train loss: 89.5417\n",
            "====> Validation set loss: 92.4833\n",
            "====> Validation set kl: 27.6267\n",
            "Epoch: 651 [  100/50000 ( 0%)]  \tLoss:   90.702637\trec:   62.999653\tkl:   27.702988\n",
            "Epoch: 651 [10100/50000 (20%)]  \tLoss:   90.534805\trec:   62.517567\tkl:   28.017235\n",
            "Epoch: 651 [20100/50000 (40%)]  \tLoss:   90.216675\trec:   62.206795\tkl:   28.009888\n",
            "Epoch: 651 [30100/50000 (60%)]  \tLoss:   89.133163\trec:   61.054966\tkl:   28.078194\n",
            "Epoch: 651 [40100/50000 (80%)]  \tLoss:   86.901085\trec:   59.991280\tkl:   26.909803\n",
            "====> Epoch: 651 Average train loss: 89.5478\n",
            "====> Validation set loss: 92.5185\n",
            "====> Validation set kl: 27.5593\n",
            "Epoch: 652 [  100/50000 ( 0%)]  \tLoss:   90.634834\trec:   62.649662\tkl:   27.985172\n",
            "Epoch: 652 [10100/50000 (20%)]  \tLoss:   89.991905\trec:   62.184765\tkl:   27.807140\n",
            "Epoch: 652 [20100/50000 (40%)]  \tLoss:   86.176811\trec:   58.777840\tkl:   27.398977\n",
            "Epoch: 652 [30100/50000 (60%)]  \tLoss:   87.963493\trec:   60.656136\tkl:   27.307356\n",
            "Epoch: 652 [40100/50000 (80%)]  \tLoss:   85.879929\trec:   58.966328\tkl:   26.913603\n",
            "====> Epoch: 652 Average train loss: 89.5448\n",
            "====> Validation set loss: 92.4974\n",
            "====> Validation set kl: 27.4892\n",
            "Epoch: 653 [  100/50000 ( 0%)]  \tLoss:   88.373741\trec:   60.718094\tkl:   27.655643\n",
            "Epoch: 653 [10100/50000 (20%)]  \tLoss:   87.575302\trec:   60.860233\tkl:   26.715071\n",
            "Epoch: 653 [20100/50000 (40%)]  \tLoss:   86.230270\trec:   58.628044\tkl:   27.602230\n",
            "Epoch: 653 [30100/50000 (60%)]  \tLoss:   90.797379\trec:   63.256428\tkl:   27.540949\n",
            "Epoch: 653 [40100/50000 (80%)]  \tLoss:   90.359428\trec:   62.399910\tkl:   27.959520\n",
            "====> Epoch: 653 Average train loss: 89.5383\n",
            "====> Validation set loss: 92.5354\n",
            "====> Validation set kl: 27.6901\n",
            "Epoch: 654 [  100/50000 ( 0%)]  \tLoss:   89.062965\trec:   60.493191\tkl:   28.569780\n",
            "Epoch: 654 [10100/50000 (20%)]  \tLoss:   86.116600\trec:   59.233860\tkl:   26.882734\n",
            "Epoch: 654 [20100/50000 (40%)]  \tLoss:   86.386208\trec:   60.283054\tkl:   26.103151\n",
            "Epoch: 654 [30100/50000 (60%)]  \tLoss:   90.430565\trec:   63.073914\tkl:   27.356655\n",
            "Epoch: 654 [40100/50000 (80%)]  \tLoss:   85.545616\trec:   57.986141\tkl:   27.559469\n",
            "====> Epoch: 654 Average train loss: 89.5415\n",
            "====> Validation set loss: 92.4641\n",
            "====> Validation set kl: 27.5307\n",
            "Epoch: 655 [  100/50000 ( 0%)]  \tLoss:   92.137314\trec:   64.082451\tkl:   28.054857\n",
            "Epoch: 655 [10100/50000 (20%)]  \tLoss:   89.221230\trec:   62.116688\tkl:   27.104546\n",
            "Epoch: 655 [20100/50000 (40%)]  \tLoss:   86.807846\trec:   60.090546\tkl:   26.717304\n",
            "Epoch: 655 [30100/50000 (60%)]  \tLoss:   89.502693\trec:   62.179138\tkl:   27.323559\n",
            "Epoch: 655 [40100/50000 (80%)]  \tLoss:   87.924431\trec:   59.878948\tkl:   28.045488\n",
            "====> Epoch: 655 Average train loss: 89.5140\n",
            "====> Validation set loss: 92.5326\n",
            "====> Validation set kl: 27.6985\n",
            "Epoch: 656 [  100/50000 ( 0%)]  \tLoss:   90.766335\trec:   62.054619\tkl:   28.711721\n",
            "Epoch: 656 [10100/50000 (20%)]  \tLoss:   89.028595\trec:   60.147064\tkl:   28.881527\n",
            "Epoch: 656 [20100/50000 (40%)]  \tLoss:   87.324074\trec:   60.640686\tkl:   26.683386\n",
            "Epoch: 656 [30100/50000 (60%)]  \tLoss:   92.025642\trec:   64.463814\tkl:   27.561829\n",
            "Epoch: 656 [40100/50000 (80%)]  \tLoss:   91.454102\trec:   63.659500\tkl:   27.794601\n",
            "====> Epoch: 656 Average train loss: 89.5252\n",
            "====> Validation set loss: 92.5199\n",
            "====> Validation set kl: 27.7026\n",
            "Epoch: 657 [  100/50000 ( 0%)]  \tLoss:   90.125977\trec:   62.463856\tkl:   27.662119\n",
            "Epoch: 657 [10100/50000 (20%)]  \tLoss:   93.925163\trec:   65.794632\tkl:   28.130529\n",
            "Epoch: 657 [20100/50000 (40%)]  \tLoss:   87.132286\trec:   60.012741\tkl:   27.119537\n",
            "Epoch: 657 [30100/50000 (60%)]  \tLoss:   91.637558\trec:   63.679699\tkl:   27.957851\n",
            "Epoch: 657 [40100/50000 (80%)]  \tLoss:   90.291412\trec:   62.058472\tkl:   28.232941\n",
            "====> Epoch: 657 Average train loss: 89.5012\n",
            "====> Validation set loss: 92.5383\n",
            "====> Validation set kl: 27.6176\n",
            "Epoch: 658 [  100/50000 ( 0%)]  \tLoss:   89.881699\trec:   61.915386\tkl:   27.966309\n",
            "Epoch: 658 [10100/50000 (20%)]  \tLoss:   90.239990\trec:   61.344284\tkl:   28.895704\n",
            "Epoch: 658 [20100/50000 (40%)]  \tLoss:   89.479149\trec:   61.851086\tkl:   27.628063\n",
            "Epoch: 658 [30100/50000 (60%)]  \tLoss:   90.390419\trec:   62.522686\tkl:   27.867733\n",
            "Epoch: 658 [40100/50000 (80%)]  \tLoss:   91.177559\trec:   63.071636\tkl:   28.105919\n",
            "====> Epoch: 658 Average train loss: 89.5441\n",
            "====> Validation set loss: 92.4669\n",
            "====> Validation set kl: 27.4243\n",
            "Epoch: 659 [  100/50000 ( 0%)]  \tLoss:   89.168571\trec:   62.044456\tkl:   27.124115\n",
            "Epoch: 659 [10100/50000 (20%)]  \tLoss:   85.340012\trec:   59.194408\tkl:   26.145597\n",
            "Epoch: 659 [20100/50000 (40%)]  \tLoss:   91.848259\trec:   63.283230\tkl:   28.565033\n",
            "Epoch: 659 [30100/50000 (60%)]  \tLoss:   89.190643\trec:   61.237450\tkl:   27.953194\n",
            "Epoch: 659 [40100/50000 (80%)]  \tLoss:   89.340889\trec:   61.327263\tkl:   28.013622\n",
            "====> Epoch: 659 Average train loss: 89.5126\n",
            "====> Validation set loss: 92.4037\n",
            "====> Validation set kl: 27.3609\n",
            "Epoch: 660 [  100/50000 ( 0%)]  \tLoss:   93.112114\trec:   65.317444\tkl:   27.794674\n",
            "Epoch: 660 [10100/50000 (20%)]  \tLoss:   89.421295\trec:   61.289619\tkl:   28.131681\n",
            "Epoch: 660 [20100/50000 (40%)]  \tLoss:   88.965584\trec:   61.464901\tkl:   27.500689\n",
            "Epoch: 660 [30100/50000 (60%)]  \tLoss:   92.742661\trec:   63.952923\tkl:   28.789738\n",
            "Epoch: 660 [40100/50000 (80%)]  \tLoss:   88.357536\trec:   60.161255\tkl:   28.196281\n",
            "====> Epoch: 660 Average train loss: 89.5039\n",
            "====> Validation set loss: 92.4629\n",
            "====> Validation set kl: 27.4881\n",
            "Epoch: 661 [  100/50000 ( 0%)]  \tLoss:   88.837875\trec:   61.720642\tkl:   27.117235\n",
            "Epoch: 661 [10100/50000 (20%)]  \tLoss:   87.615524\trec:   60.224472\tkl:   27.391060\n",
            "Epoch: 661 [20100/50000 (40%)]  \tLoss:   87.225349\trec:   59.502224\tkl:   27.723122\n",
            "Epoch: 661 [30100/50000 (60%)]  \tLoss:   90.224373\trec:   61.644814\tkl:   28.579557\n",
            "Epoch: 661 [40100/50000 (80%)]  \tLoss:   88.701759\trec:   60.399086\tkl:   28.302673\n",
            "====> Epoch: 661 Average train loss: 89.5186\n",
            "====> Validation set loss: 92.4387\n",
            "====> Validation set kl: 27.6796\n",
            "Epoch: 662 [  100/50000 ( 0%)]  \tLoss:   90.204552\trec:   62.540218\tkl:   27.664326\n",
            "Epoch: 662 [10100/50000 (20%)]  \tLoss:   89.066788\trec:   61.344589\tkl:   27.722198\n",
            "Epoch: 662 [20100/50000 (40%)]  \tLoss:   89.346367\trec:   62.522625\tkl:   26.823744\n",
            "Epoch: 662 [30100/50000 (60%)]  \tLoss:   89.503532\trec:   61.719734\tkl:   27.783798\n",
            "Epoch: 662 [40100/50000 (80%)]  \tLoss:   89.258759\trec:   61.872227\tkl:   27.386536\n",
            "====> Epoch: 662 Average train loss: 89.5279\n",
            "====> Validation set loss: 92.5350\n",
            "====> Validation set kl: 27.7220\n",
            "Epoch: 663 [  100/50000 ( 0%)]  \tLoss:   88.989365\trec:   60.942696\tkl:   28.046669\n",
            "Epoch: 663 [10100/50000 (20%)]  \tLoss:   89.213593\trec:   61.190239\tkl:   28.023352\n",
            "Epoch: 663 [20100/50000 (40%)]  \tLoss:   86.921227\trec:   60.245430\tkl:   26.675795\n",
            "Epoch: 663 [30100/50000 (60%)]  \tLoss:   94.582466\trec:   65.600334\tkl:   28.982140\n",
            "Epoch: 663 [40100/50000 (80%)]  \tLoss:   87.726807\trec:   59.736416\tkl:   27.990387\n",
            "====> Epoch: 663 Average train loss: 89.5310\n",
            "====> Validation set loss: 92.5029\n",
            "====> Validation set kl: 27.5886\n",
            "Epoch: 664 [  100/50000 ( 0%)]  \tLoss:   92.505913\trec:   63.854683\tkl:   28.651232\n",
            "Epoch: 664 [10100/50000 (20%)]  \tLoss:   85.393211\trec:   58.623516\tkl:   26.769693\n",
            "Epoch: 664 [20100/50000 (40%)]  \tLoss:   86.494858\trec:   60.200230\tkl:   26.294630\n",
            "Epoch: 664 [30100/50000 (60%)]  \tLoss:   87.987633\trec:   60.847683\tkl:   27.139948\n",
            "Epoch: 664 [40100/50000 (80%)]  \tLoss:   91.064766\trec:   62.728569\tkl:   28.336193\n",
            "====> Epoch: 664 Average train loss: 89.4903\n",
            "====> Validation set loss: 92.4934\n",
            "====> Validation set kl: 27.6465\n",
            "Epoch: 665 [  100/50000 ( 0%)]  \tLoss:   93.051216\trec:   65.031586\tkl:   28.019630\n",
            "Epoch: 665 [10100/50000 (20%)]  \tLoss:   89.082733\trec:   61.429451\tkl:   27.653276\n",
            "Epoch: 665 [20100/50000 (40%)]  \tLoss:   91.813240\trec:   63.533920\tkl:   28.279320\n",
            "Epoch: 665 [30100/50000 (60%)]  \tLoss:   88.932938\trec:   60.754486\tkl:   28.178450\n",
            "Epoch: 665 [40100/50000 (80%)]  \tLoss:   89.560112\trec:   61.768612\tkl:   27.791500\n",
            "====> Epoch: 665 Average train loss: 89.4857\n",
            "====> Validation set loss: 92.5209\n",
            "====> Validation set kl: 27.5925\n",
            "Epoch: 666 [  100/50000 ( 0%)]  \tLoss:   89.219704\trec:   61.052849\tkl:   28.166861\n",
            "Epoch: 666 [10100/50000 (20%)]  \tLoss:   89.507614\trec:   61.954315\tkl:   27.553295\n",
            "Epoch: 666 [20100/50000 (40%)]  \tLoss:   88.740601\trec:   61.141960\tkl:   27.598646\n",
            "Epoch: 666 [30100/50000 (60%)]  \tLoss:   87.224663\trec:   59.292786\tkl:   27.931877\n",
            "Epoch: 666 [40100/50000 (80%)]  \tLoss:   88.622009\trec:   61.114491\tkl:   27.507517\n",
            "====> Epoch: 666 Average train loss: 89.4904\n",
            "====> Validation set loss: 92.4713\n",
            "====> Validation set kl: 27.5413\n",
            "Epoch: 667 [  100/50000 ( 0%)]  \tLoss:   88.913063\trec:   60.276985\tkl:   28.636078\n",
            "Epoch: 667 [10100/50000 (20%)]  \tLoss:   89.167480\trec:   61.666267\tkl:   27.501205\n",
            "Epoch: 667 [20100/50000 (40%)]  \tLoss:   94.868195\trec:   65.168266\tkl:   29.699919\n",
            "Epoch: 667 [30100/50000 (60%)]  \tLoss:   86.826836\trec:   60.617126\tkl:   26.209702\n",
            "Epoch: 667 [40100/50000 (80%)]  \tLoss:   88.591774\trec:   61.292995\tkl:   27.298777\n",
            "====> Epoch: 667 Average train loss: 89.4737\n",
            "====> Validation set loss: 92.3583\n",
            "====> Validation set kl: 27.7761\n",
            "Epoch: 668 [  100/50000 ( 0%)]  \tLoss:   88.081444\trec:   60.059021\tkl:   28.022419\n",
            "Epoch: 668 [10100/50000 (20%)]  \tLoss:   89.843864\trec:   62.281395\tkl:   27.562475\n",
            "Epoch: 668 [20100/50000 (40%)]  \tLoss:   86.629494\trec:   60.289413\tkl:   26.340073\n",
            "Epoch: 668 [30100/50000 (60%)]  \tLoss:   86.311188\trec:   58.818665\tkl:   27.492527\n",
            "Epoch: 668 [40100/50000 (80%)]  \tLoss:   86.119713\trec:   58.930321\tkl:   27.189396\n",
            "====> Epoch: 668 Average train loss: 89.4684\n",
            "====> Validation set loss: 92.5318\n",
            "====> Validation set kl: 27.7512\n",
            "Epoch: 669 [  100/50000 ( 0%)]  \tLoss:   89.403633\trec:   61.687641\tkl:   27.715994\n",
            "Epoch: 669 [10100/50000 (20%)]  \tLoss:   89.463982\trec:   62.408916\tkl:   27.055067\n",
            "Epoch: 669 [20100/50000 (40%)]  \tLoss:   95.355568\trec:   66.976021\tkl:   28.379547\n",
            "Epoch: 669 [30100/50000 (60%)]  \tLoss:   91.616501\trec:   63.255295\tkl:   28.361208\n",
            "Epoch: 669 [40100/50000 (80%)]  \tLoss:   91.136734\trec:   63.673134\tkl:   27.463608\n",
            "====> Epoch: 669 Average train loss: 89.4981\n",
            "====> Validation set loss: 92.5306\n",
            "====> Validation set kl: 27.5932\n",
            "Epoch: 670 [  100/50000 ( 0%)]  \tLoss:   86.993614\trec:   60.094528\tkl:   26.899078\n",
            "Epoch: 670 [10100/50000 (20%)]  \tLoss:   88.635483\trec:   60.620407\tkl:   28.015072\n",
            "Epoch: 670 [20100/50000 (40%)]  \tLoss:   90.210495\trec:   62.305130\tkl:   27.905369\n",
            "Epoch: 670 [30100/50000 (60%)]  \tLoss:   87.059158\trec:   59.797508\tkl:   27.261650\n",
            "Epoch: 670 [40100/50000 (80%)]  \tLoss:   88.634605\trec:   61.038738\tkl:   27.595865\n",
            "====> Epoch: 670 Average train loss: 89.4805\n",
            "====> Validation set loss: 92.5285\n",
            "====> Validation set kl: 27.7639\n",
            "Epoch: 671 [  100/50000 ( 0%)]  \tLoss:   89.506851\trec:   61.318924\tkl:   28.187931\n",
            "Epoch: 671 [10100/50000 (20%)]  \tLoss:   90.510109\trec:   62.010246\tkl:   28.499857\n",
            "Epoch: 671 [20100/50000 (40%)]  \tLoss:   88.690369\trec:   60.087204\tkl:   28.603163\n",
            "Epoch: 671 [30100/50000 (60%)]  \tLoss:   92.073349\trec:   63.660595\tkl:   28.412756\n",
            "Epoch: 671 [40100/50000 (80%)]  \tLoss:   89.663139\trec:   61.428856\tkl:   28.234289\n",
            "====> Epoch: 671 Average train loss: 89.4789\n",
            "====> Validation set loss: 92.6495\n",
            "====> Validation set kl: 27.7704\n",
            "Epoch: 672 [  100/50000 ( 0%)]  \tLoss:   96.929787\trec:   66.737564\tkl:   30.192211\n",
            "Epoch: 672 [10100/50000 (20%)]  \tLoss:   84.362701\trec:   58.569843\tkl:   25.792858\n",
            "Epoch: 672 [20100/50000 (40%)]  \tLoss:   91.523628\trec:   62.788662\tkl:   28.734964\n",
            "Epoch: 672 [30100/50000 (60%)]  \tLoss:   89.375740\trec:   61.881504\tkl:   27.494238\n",
            "Epoch: 672 [40100/50000 (80%)]  \tLoss:   90.826157\trec:   63.108982\tkl:   27.717180\n",
            "====> Epoch: 672 Average train loss: 89.4674\n",
            "====> Validation set loss: 92.5692\n",
            "====> Validation set kl: 27.7395\n",
            "Epoch: 673 [  100/50000 ( 0%)]  \tLoss:   89.205948\trec:   61.306316\tkl:   27.899628\n",
            "Epoch: 673 [10100/50000 (20%)]  \tLoss:   89.910721\trec:   61.899353\tkl:   28.011366\n",
            "Epoch: 673 [20100/50000 (40%)]  \tLoss:   86.547554\trec:   59.894775\tkl:   26.652781\n",
            "Epoch: 673 [30100/50000 (60%)]  \tLoss:   90.121208\trec:   62.504051\tkl:   27.617163\n",
            "Epoch: 673 [40100/50000 (80%)]  \tLoss:   87.220436\trec:   59.851254\tkl:   27.369184\n",
            "====> Epoch: 673 Average train loss: 89.4515\n",
            "====> Validation set loss: 92.4838\n",
            "====> Validation set kl: 27.5042\n",
            "Epoch: 674 [  100/50000 ( 0%)]  \tLoss:   84.383728\trec:   58.829769\tkl:   25.553959\n",
            "Epoch: 674 [10100/50000 (20%)]  \tLoss:   88.690704\trec:   61.253262\tkl:   27.437439\n",
            "Epoch: 674 [20100/50000 (40%)]  \tLoss:   88.698608\trec:   60.769051\tkl:   27.929565\n",
            "Epoch: 674 [30100/50000 (60%)]  \tLoss:   89.096504\trec:   61.314232\tkl:   27.782274\n",
            "Epoch: 674 [40100/50000 (80%)]  \tLoss:   90.631577\trec:   62.608662\tkl:   28.022915\n",
            "====> Epoch: 674 Average train loss: 89.4806\n",
            "====> Validation set loss: 92.5030\n",
            "====> Validation set kl: 27.6796\n",
            "Epoch: 675 [  100/50000 ( 0%)]  \tLoss:   89.443726\trec:   61.723320\tkl:   27.720409\n",
            "Epoch: 675 [10100/50000 (20%)]  \tLoss:   88.058739\trec:   60.515888\tkl:   27.542849\n",
            "Epoch: 675 [20100/50000 (40%)]  \tLoss:   90.027222\trec:   61.998001\tkl:   28.029222\n",
            "Epoch: 675 [30100/50000 (60%)]  \tLoss:   92.998749\trec:   63.550312\tkl:   29.448442\n",
            "Epoch: 675 [40100/50000 (80%)]  \tLoss:   86.630295\trec:   59.455433\tkl:   27.174856\n",
            "====> Epoch: 675 Average train loss: 89.4740\n",
            "====> Validation set loss: 92.4523\n",
            "====> Validation set kl: 27.4203\n",
            "Epoch: 676 [  100/50000 ( 0%)]  \tLoss:   87.515587\trec:   61.208599\tkl:   26.306990\n",
            "Epoch: 676 [10100/50000 (20%)]  \tLoss:   86.624969\trec:   59.742195\tkl:   26.882772\n",
            "Epoch: 676 [20100/50000 (40%)]  \tLoss:   90.032578\trec:   61.712284\tkl:   28.320295\n",
            "Epoch: 676 [30100/50000 (60%)]  \tLoss:   86.130760\trec:   59.438602\tkl:   26.692158\n",
            "Epoch: 676 [40100/50000 (80%)]  \tLoss:   88.465378\trec:   60.506531\tkl:   27.958845\n",
            "====> Epoch: 676 Average train loss: 89.4458\n",
            "====> Validation set loss: 92.4756\n",
            "====> Validation set kl: 27.8845\n",
            "Epoch: 677 [  100/50000 ( 0%)]  \tLoss:   90.668335\trec:   62.029037\tkl:   28.639301\n",
            "Epoch: 677 [10100/50000 (20%)]  \tLoss:   85.559052\trec:   58.804966\tkl:   26.754086\n",
            "Epoch: 677 [20100/50000 (40%)]  \tLoss:   92.008621\trec:   64.620514\tkl:   27.388107\n",
            "Epoch: 677 [30100/50000 (60%)]  \tLoss:   90.888062\trec:   63.182652\tkl:   27.705410\n",
            "Epoch: 677 [40100/50000 (80%)]  \tLoss:   91.202820\trec:   63.226345\tkl:   27.976471\n",
            "====> Epoch: 677 Average train loss: 89.4344\n",
            "====> Validation set loss: 92.4484\n",
            "====> Validation set kl: 27.4121\n",
            "Epoch: 678 [  100/50000 ( 0%)]  \tLoss:   91.942635\trec:   63.710213\tkl:   28.232418\n",
            "Epoch: 678 [10100/50000 (20%)]  \tLoss:   85.103477\trec:   58.111259\tkl:   26.992214\n",
            "Epoch: 678 [20100/50000 (40%)]  \tLoss:   93.515907\trec:   64.988228\tkl:   28.527672\n",
            "Epoch: 678 [30100/50000 (60%)]  \tLoss:   93.535484\trec:   64.581818\tkl:   28.953667\n",
            "Epoch: 678 [40100/50000 (80%)]  \tLoss:   91.134781\trec:   63.379871\tkl:   27.754917\n",
            "====> Epoch: 678 Average train loss: 89.4398\n",
            "====> Validation set loss: 92.5551\n",
            "====> Validation set kl: 27.3302\n",
            "Epoch: 679 [  100/50000 ( 0%)]  \tLoss:   86.471794\trec:   59.703754\tkl:   26.768036\n",
            "Epoch: 679 [10100/50000 (20%)]  \tLoss:   90.636520\trec:   62.163425\tkl:   28.473095\n",
            "Epoch: 679 [20100/50000 (40%)]  \tLoss:   89.779572\trec:   61.909695\tkl:   27.869867\n",
            "Epoch: 679 [30100/50000 (60%)]  \tLoss:   90.867973\trec:   62.435448\tkl:   28.432526\n",
            "Epoch: 679 [40100/50000 (80%)]  \tLoss:   87.943588\trec:   59.552372\tkl:   28.391220\n",
            "====> Epoch: 679 Average train loss: 89.4590\n",
            "====> Validation set loss: 92.5128\n",
            "====> Validation set kl: 27.3822\n",
            "Epoch: 680 [  100/50000 ( 0%)]  \tLoss:   89.120659\trec:   62.151543\tkl:   26.969126\n",
            "Epoch: 680 [10100/50000 (20%)]  \tLoss:   92.780190\trec:   63.740749\tkl:   29.039448\n",
            "Epoch: 680 [20100/50000 (40%)]  \tLoss:   86.019547\trec:   59.224236\tkl:   26.795315\n",
            "Epoch: 680 [30100/50000 (60%)]  \tLoss:   92.994728\trec:   64.702194\tkl:   28.292532\n",
            "Epoch: 680 [40100/50000 (80%)]  \tLoss:   91.006973\trec:   62.886845\tkl:   28.120121\n",
            "====> Epoch: 680 Average train loss: 89.4521\n",
            "====> Validation set loss: 92.5317\n",
            "====> Validation set kl: 27.7060\n",
            "Epoch: 681 [  100/50000 ( 0%)]  \tLoss:   88.478653\trec:   60.947571\tkl:   27.531080\n",
            "Epoch: 681 [10100/50000 (20%)]  \tLoss:   88.161346\trec:   60.449219\tkl:   27.712124\n",
            "Epoch: 681 [20100/50000 (40%)]  \tLoss:   88.645935\trec:   60.776047\tkl:   27.869883\n",
            "Epoch: 681 [30100/50000 (60%)]  \tLoss:   90.862968\trec:   62.992573\tkl:   27.870398\n",
            "Epoch: 681 [40100/50000 (80%)]  \tLoss:   89.225800\trec:   62.095013\tkl:   27.130783\n",
            "====> Epoch: 681 Average train loss: 89.4481\n",
            "====> Validation set loss: 92.4644\n",
            "====> Validation set kl: 27.5779\n",
            "Epoch: 682 [  100/50000 ( 0%)]  \tLoss:   89.741463\trec:   61.586216\tkl:   28.155251\n",
            "Epoch: 682 [10100/50000 (20%)]  \tLoss:   85.684311\trec:   59.061794\tkl:   26.622515\n",
            "Epoch: 682 [20100/50000 (40%)]  \tLoss:   90.906464\trec:   63.430744\tkl:   27.475712\n",
            "Epoch: 682 [30100/50000 (60%)]  \tLoss:   90.876472\trec:   62.764030\tkl:   28.112444\n",
            "Epoch: 682 [40100/50000 (80%)]  \tLoss:   90.071739\trec:   61.902298\tkl:   28.169443\n",
            "====> Epoch: 682 Average train loss: 89.4231\n",
            "====> Validation set loss: 92.4791\n",
            "====> Validation set kl: 27.5356\n",
            "Epoch: 683 [  100/50000 ( 0%)]  \tLoss:   93.340858\trec:   64.387283\tkl:   28.953579\n",
            "Epoch: 683 [10100/50000 (20%)]  \tLoss:   90.237877\trec:   62.069618\tkl:   28.168264\n",
            "Epoch: 683 [20100/50000 (40%)]  \tLoss:   88.045761\trec:   60.876507\tkl:   27.169247\n",
            "Epoch: 683 [30100/50000 (60%)]  \tLoss:   87.573280\trec:   60.488571\tkl:   27.084711\n",
            "Epoch: 683 [40100/50000 (80%)]  \tLoss:   87.169968\trec:   60.124569\tkl:   27.045401\n",
            "====> Epoch: 683 Average train loss: 89.4171\n",
            "====> Validation set loss: 92.4746\n",
            "====> Validation set kl: 27.7058\n",
            "Epoch: 684 [  100/50000 ( 0%)]  \tLoss:   94.430557\trec:   64.746162\tkl:   29.684389\n",
            "Epoch: 684 [10100/50000 (20%)]  \tLoss:   85.952461\trec:   58.972412\tkl:   26.980043\n",
            "Epoch: 684 [20100/50000 (40%)]  \tLoss:   90.719902\trec:   63.616020\tkl:   27.103878\n",
            "Epoch: 684 [30100/50000 (60%)]  \tLoss:   91.821152\trec:   63.208385\tkl:   28.612759\n",
            "Epoch: 684 [40100/50000 (80%)]  \tLoss:   86.480568\trec:   59.246864\tkl:   27.233706\n",
            "====> Epoch: 684 Average train loss: 89.4273\n",
            "====> Validation set loss: 92.4932\n",
            "====> Validation set kl: 27.4277\n",
            "Epoch: 685 [  100/50000 ( 0%)]  \tLoss:   86.829201\trec:   60.183418\tkl:   26.645775\n",
            "Epoch: 685 [10100/50000 (20%)]  \tLoss:   88.684586\trec:   60.671875\tkl:   28.012714\n",
            "Epoch: 685 [20100/50000 (40%)]  \tLoss:   86.137398\trec:   59.058422\tkl:   27.078979\n",
            "Epoch: 685 [30100/50000 (60%)]  \tLoss:   90.250504\trec:   62.991577\tkl:   27.258934\n",
            "Epoch: 685 [40100/50000 (80%)]  \tLoss:   89.711609\trec:   62.063946\tkl:   27.647667\n",
            "====> Epoch: 685 Average train loss: 89.4153\n",
            "====> Validation set loss: 92.4712\n",
            "====> Validation set kl: 27.5494\n",
            "Epoch: 686 [  100/50000 ( 0%)]  \tLoss:   90.326622\trec:   62.498516\tkl:   27.828104\n",
            "Epoch: 686 [10100/50000 (20%)]  \tLoss:   92.682930\trec:   63.976395\tkl:   28.706528\n",
            "Epoch: 686 [20100/50000 (40%)]  \tLoss:   89.336639\trec:   61.836029\tkl:   27.500607\n",
            "Epoch: 686 [30100/50000 (60%)]  \tLoss:   90.183640\trec:   62.844997\tkl:   27.338644\n",
            "Epoch: 686 [40100/50000 (80%)]  \tLoss:   86.032799\trec:   59.153259\tkl:   26.879543\n",
            "====> Epoch: 686 Average train loss: 89.4470\n",
            "====> Validation set loss: 92.5485\n",
            "====> Validation set kl: 27.5720\n",
            "Epoch: 687 [  100/50000 ( 0%)]  \tLoss:   89.432411\trec:   61.187080\tkl:   28.245331\n",
            "Epoch: 687 [10100/50000 (20%)]  \tLoss:   89.367104\trec:   61.280029\tkl:   28.087080\n",
            "Epoch: 687 [20100/50000 (40%)]  \tLoss:   92.357582\trec:   63.982979\tkl:   28.374609\n",
            "Epoch: 687 [30100/50000 (60%)]  \tLoss:   91.736259\trec:   63.931660\tkl:   27.804600\n",
            "Epoch: 687 [40100/50000 (80%)]  \tLoss:   85.421051\trec:   58.786903\tkl:   26.634151\n",
            "====> Epoch: 687 Average train loss: 89.4189\n",
            "====> Validation set loss: 92.4836\n",
            "====> Validation set kl: 27.7717\n",
            "Epoch: 688 [  100/50000 ( 0%)]  \tLoss:   90.653198\trec:   61.910446\tkl:   28.742754\n",
            "Epoch: 688 [10100/50000 (20%)]  \tLoss:   87.852394\trec:   60.062225\tkl:   27.790165\n",
            "Epoch: 688 [20100/50000 (40%)]  \tLoss:   91.152130\trec:   62.843525\tkl:   28.308607\n",
            "Epoch: 688 [30100/50000 (60%)]  \tLoss:   82.779800\trec:   56.212280\tkl:   26.567526\n",
            "Epoch: 688 [40100/50000 (80%)]  \tLoss:   89.846413\trec:   62.570526\tkl:   27.275887\n",
            "====> Epoch: 688 Average train loss: 89.4089\n",
            "====> Validation set loss: 92.5173\n",
            "====> Validation set kl: 27.8043\n",
            "Epoch: 689 [  100/50000 ( 0%)]  \tLoss:   89.405876\trec:   61.233089\tkl:   28.172783\n",
            "Epoch: 689 [10100/50000 (20%)]  \tLoss:   84.840691\trec:   57.298321\tkl:   27.542376\n",
            "Epoch: 689 [20100/50000 (40%)]  \tLoss:   91.249832\trec:   63.394112\tkl:   27.855724\n",
            "Epoch: 689 [30100/50000 (60%)]  \tLoss:   84.320320\trec:   57.669559\tkl:   26.650761\n",
            "Epoch: 689 [40100/50000 (80%)]  \tLoss:   92.364922\trec:   63.842655\tkl:   28.522263\n",
            "====> Epoch: 689 Average train loss: 89.4193\n",
            "====> Validation set loss: 92.4380\n",
            "====> Validation set kl: 27.6999\n",
            "Epoch: 690 [  100/50000 ( 0%)]  \tLoss:   90.740761\trec:   62.601021\tkl:   28.139746\n",
            "Epoch: 690 [10100/50000 (20%)]  \tLoss:   91.894936\trec:   63.553814\tkl:   28.341125\n",
            "Epoch: 690 [20100/50000 (40%)]  \tLoss:   87.323669\trec:   59.839024\tkl:   27.484642\n",
            "Epoch: 690 [30100/50000 (60%)]  \tLoss:   93.202858\trec:   65.185051\tkl:   28.017809\n",
            "Epoch: 690 [40100/50000 (80%)]  \tLoss:   88.113174\trec:   60.811577\tkl:   27.301598\n",
            "====> Epoch: 690 Average train loss: 89.4077\n",
            "====> Validation set loss: 92.5153\n",
            "====> Validation set kl: 27.5544\n",
            "Epoch: 691 [  100/50000 ( 0%)]  \tLoss:   91.379021\trec:   63.002758\tkl:   28.376268\n",
            "Epoch: 691 [10100/50000 (20%)]  \tLoss:   91.528748\trec:   63.150810\tkl:   28.377934\n",
            "Epoch: 691 [20100/50000 (40%)]  \tLoss:   90.828407\trec:   63.468056\tkl:   27.360353\n",
            "Epoch: 691 [30100/50000 (60%)]  \tLoss:   92.883354\trec:   64.270744\tkl:   28.612612\n",
            "Epoch: 691 [40100/50000 (80%)]  \tLoss:   89.512108\trec:   60.763554\tkl:   28.748549\n",
            "====> Epoch: 691 Average train loss: 89.4159\n",
            "====> Validation set loss: 92.5416\n",
            "====> Validation set kl: 27.8469\n",
            "Epoch: 692 [  100/50000 ( 0%)]  \tLoss:   90.583183\trec:   61.969860\tkl:   28.613317\n",
            "Epoch: 692 [10100/50000 (20%)]  \tLoss:   89.175919\trec:   61.675930\tkl:   27.499985\n",
            "Epoch: 692 [20100/50000 (40%)]  \tLoss:   90.199318\trec:   62.739491\tkl:   27.459818\n",
            "Epoch: 692 [30100/50000 (60%)]  \tLoss:   90.160561\trec:   62.468174\tkl:   27.692396\n",
            "Epoch: 692 [40100/50000 (80%)]  \tLoss:   91.131905\trec:   62.875427\tkl:   28.256472\n",
            "====> Epoch: 692 Average train loss: 89.4222\n",
            "====> Validation set loss: 92.4129\n",
            "====> Validation set kl: 27.5598\n",
            "Epoch: 693 [  100/50000 ( 0%)]  \tLoss:   89.910484\trec:   61.757244\tkl:   28.153246\n",
            "Epoch: 693 [10100/50000 (20%)]  \tLoss:   90.305031\trec:   61.517460\tkl:   28.787567\n",
            "Epoch: 693 [20100/50000 (40%)]  \tLoss:   88.941391\trec:   62.145611\tkl:   26.795784\n",
            "Epoch: 693 [30100/50000 (60%)]  \tLoss:   91.573433\trec:   63.201366\tkl:   28.372066\n",
            "Epoch: 693 [40100/50000 (80%)]  \tLoss:   90.391327\trec:   62.500408\tkl:   27.890915\n",
            "====> Epoch: 693 Average train loss: 89.4182\n",
            "====> Validation set loss: 92.5887\n",
            "====> Validation set kl: 27.7987\n",
            "Epoch: 694 [  100/50000 ( 0%)]  \tLoss:   89.466072\trec:   61.159737\tkl:   28.306335\n",
            "Epoch: 694 [10100/50000 (20%)]  \tLoss:   92.391510\trec:   64.278297\tkl:   28.113214\n",
            "Epoch: 694 [20100/50000 (40%)]  \tLoss:   86.934479\trec:   60.612343\tkl:   26.322136\n",
            "Epoch: 694 [30100/50000 (60%)]  \tLoss:   89.918945\trec:   61.975906\tkl:   27.943041\n",
            "Epoch: 694 [40100/50000 (80%)]  \tLoss:   87.840279\trec:   59.867104\tkl:   27.973179\n",
            "====> Epoch: 694 Average train loss: 89.3958\n",
            "====> Validation set loss: 92.4488\n",
            "====> Validation set kl: 27.6578\n",
            "Epoch: 695 [  100/50000 ( 0%)]  \tLoss:   89.769844\trec:   61.646519\tkl:   28.123329\n",
            "Epoch: 695 [10100/50000 (20%)]  \tLoss:   86.443504\trec:   59.712616\tkl:   26.730888\n",
            "Epoch: 695 [20100/50000 (40%)]  \tLoss:   89.034111\trec:   60.997742\tkl:   28.036367\n",
            "Epoch: 695 [30100/50000 (60%)]  \tLoss:   86.676834\trec:   59.040081\tkl:   27.636757\n",
            "Epoch: 695 [40100/50000 (80%)]  \tLoss:   89.654549\trec:   61.629276\tkl:   28.025278\n",
            "====> Epoch: 695 Average train loss: 89.3961\n",
            "====> Validation set loss: 92.5015\n",
            "====> Validation set kl: 27.7904\n",
            "Epoch: 696 [  100/50000 ( 0%)]  \tLoss:   87.567192\trec:   60.421856\tkl:   27.145344\n",
            "Epoch: 696 [10100/50000 (20%)]  \tLoss:   86.527733\trec:   59.263153\tkl:   27.264584\n",
            "Epoch: 696 [20100/50000 (40%)]  \tLoss:   88.374107\trec:   60.393475\tkl:   27.980635\n",
            "Epoch: 696 [30100/50000 (60%)]  \tLoss:   94.902107\trec:   65.084320\tkl:   29.817783\n",
            "Epoch: 696 [40100/50000 (80%)]  \tLoss:   90.601570\trec:   62.568928\tkl:   28.032639\n",
            "====> Epoch: 696 Average train loss: 89.4019\n",
            "====> Validation set loss: 92.4646\n",
            "====> Validation set kl: 27.5659\n",
            "Epoch: 697 [  100/50000 ( 0%)]  \tLoss:   86.414482\trec:   59.781044\tkl:   26.633434\n",
            "Epoch: 697 [10100/50000 (20%)]  \tLoss:   89.143768\trec:   60.628399\tkl:   28.515375\n",
            "Epoch: 697 [20100/50000 (40%)]  \tLoss:   90.502106\trec:   62.396072\tkl:   28.106037\n",
            "Epoch: 697 [30100/50000 (60%)]  \tLoss:   87.747658\trec:   60.905529\tkl:   26.842119\n",
            "Epoch: 697 [40100/50000 (80%)]  \tLoss:   90.402252\trec:   62.418991\tkl:   27.983263\n",
            "====> Epoch: 697 Average train loss: 89.3814\n",
            "====> Validation set loss: 92.5152\n",
            "====> Validation set kl: 27.6679\n",
            "Epoch: 698 [  100/50000 ( 0%)]  \tLoss:   91.856987\trec:   63.899071\tkl:   27.957922\n",
            "Epoch: 698 [10100/50000 (20%)]  \tLoss:   85.827843\trec:   59.445232\tkl:   26.382605\n",
            "Epoch: 698 [20100/50000 (40%)]  \tLoss:   90.539909\trec:   62.503242\tkl:   28.036669\n",
            "Epoch: 698 [30100/50000 (60%)]  \tLoss:   87.820000\trec:   60.321106\tkl:   27.498886\n",
            "Epoch: 698 [40100/50000 (80%)]  \tLoss:   89.798103\trec:   62.755066\tkl:   27.043037\n",
            "====> Epoch: 698 Average train loss: 89.3646\n",
            "====> Validation set loss: 92.5787\n",
            "====> Validation set kl: 27.7470\n",
            "Epoch: 699 [  100/50000 ( 0%)]  \tLoss:   88.235039\trec:   60.838161\tkl:   27.396877\n",
            "Epoch: 699 [10100/50000 (20%)]  \tLoss:   85.886772\trec:   58.469505\tkl:   27.417271\n",
            "Epoch: 699 [20100/50000 (40%)]  \tLoss:   91.216728\trec:   62.098743\tkl:   29.117981\n",
            "Epoch: 699 [30100/50000 (60%)]  \tLoss:   87.150154\trec:   60.642117\tkl:   26.508034\n",
            "Epoch: 699 [40100/50000 (80%)]  \tLoss:   91.677032\trec:   63.233231\tkl:   28.443804\n",
            "====> Epoch: 699 Average train loss: 89.3692\n",
            "====> Validation set loss: 92.3771\n",
            "====> Validation set kl: 27.5056\n",
            "Epoch: 700 [  100/50000 ( 0%)]  \tLoss:   87.756798\trec:   61.738953\tkl:   26.017841\n",
            "Epoch: 700 [10100/50000 (20%)]  \tLoss:   90.925720\trec:   62.527641\tkl:   28.398079\n",
            "Epoch: 700 [20100/50000 (40%)]  \tLoss:   92.437546\trec:   64.408936\tkl:   28.028608\n",
            "Epoch: 700 [30100/50000 (60%)]  \tLoss:   87.897644\trec:   60.018291\tkl:   27.879354\n",
            "Epoch: 700 [40100/50000 (80%)]  \tLoss:   89.788063\trec:   61.355083\tkl:   28.432983\n",
            "====> Epoch: 700 Average train loss: 89.3810\n",
            "====> Validation set loss: 92.5002\n",
            "====> Validation set kl: 27.4223\n",
            "Epoch: 701 [  100/50000 ( 0%)]  \tLoss:   86.990288\trec:   59.590263\tkl:   27.400026\n",
            "Epoch: 701 [10100/50000 (20%)]  \tLoss:   88.591385\trec:   61.299541\tkl:   27.291845\n",
            "Epoch: 701 [20100/50000 (40%)]  \tLoss:   89.774200\trec:   62.422558\tkl:   27.351645\n",
            "Epoch: 701 [30100/50000 (60%)]  \tLoss:   91.354042\trec:   62.769558\tkl:   28.584484\n",
            "Epoch: 701 [40100/50000 (80%)]  \tLoss:   91.531212\trec:   63.158764\tkl:   28.372446\n",
            "====> Epoch: 701 Average train loss: 89.3803\n",
            "====> Validation set loss: 92.4474\n",
            "====> Validation set kl: 27.4922\n",
            "Epoch: 702 [  100/50000 ( 0%)]  \tLoss:   89.312996\trec:   61.912983\tkl:   27.400015\n",
            "Epoch: 702 [10100/50000 (20%)]  \tLoss:   90.613739\trec:   63.210663\tkl:   27.403072\n",
            "Epoch: 702 [20100/50000 (40%)]  \tLoss:   90.309204\trec:   62.330379\tkl:   27.978825\n",
            "Epoch: 702 [30100/50000 (60%)]  \tLoss:   91.583191\trec:   63.703796\tkl:   27.879395\n",
            "Epoch: 702 [40100/50000 (80%)]  \tLoss:   90.241211\trec:   61.293865\tkl:   28.947346\n",
            "====> Epoch: 702 Average train loss: 89.3875\n",
            "====> Validation set loss: 92.4753\n",
            "====> Validation set kl: 27.6094\n",
            "Epoch: 703 [  100/50000 ( 0%)]  \tLoss:   92.221474\trec:   63.764309\tkl:   28.457163\n",
            "Epoch: 703 [10100/50000 (20%)]  \tLoss:   85.919197\trec:   58.747246\tkl:   27.171949\n",
            "Epoch: 703 [20100/50000 (40%)]  \tLoss:   89.144814\trec:   61.822166\tkl:   27.322643\n",
            "Epoch: 703 [30100/50000 (60%)]  \tLoss:   91.348770\trec:   63.696239\tkl:   27.652527\n",
            "Epoch: 703 [40100/50000 (80%)]  \tLoss:   95.780067\trec:   67.030067\tkl:   28.749996\n",
            "====> Epoch: 703 Average train loss: 89.3874\n",
            "====> Validation set loss: 92.4388\n",
            "====> Validation set kl: 27.6339\n",
            "Epoch: 704 [  100/50000 ( 0%)]  \tLoss:   88.148720\trec:   60.615780\tkl:   27.532942\n",
            "Epoch: 704 [10100/50000 (20%)]  \tLoss:   88.731873\trec:   60.724476\tkl:   28.007399\n",
            "Epoch: 704 [20100/50000 (40%)]  \tLoss:   89.228043\trec:   61.993149\tkl:   27.234892\n",
            "Epoch: 704 [30100/50000 (60%)]  \tLoss:   89.519684\trec:   61.780296\tkl:   27.739384\n",
            "Epoch: 704 [40100/50000 (80%)]  \tLoss:   87.198044\trec:   59.944199\tkl:   27.253847\n",
            "====> Epoch: 704 Average train loss: 89.3765\n",
            "====> Validation set loss: 92.4770\n",
            "====> Validation set kl: 27.6730\n",
            "Epoch: 705 [  100/50000 ( 0%)]  \tLoss:   91.488434\trec:   63.780300\tkl:   27.708134\n",
            "Epoch: 705 [10100/50000 (20%)]  \tLoss:   89.973549\trec:   62.664398\tkl:   27.309156\n",
            "Epoch: 705 [20100/50000 (40%)]  \tLoss:   88.694794\trec:   60.540981\tkl:   28.153812\n",
            "Epoch: 705 [30100/50000 (60%)]  \tLoss:   91.932388\trec:   63.283276\tkl:   28.649113\n",
            "Epoch: 705 [40100/50000 (80%)]  \tLoss:   89.125641\trec:   61.084606\tkl:   28.041033\n",
            "====> Epoch: 705 Average train loss: 89.3598\n",
            "====> Validation set loss: 92.5259\n",
            "====> Validation set kl: 27.7431\n",
            "Epoch: 706 [  100/50000 ( 0%)]  \tLoss:   87.573189\trec:   60.618210\tkl:   26.954983\n",
            "Epoch: 706 [10100/50000 (20%)]  \tLoss:   89.792168\trec:   62.172352\tkl:   27.619812\n",
            "Epoch: 706 [20100/50000 (40%)]  \tLoss:   91.595192\trec:   63.543339\tkl:   28.051859\n",
            "Epoch: 706 [30100/50000 (60%)]  \tLoss:   89.174011\trec:   62.075020\tkl:   27.098993\n",
            "Epoch: 706 [40100/50000 (80%)]  \tLoss:   90.600311\trec:   62.441238\tkl:   28.159071\n",
            "====> Epoch: 706 Average train loss: 89.3575\n",
            "====> Validation set loss: 92.4914\n",
            "====> Validation set kl: 27.7267\n",
            "Epoch: 707 [  100/50000 ( 0%)]  \tLoss:   85.972031\trec:   58.597858\tkl:   27.374172\n",
            "Epoch: 707 [10100/50000 (20%)]  \tLoss:   89.605545\trec:   62.574463\tkl:   27.031078\n",
            "Epoch: 707 [20100/50000 (40%)]  \tLoss:   89.770668\trec:   62.078205\tkl:   27.692467\n",
            "Epoch: 707 [30100/50000 (60%)]  \tLoss:   90.863541\trec:   61.969570\tkl:   28.893974\n",
            "Epoch: 707 [40100/50000 (80%)]  \tLoss:   89.143692\trec:   61.386326\tkl:   27.757364\n",
            "====> Epoch: 707 Average train loss: 89.3514\n",
            "====> Validation set loss: 92.5521\n",
            "====> Validation set kl: 27.5651\n",
            "Epoch: 708 [  100/50000 ( 0%)]  \tLoss:   88.939316\trec:   61.007679\tkl:   27.931631\n",
            "Epoch: 708 [10100/50000 (20%)]  \tLoss:   92.321083\trec:   64.064514\tkl:   28.256569\n",
            "Epoch: 708 [20100/50000 (40%)]  \tLoss:   92.355919\trec:   64.740623\tkl:   27.615295\n",
            "Epoch: 708 [30100/50000 (60%)]  \tLoss:   90.278923\trec:   62.263836\tkl:   28.015089\n",
            "Epoch: 708 [40100/50000 (80%)]  \tLoss:   90.710800\trec:   62.442768\tkl:   28.268028\n",
            "====> Epoch: 708 Average train loss: 89.3326\n",
            "====> Validation set loss: 92.5727\n",
            "====> Validation set kl: 27.7251\n",
            "Epoch: 709 [  100/50000 ( 0%)]  \tLoss:   90.000542\trec:   62.449173\tkl:   27.551374\n",
            "Epoch: 709 [10100/50000 (20%)]  \tLoss:   87.464195\trec:   59.872707\tkl:   27.591486\n",
            "Epoch: 709 [20100/50000 (40%)]  \tLoss:   84.783501\trec:   57.895653\tkl:   26.887848\n",
            "Epoch: 709 [30100/50000 (60%)]  \tLoss:   89.521095\trec:   61.498188\tkl:   28.022900\n",
            "Epoch: 709 [40100/50000 (80%)]  \tLoss:   89.400444\trec:   61.625198\tkl:   27.775248\n",
            "====> Epoch: 709 Average train loss: 89.3641\n",
            "====> Validation set loss: 92.4739\n",
            "====> Validation set kl: 27.7989\n",
            "Epoch: 710 [  100/50000 ( 0%)]  \tLoss:   91.501030\trec:   62.876030\tkl:   28.625008\n",
            "Epoch: 710 [10100/50000 (20%)]  \tLoss:   89.884590\trec:   62.007675\tkl:   27.876915\n",
            "Epoch: 710 [20100/50000 (40%)]  \tLoss:   92.950478\trec:   64.715790\tkl:   28.234688\n",
            "Epoch: 710 [30100/50000 (60%)]  \tLoss:   89.621597\trec:   62.328545\tkl:   27.293051\n",
            "Epoch: 710 [40100/50000 (80%)]  \tLoss:   92.448883\trec:   64.212448\tkl:   28.236441\n",
            "====> Epoch: 710 Average train loss: 89.3789\n",
            "====> Validation set loss: 92.3471\n",
            "====> Validation set kl: 27.6460\n",
            "Epoch: 711 [  100/50000 ( 0%)]  \tLoss:   90.500473\trec:   61.999966\tkl:   28.500509\n",
            "Epoch: 711 [10100/50000 (20%)]  \tLoss:   91.177437\trec:   63.815533\tkl:   27.361906\n",
            "Epoch: 711 [20100/50000 (40%)]  \tLoss:   91.526245\trec:   62.738377\tkl:   28.787872\n",
            "Epoch: 711 [30100/50000 (60%)]  \tLoss:   85.816238\trec:   58.793861\tkl:   27.022377\n",
            "Epoch: 711 [40100/50000 (80%)]  \tLoss:   85.970978\trec:   58.712498\tkl:   27.258471\n",
            "====> Epoch: 711 Average train loss: 89.3421\n",
            "====> Validation set loss: 92.5334\n",
            "====> Validation set kl: 27.8986\n",
            "Epoch: 712 [  100/50000 ( 0%)]  \tLoss:   85.741737\trec:   58.937275\tkl:   26.804457\n",
            "Epoch: 712 [10100/50000 (20%)]  \tLoss:   88.946724\trec:   60.758347\tkl:   28.188375\n",
            "Epoch: 712 [20100/50000 (40%)]  \tLoss:   89.887733\trec:   62.147949\tkl:   27.739784\n",
            "Epoch: 712 [30100/50000 (60%)]  \tLoss:   92.788185\trec:   64.244225\tkl:   28.543955\n",
            "Epoch: 712 [40100/50000 (80%)]  \tLoss:   87.345116\trec:   60.544285\tkl:   26.800835\n",
            "====> Epoch: 712 Average train loss: 89.3316\n",
            "====> Validation set loss: 92.3964\n",
            "====> Validation set kl: 27.8202\n",
            "Epoch: 713 [  100/50000 ( 0%)]  \tLoss:   86.561661\trec:   59.607166\tkl:   26.954491\n",
            "Epoch: 713 [10100/50000 (20%)]  \tLoss:   91.138321\trec:   62.951912\tkl:   28.186409\n",
            "Epoch: 713 [20100/50000 (40%)]  \tLoss:   87.628029\trec:   60.808426\tkl:   26.819593\n",
            "Epoch: 713 [30100/50000 (60%)]  \tLoss:   90.739296\trec:   62.948967\tkl:   27.790323\n",
            "Epoch: 713 [40100/50000 (80%)]  \tLoss:   87.791641\trec:   60.415485\tkl:   27.376150\n",
            "====> Epoch: 713 Average train loss: 89.3383\n",
            "====> Validation set loss: 92.4826\n",
            "====> Validation set kl: 27.7671\n",
            "Epoch: 714 [  100/50000 ( 0%)]  \tLoss:   88.336792\trec:   60.786953\tkl:   27.549845\n",
            "Epoch: 714 [10100/50000 (20%)]  \tLoss:   90.040016\trec:   61.893250\tkl:   28.146763\n",
            "Epoch: 714 [20100/50000 (40%)]  \tLoss:   90.284531\trec:   62.591293\tkl:   27.693239\n",
            "Epoch: 714 [30100/50000 (60%)]  \tLoss:   89.865883\trec:   62.214569\tkl:   27.651316\n",
            "Epoch: 714 [40100/50000 (80%)]  \tLoss:   90.278038\trec:   62.419453\tkl:   27.858583\n",
            "====> Epoch: 714 Average train loss: 89.3441\n",
            "====> Validation set loss: 92.3943\n",
            "====> Validation set kl: 27.7570\n",
            "Epoch: 715 [  100/50000 ( 0%)]  \tLoss:   92.244011\trec:   63.365673\tkl:   28.878340\n",
            "Epoch: 715 [10100/50000 (20%)]  \tLoss:   86.772789\trec:   59.543777\tkl:   27.229013\n",
            "Epoch: 715 [20100/50000 (40%)]  \tLoss:   86.007050\trec:   58.862675\tkl:   27.144377\n",
            "Epoch: 715 [30100/50000 (60%)]  \tLoss:   91.809341\trec:   62.984421\tkl:   28.824924\n",
            "Epoch: 715 [40100/50000 (80%)]  \tLoss:   91.639336\trec:   63.073086\tkl:   28.566244\n",
            "====> Epoch: 715 Average train loss: 89.3271\n",
            "====> Validation set loss: 92.4159\n",
            "====> Validation set kl: 27.7478\n",
            "Epoch: 716 [  100/50000 ( 0%)]  \tLoss:   88.706345\trec:   60.748943\tkl:   27.957401\n",
            "Epoch: 716 [10100/50000 (20%)]  \tLoss:   89.638855\trec:   61.968845\tkl:   27.670006\n",
            "Epoch: 716 [20100/50000 (40%)]  \tLoss:   87.780838\trec:   60.211651\tkl:   27.569193\n",
            "Epoch: 716 [30100/50000 (60%)]  \tLoss:   85.690796\trec:   59.480312\tkl:   26.210493\n",
            "Epoch: 716 [40100/50000 (80%)]  \tLoss:   90.960976\trec:   62.521389\tkl:   28.439585\n",
            "====> Epoch: 716 Average train loss: 89.3226\n",
            "====> Validation set loss: 92.4051\n",
            "====> Validation set kl: 27.6969\n",
            "Epoch: 717 [  100/50000 ( 0%)]  \tLoss:   85.360580\trec:   58.028671\tkl:   27.331911\n",
            "Epoch: 717 [10100/50000 (20%)]  \tLoss:   93.459244\trec:   64.452164\tkl:   29.007076\n",
            "Epoch: 717 [20100/50000 (40%)]  \tLoss:   88.530563\trec:   60.403576\tkl:   28.126989\n",
            "Epoch: 717 [30100/50000 (60%)]  \tLoss:   88.242241\trec:   60.965462\tkl:   27.276777\n",
            "Epoch: 717 [40100/50000 (80%)]  \tLoss:   85.189560\trec:   57.968758\tkl:   27.220798\n",
            "====> Epoch: 717 Average train loss: 89.3220\n",
            "====> Validation set loss: 92.4028\n",
            "====> Validation set kl: 27.6773\n",
            "Epoch: 718 [  100/50000 ( 0%)]  \tLoss:   89.284340\trec:   61.822861\tkl:   27.461483\n",
            "Epoch: 718 [10100/50000 (20%)]  \tLoss:   86.169724\trec:   59.704800\tkl:   26.464926\n",
            "Epoch: 718 [20100/50000 (40%)]  \tLoss:   87.106918\trec:   59.787582\tkl:   27.319338\n",
            "Epoch: 718 [30100/50000 (60%)]  \tLoss:   90.560211\trec:   63.258064\tkl:   27.302143\n",
            "Epoch: 718 [40100/50000 (80%)]  \tLoss:   89.741661\trec:   61.399395\tkl:   28.342260\n",
            "====> Epoch: 718 Average train loss: 89.3503\n",
            "====> Validation set loss: 92.4821\n",
            "====> Validation set kl: 27.9412\n",
            "Epoch: 719 [  100/50000 ( 0%)]  \tLoss:   88.999489\trec:   60.840767\tkl:   28.158722\n",
            "Epoch: 719 [10100/50000 (20%)]  \tLoss:   89.150932\trec:   61.092236\tkl:   28.058706\n",
            "Epoch: 719 [20100/50000 (40%)]  \tLoss:   88.918198\trec:   61.379265\tkl:   27.538933\n",
            "Epoch: 719 [30100/50000 (60%)]  \tLoss:   90.041748\trec:   62.038670\tkl:   28.003075\n",
            "Epoch: 719 [40100/50000 (80%)]  \tLoss:   91.841827\trec:   63.807678\tkl:   28.034145\n",
            "====> Epoch: 719 Average train loss: 89.3317\n",
            "====> Validation set loss: 92.4332\n",
            "====> Validation set kl: 27.7759\n",
            "Epoch: 720 [  100/50000 ( 0%)]  \tLoss:   91.346237\trec:   62.439068\tkl:   28.907169\n",
            "Epoch: 720 [10100/50000 (20%)]  \tLoss:   87.474312\trec:   60.557468\tkl:   26.916845\n",
            "Epoch: 720 [20100/50000 (40%)]  \tLoss:   91.058380\trec:   63.722988\tkl:   27.335396\n",
            "Epoch: 720 [30100/50000 (60%)]  \tLoss:   88.510925\trec:   61.765873\tkl:   26.745052\n",
            "Epoch: 720 [40100/50000 (80%)]  \tLoss:   86.400131\trec:   59.194233\tkl:   27.205908\n",
            "====> Epoch: 720 Average train loss: 89.3246\n",
            "====> Validation set loss: 92.5189\n",
            "====> Validation set kl: 27.5548\n",
            "Epoch: 721 [  100/50000 ( 0%)]  \tLoss:   91.309517\trec:   62.749710\tkl:   28.559811\n",
            "Epoch: 721 [10100/50000 (20%)]  \tLoss:   88.149742\trec:   60.410130\tkl:   27.739611\n",
            "Epoch: 721 [20100/50000 (40%)]  \tLoss:   85.949547\trec:   58.796726\tkl:   27.152819\n",
            "Epoch: 721 [30100/50000 (60%)]  \tLoss:   90.878174\trec:   62.860256\tkl:   28.017912\n",
            "Epoch: 721 [40100/50000 (80%)]  \tLoss:   88.300217\trec:   61.856209\tkl:   26.444008\n",
            "====> Epoch: 721 Average train loss: 89.3237\n",
            "====> Validation set loss: 92.5667\n",
            "====> Validation set kl: 27.8553\n",
            "Epoch: 722 [  100/50000 ( 0%)]  \tLoss:   88.970757\trec:   61.181309\tkl:   27.789455\n",
            "Epoch: 722 [10100/50000 (20%)]  \tLoss:   89.217255\trec:   61.492088\tkl:   27.725168\n",
            "Epoch: 722 [20100/50000 (40%)]  \tLoss:   87.146324\trec:   58.561150\tkl:   28.585178\n",
            "Epoch: 722 [30100/50000 (60%)]  \tLoss:   90.581375\trec:   63.127861\tkl:   27.453512\n",
            "Epoch: 722 [40100/50000 (80%)]  \tLoss:   87.072861\trec:   59.878418\tkl:   27.194441\n",
            "====> Epoch: 722 Average train loss: 89.3015\n",
            "====> Validation set loss: 92.4651\n",
            "====> Validation set kl: 27.6418\n",
            "Epoch: 723 [  100/50000 ( 0%)]  \tLoss:   89.748634\trec:   61.158581\tkl:   28.590050\n",
            "Epoch: 723 [10100/50000 (20%)]  \tLoss:   87.571510\trec:   61.074188\tkl:   26.497326\n",
            "Epoch: 723 [20100/50000 (40%)]  \tLoss:   87.791153\trec:   60.400078\tkl:   27.391069\n",
            "Epoch: 723 [30100/50000 (60%)]  \tLoss:   89.008926\trec:   61.462704\tkl:   27.546223\n",
            "Epoch: 723 [40100/50000 (80%)]  \tLoss:   90.224892\trec:   62.159500\tkl:   28.065392\n",
            "====> Epoch: 723 Average train loss: 89.3211\n",
            "====> Validation set loss: 92.4194\n",
            "====> Validation set kl: 27.8660\n",
            "Epoch: 724 [  100/50000 ( 0%)]  \tLoss:   86.855309\trec:   59.076073\tkl:   27.779243\n",
            "Epoch: 724 [10100/50000 (20%)]  \tLoss:   89.846237\trec:   61.844490\tkl:   28.001749\n",
            "Epoch: 724 [20100/50000 (40%)]  \tLoss:   89.979256\trec:   61.330223\tkl:   28.649033\n",
            "Epoch: 724 [30100/50000 (60%)]  \tLoss:   88.649536\trec:   62.154369\tkl:   26.495173\n",
            "Epoch: 724 [40100/50000 (80%)]  \tLoss:   87.107422\trec:   59.798740\tkl:   27.308681\n",
            "====> Epoch: 724 Average train loss: 89.3314\n",
            "====> Validation set loss: 92.5006\n",
            "====> Validation set kl: 27.7611\n",
            "Epoch: 725 [  100/50000 ( 0%)]  \tLoss:   91.796402\trec:   63.694695\tkl:   28.101711\n",
            "Epoch: 725 [10100/50000 (20%)]  \tLoss:   89.687904\trec:   62.559536\tkl:   27.128374\n",
            "Epoch: 725 [20100/50000 (40%)]  \tLoss:   92.702911\trec:   64.331863\tkl:   28.371042\n",
            "Epoch: 725 [30100/50000 (60%)]  \tLoss:   89.539490\trec:   61.429268\tkl:   28.110229\n",
            "Epoch: 725 [40100/50000 (80%)]  \tLoss:   89.588593\trec:   61.621552\tkl:   27.967037\n",
            "====> Epoch: 725 Average train loss: 89.3100\n",
            "====> Validation set loss: 92.5280\n",
            "====> Validation set kl: 27.6071\n",
            "Epoch: 726 [  100/50000 ( 0%)]  \tLoss:   94.520248\trec:   65.502739\tkl:   29.017513\n",
            "Epoch: 726 [10100/50000 (20%)]  \tLoss:   92.041443\trec:   63.830769\tkl:   28.210676\n",
            "Epoch: 726 [20100/50000 (40%)]  \tLoss:   91.679298\trec:   62.717033\tkl:   28.962255\n",
            "Epoch: 726 [30100/50000 (60%)]  \tLoss:   91.185722\trec:   62.879421\tkl:   28.306303\n",
            "Epoch: 726 [40100/50000 (80%)]  \tLoss:   90.430679\trec:   61.998661\tkl:   28.432016\n",
            "====> Epoch: 726 Average train loss: 89.3071\n",
            "====> Validation set loss: 92.3879\n",
            "====> Validation set kl: 27.6396\n",
            "Epoch: 727 [  100/50000 ( 0%)]  \tLoss:   87.175934\trec:   59.397419\tkl:   27.778511\n",
            "Epoch: 727 [10100/50000 (20%)]  \tLoss:   87.540268\trec:   59.567490\tkl:   27.972786\n",
            "Epoch: 727 [20100/50000 (40%)]  \tLoss:   91.869698\trec:   63.123749\tkl:   28.745947\n",
            "Epoch: 727 [30100/50000 (60%)]  \tLoss:   89.289467\trec:   61.531319\tkl:   27.758156\n",
            "Epoch: 727 [40100/50000 (80%)]  \tLoss:   89.707260\trec:   62.079903\tkl:   27.627363\n",
            "====> Epoch: 727 Average train loss: 89.2987\n",
            "====> Validation set loss: 92.4095\n",
            "====> Validation set kl: 27.8072\n",
            "Epoch: 728 [  100/50000 ( 0%)]  \tLoss:   88.036942\trec:   60.554844\tkl:   27.482100\n",
            "Epoch: 728 [10100/50000 (20%)]  \tLoss:   87.254761\trec:   60.056755\tkl:   27.198009\n",
            "Epoch: 728 [20100/50000 (40%)]  \tLoss:   89.734764\trec:   61.441208\tkl:   28.293549\n",
            "Epoch: 728 [30100/50000 (60%)]  \tLoss:   90.486931\trec:   62.825325\tkl:   27.661604\n",
            "Epoch: 728 [40100/50000 (80%)]  \tLoss:   90.952950\trec:   63.643513\tkl:   27.309427\n",
            "====> Epoch: 728 Average train loss: 89.2966\n",
            "====> Validation set loss: 92.4934\n",
            "====> Validation set kl: 27.6079\n",
            "Epoch: 729 [  100/50000 ( 0%)]  \tLoss:   90.268288\trec:   62.235275\tkl:   28.033010\n",
            "Epoch: 729 [10100/50000 (20%)]  \tLoss:   88.897736\trec:   62.009560\tkl:   26.888168\n",
            "Epoch: 729 [20100/50000 (40%)]  \tLoss:   89.227066\trec:   61.244511\tkl:   27.982553\n",
            "Epoch: 729 [30100/50000 (60%)]  \tLoss:   91.593506\trec:   62.977421\tkl:   28.616085\n",
            "Epoch: 729 [40100/50000 (80%)]  \tLoss:   94.822983\trec:   65.800865\tkl:   29.022123\n",
            "====> Epoch: 729 Average train loss: 89.3016\n",
            "====> Validation set loss: 92.4569\n",
            "====> Validation set kl: 27.8040\n",
            "Epoch: 730 [  100/50000 ( 0%)]  \tLoss:   91.400917\trec:   62.351109\tkl:   29.049814\n",
            "Epoch: 730 [10100/50000 (20%)]  \tLoss:   86.412888\trec:   58.468708\tkl:   27.944180\n",
            "Epoch: 730 [20100/50000 (40%)]  \tLoss:   92.232849\trec:   64.527336\tkl:   27.705513\n",
            "Epoch: 730 [30100/50000 (60%)]  \tLoss:   91.985489\trec:   63.803719\tkl:   28.181772\n",
            "Epoch: 730 [40100/50000 (80%)]  \tLoss:   89.323097\trec:   61.326279\tkl:   27.996817\n",
            "====> Epoch: 730 Average train loss: 89.2935\n",
            "====> Validation set loss: 92.3672\n",
            "====> Validation set kl: 27.7940\n",
            "Epoch: 731 [  100/50000 ( 0%)]  \tLoss:   85.848434\trec:   58.926208\tkl:   26.922226\n",
            "Epoch: 731 [10100/50000 (20%)]  \tLoss:   88.579117\trec:   61.013344\tkl:   27.565773\n",
            "Epoch: 731 [20100/50000 (40%)]  \tLoss:   88.482719\trec:   60.964626\tkl:   27.518095\n",
            "Epoch: 731 [30100/50000 (60%)]  \tLoss:   91.318161\trec:   62.465706\tkl:   28.852453\n",
            "Epoch: 731 [40100/50000 (80%)]  \tLoss:   92.925095\trec:   64.003983\tkl:   28.921116\n",
            "====> Epoch: 731 Average train loss: 89.2804\n",
            "====> Validation set loss: 92.3797\n",
            "====> Validation set kl: 27.6926\n",
            "Epoch: 732 [  100/50000 ( 0%)]  \tLoss:   85.481186\trec:   58.054600\tkl:   27.426592\n",
            "Epoch: 732 [10100/50000 (20%)]  \tLoss:   90.413864\trec:   62.913750\tkl:   27.500116\n",
            "Epoch: 732 [20100/50000 (40%)]  \tLoss:   87.911621\trec:   60.577526\tkl:   27.334093\n",
            "Epoch: 732 [30100/50000 (60%)]  \tLoss:   88.636658\trec:   60.676704\tkl:   27.959951\n",
            "Epoch: 732 [40100/50000 (80%)]  \tLoss:   91.494370\trec:   64.040123\tkl:   27.454252\n",
            "====> Epoch: 732 Average train loss: 89.2663\n",
            "====> Validation set loss: 92.4758\n",
            "====> Validation set kl: 27.5384\n",
            "Epoch: 733 [  100/50000 ( 0%)]  \tLoss:   87.828178\trec:   60.577473\tkl:   27.250702\n",
            "Epoch: 733 [10100/50000 (20%)]  \tLoss:   88.624626\trec:   61.913662\tkl:   26.710966\n",
            "Epoch: 733 [20100/50000 (40%)]  \tLoss:   89.188789\trec:   61.234364\tkl:   27.954424\n",
            "Epoch: 733 [30100/50000 (60%)]  \tLoss:   91.643845\trec:   63.653728\tkl:   27.990114\n",
            "Epoch: 733 [40100/50000 (80%)]  \tLoss:   90.422134\trec:   62.896641\tkl:   27.525496\n",
            "====> Epoch: 733 Average train loss: 89.2732\n",
            "====> Validation set loss: 92.4001\n",
            "====> Validation set kl: 27.6743\n",
            "Epoch: 734 [  100/50000 ( 0%)]  \tLoss:   91.631805\trec:   62.904125\tkl:   28.727680\n",
            "Epoch: 734 [10100/50000 (20%)]  \tLoss:   82.935738\trec:   56.114563\tkl:   26.821175\n",
            "Epoch: 734 [20100/50000 (40%)]  \tLoss:   85.829063\trec:   59.021862\tkl:   26.807198\n",
            "Epoch: 734 [30100/50000 (60%)]  \tLoss:   90.580467\trec:   62.010906\tkl:   28.569563\n",
            "Epoch: 734 [40100/50000 (80%)]  \tLoss:   88.825417\trec:   61.636932\tkl:   27.188484\n",
            "====> Epoch: 734 Average train loss: 89.2940\n",
            "====> Validation set loss: 92.2707\n",
            "====> Validation set kl: 27.6488\n",
            "Epoch: 735 [  100/50000 ( 0%)]  \tLoss:   90.879654\trec:   62.363327\tkl:   28.516327\n",
            "Epoch: 735 [10100/50000 (20%)]  \tLoss:   92.497597\trec:   64.212891\tkl:   28.284704\n",
            "Epoch: 735 [20100/50000 (40%)]  \tLoss:   87.841759\trec:   60.349743\tkl:   27.492006\n",
            "Epoch: 735 [30100/50000 (60%)]  \tLoss:   89.191071\trec:   60.780838\tkl:   28.410236\n",
            "Epoch: 735 [40100/50000 (80%)]  \tLoss:   87.397202\trec:   60.173904\tkl:   27.223303\n",
            "====> Epoch: 735 Average train loss: 89.2673\n",
            "====> Validation set loss: 92.3464\n",
            "====> Validation set kl: 27.7216\n",
            "Epoch: 736 [  100/50000 ( 0%)]  \tLoss:   92.119606\trec:   63.323689\tkl:   28.795912\n",
            "Epoch: 736 [10100/50000 (20%)]  \tLoss:   91.960075\trec:   63.779411\tkl:   28.180658\n",
            "Epoch: 736 [20100/50000 (40%)]  \tLoss:   86.552742\trec:   60.418308\tkl:   26.134430\n",
            "Epoch: 736 [30100/50000 (60%)]  \tLoss:   89.352203\trec:   62.543449\tkl:   26.808760\n",
            "Epoch: 736 [40100/50000 (80%)]  \tLoss:   87.656578\trec:   60.129501\tkl:   27.527079\n",
            "====> Epoch: 736 Average train loss: 89.2981\n",
            "====> Validation set loss: 92.4828\n",
            "====> Validation set kl: 27.8233\n",
            "Epoch: 737 [  100/50000 ( 0%)]  \tLoss:   87.804390\trec:   59.752331\tkl:   28.052063\n",
            "Epoch: 737 [10100/50000 (20%)]  \tLoss:   86.891792\trec:   60.235985\tkl:   26.655815\n",
            "Epoch: 737 [20100/50000 (40%)]  \tLoss:   87.371857\trec:   60.097664\tkl:   27.274187\n",
            "Epoch: 737 [30100/50000 (60%)]  \tLoss:   89.601479\trec:   61.217793\tkl:   28.383696\n",
            "Epoch: 737 [40100/50000 (80%)]  \tLoss:   88.563667\trec:   61.232361\tkl:   27.331310\n",
            "====> Epoch: 737 Average train loss: 89.2643\n",
            "====> Validation set loss: 92.5353\n",
            "====> Validation set kl: 28.0505\n",
            "Epoch: 738 [  100/50000 ( 0%)]  \tLoss:   94.456726\trec:   64.761650\tkl:   29.695074\n",
            "Epoch: 738 [10100/50000 (20%)]  \tLoss:   92.117958\trec:   63.624180\tkl:   28.493782\n",
            "Epoch: 738 [20100/50000 (40%)]  \tLoss:   89.609703\trec:   61.938274\tkl:   27.671431\n",
            "Epoch: 738 [30100/50000 (60%)]  \tLoss:   86.946182\trec:   60.221394\tkl:   26.724785\n",
            "Epoch: 738 [40100/50000 (80%)]  \tLoss:   88.656502\trec:   60.186180\tkl:   28.470320\n",
            "====> Epoch: 738 Average train loss: 89.2808\n",
            "====> Validation set loss: 92.4603\n",
            "====> Validation set kl: 27.9194\n",
            "Epoch: 739 [  100/50000 ( 0%)]  \tLoss:   90.254745\trec:   61.980732\tkl:   28.274008\n",
            "Epoch: 739 [10100/50000 (20%)]  \tLoss:   86.784683\trec:   60.006992\tkl:   26.777695\n",
            "Epoch: 739 [20100/50000 (40%)]  \tLoss:   87.586929\trec:   60.095798\tkl:   27.491127\n",
            "Epoch: 739 [30100/50000 (60%)]  \tLoss:   87.817078\trec:   59.821480\tkl:   27.995602\n",
            "Epoch: 739 [40100/50000 (80%)]  \tLoss:   89.076660\trec:   61.796112\tkl:   27.280540\n",
            "====> Epoch: 739 Average train loss: 89.2610\n",
            "====> Validation set loss: 92.4370\n",
            "====> Validation set kl: 27.7755\n",
            "Epoch: 740 [  100/50000 ( 0%)]  \tLoss:   88.131523\trec:   59.874149\tkl:   28.257376\n",
            "Epoch: 740 [10100/50000 (20%)]  \tLoss:   88.362419\trec:   60.520603\tkl:   27.841810\n",
            "Epoch: 740 [20100/50000 (40%)]  \tLoss:   87.570045\trec:   60.508102\tkl:   27.061943\n",
            "Epoch: 740 [30100/50000 (60%)]  \tLoss:   87.191071\trec:   59.951405\tkl:   27.239662\n",
            "Epoch: 740 [40100/50000 (80%)]  \tLoss:   86.833969\trec:   59.370220\tkl:   27.463755\n",
            "====> Epoch: 740 Average train loss: 89.2657\n",
            "====> Validation set loss: 92.4019\n",
            "====> Validation set kl: 27.8818\n",
            "Epoch: 741 [  100/50000 ( 0%)]  \tLoss:   89.368004\trec:   61.118328\tkl:   28.249680\n",
            "Epoch: 741 [10100/50000 (20%)]  \tLoss:   85.943817\trec:   59.277245\tkl:   26.666573\n",
            "Epoch: 741 [20100/50000 (40%)]  \tLoss:   89.069801\trec:   61.520615\tkl:   27.549187\n",
            "Epoch: 741 [30100/50000 (60%)]  \tLoss:   89.508347\trec:   61.885124\tkl:   27.623222\n",
            "Epoch: 741 [40100/50000 (80%)]  \tLoss:   88.962524\trec:   61.611485\tkl:   27.351048\n",
            "====> Epoch: 741 Average train loss: 89.2629\n",
            "====> Validation set loss: 92.3895\n",
            "====> Validation set kl: 27.5266\n",
            "Epoch: 742 [  100/50000 ( 0%)]  \tLoss:   87.186333\trec:   60.227581\tkl:   26.958754\n",
            "Epoch: 742 [10100/50000 (20%)]  \tLoss:   86.363533\trec:   58.715565\tkl:   27.647970\n",
            "Epoch: 742 [20100/50000 (40%)]  \tLoss:   90.096832\trec:   61.590420\tkl:   28.506418\n",
            "Epoch: 742 [30100/50000 (60%)]  \tLoss:   87.928238\trec:   60.681187\tkl:   27.247053\n",
            "Epoch: 742 [40100/50000 (80%)]  \tLoss:   84.470947\trec:   57.570560\tkl:   26.900383\n",
            "====> Epoch: 742 Average train loss: 89.2609\n",
            "====> Validation set loss: 92.3210\n",
            "====> Validation set kl: 27.5529\n",
            "Epoch: 743 [  100/50000 ( 0%)]  \tLoss:   84.854073\trec:   57.196571\tkl:   27.657497\n",
            "Epoch: 743 [10100/50000 (20%)]  \tLoss:   89.873497\trec:   61.858799\tkl:   28.014696\n",
            "Epoch: 743 [20100/50000 (40%)]  \tLoss:   87.166977\trec:   60.748028\tkl:   26.418955\n",
            "Epoch: 743 [30100/50000 (60%)]  \tLoss:   92.957832\trec:   64.167488\tkl:   28.790344\n",
            "Epoch: 743 [40100/50000 (80%)]  \tLoss:   89.775993\trec:   60.901230\tkl:   28.874769\n",
            "====> Epoch: 743 Average train loss: 89.2603\n",
            "====> Validation set loss: 92.4286\n",
            "====> Validation set kl: 27.5839\n",
            "Epoch: 744 [  100/50000 ( 0%)]  \tLoss:   91.353249\trec:   63.872425\tkl:   27.480822\n",
            "Epoch: 744 [10100/50000 (20%)]  \tLoss:   89.523354\trec:   61.490780\tkl:   28.032576\n",
            "Epoch: 744 [20100/50000 (40%)]  \tLoss:   92.097008\trec:   64.141281\tkl:   27.955732\n",
            "Epoch: 744 [30100/50000 (60%)]  \tLoss:   87.357712\trec:   59.804329\tkl:   27.553381\n",
            "Epoch: 744 [40100/50000 (80%)]  \tLoss:   86.122147\trec:   59.173820\tkl:   26.948322\n",
            "====> Epoch: 744 Average train loss: 89.2748\n",
            "====> Validation set loss: 92.4143\n",
            "====> Validation set kl: 27.7091\n",
            "Epoch: 745 [  100/50000 ( 0%)]  \tLoss:   89.777748\trec:   61.481873\tkl:   28.295874\n",
            "Epoch: 745 [10100/50000 (20%)]  \tLoss:   88.122009\trec:   60.916782\tkl:   27.205223\n",
            "Epoch: 745 [20100/50000 (40%)]  \tLoss:   91.038246\trec:   62.231018\tkl:   28.807230\n",
            "Epoch: 745 [30100/50000 (60%)]  \tLoss:   91.554184\trec:   62.889183\tkl:   28.665005\n",
            "Epoch: 745 [40100/50000 (80%)]  \tLoss:   88.079842\trec:   61.258202\tkl:   26.821640\n",
            "====> Epoch: 745 Average train loss: 89.2583\n",
            "====> Validation set loss: 92.4527\n",
            "====> Validation set kl: 27.5510\n",
            "Epoch: 746 [  100/50000 ( 0%)]  \tLoss:   92.660873\trec:   64.112587\tkl:   28.548288\n",
            "Epoch: 746 [10100/50000 (20%)]  \tLoss:   89.719307\trec:   61.037224\tkl:   28.682079\n",
            "Epoch: 746 [20100/50000 (40%)]  \tLoss:   91.385605\trec:   63.502480\tkl:   27.883125\n",
            "Epoch: 746 [30100/50000 (60%)]  \tLoss:   89.984619\trec:   61.466850\tkl:   28.517765\n",
            "Epoch: 746 [40100/50000 (80%)]  \tLoss:   90.707733\trec:   62.579861\tkl:   28.127876\n",
            "====> Epoch: 746 Average train loss: 89.2390\n",
            "====> Validation set loss: 92.3399\n",
            "====> Validation set kl: 27.7323\n",
            "Epoch: 747 [  100/50000 ( 0%)]  \tLoss:   89.151772\trec:   61.540440\tkl:   27.611341\n",
            "Epoch: 747 [10100/50000 (20%)]  \tLoss:   89.912140\trec:   62.071083\tkl:   27.841057\n",
            "Epoch: 747 [20100/50000 (40%)]  \tLoss:   86.565392\trec:   58.800819\tkl:   27.764566\n",
            "Epoch: 747 [30100/50000 (60%)]  \tLoss:   91.294571\trec:   61.772083\tkl:   29.522490\n",
            "Epoch: 747 [40100/50000 (80%)]  \tLoss:   91.424980\trec:   63.690937\tkl:   27.734037\n",
            "====> Epoch: 747 Average train loss: 89.2376\n",
            "====> Validation set loss: 92.5565\n",
            "====> Validation set kl: 27.6818\n",
            "Epoch: 748 [  100/50000 ( 0%)]  \tLoss:   91.105820\trec:   61.846611\tkl:   29.259209\n",
            "Epoch: 748 [10100/50000 (20%)]  \tLoss:   88.968925\trec:   60.825081\tkl:   28.143839\n",
            "Epoch: 748 [20100/50000 (40%)]  \tLoss:   89.985451\trec:   61.076717\tkl:   28.908726\n",
            "Epoch: 748 [30100/50000 (60%)]  \tLoss:   85.867928\trec:   58.352371\tkl:   27.515560\n",
            "Epoch: 748 [40100/50000 (80%)]  \tLoss:   88.277634\trec:   60.811489\tkl:   27.466148\n",
            "====> Epoch: 748 Average train loss: 89.2545\n",
            "====> Validation set loss: 92.3864\n",
            "====> Validation set kl: 27.6021\n",
            "Epoch: 749 [  100/50000 ( 0%)]  \tLoss:   87.531425\trec:   59.249325\tkl:   28.282101\n",
            "Epoch: 749 [10100/50000 (20%)]  \tLoss:   91.567657\trec:   63.769295\tkl:   27.798353\n",
            "Epoch: 749 [20100/50000 (40%)]  \tLoss:   90.348709\trec:   62.615955\tkl:   27.732750\n",
            "Epoch: 749 [30100/50000 (60%)]  \tLoss:   87.337051\trec:   59.389130\tkl:   27.947924\n",
            "Epoch: 749 [40100/50000 (80%)]  \tLoss:   91.883705\trec:   63.487705\tkl:   28.396009\n",
            "====> Epoch: 749 Average train loss: 89.2214\n",
            "====> Validation set loss: 92.4923\n",
            "====> Validation set kl: 27.7982\n",
            "Epoch: 750 [  100/50000 ( 0%)]  \tLoss:   90.996803\trec:   62.545399\tkl:   28.451408\n",
            "Epoch: 750 [10100/50000 (20%)]  \tLoss:   88.040993\trec:   60.642693\tkl:   27.398294\n",
            "Epoch: 750 [20100/50000 (40%)]  \tLoss:   87.358543\trec:   59.818958\tkl:   27.539585\n",
            "Epoch: 750 [30100/50000 (60%)]  \tLoss:   91.984352\trec:   63.172226\tkl:   28.812130\n",
            "Epoch: 750 [40100/50000 (80%)]  \tLoss:   91.185196\trec:   62.497742\tkl:   28.687450\n",
            "====> Epoch: 750 Average train loss: 89.2387\n",
            "====> Validation set loss: 92.4281\n",
            "====> Validation set kl: 27.5928\n",
            "Epoch: 751 [  100/50000 ( 0%)]  \tLoss:   87.282265\trec:   60.930176\tkl:   26.352091\n",
            "Epoch: 751 [10100/50000 (20%)]  \tLoss:   87.079704\trec:   59.854588\tkl:   27.225119\n",
            "Epoch: 751 [20100/50000 (40%)]  \tLoss:   88.309097\trec:   61.389553\tkl:   26.919548\n",
            "Epoch: 751 [30100/50000 (60%)]  \tLoss:   86.910210\trec:   60.019989\tkl:   26.890228\n",
            "Epoch: 751 [40100/50000 (80%)]  \tLoss:   89.839096\trec:   61.982212\tkl:   27.856886\n",
            "====> Epoch: 751 Average train loss: 89.2540\n",
            "====> Validation set loss: 92.3878\n",
            "====> Validation set kl: 27.7631\n",
            "Epoch: 752 [  100/50000 ( 0%)]  \tLoss:   90.824234\trec:   61.932533\tkl:   28.891699\n",
            "Epoch: 752 [10100/50000 (20%)]  \tLoss:   88.062126\trec:   59.948425\tkl:   28.113703\n",
            "Epoch: 752 [20100/50000 (40%)]  \tLoss:   90.395103\trec:   62.671394\tkl:   27.723707\n",
            "Epoch: 752 [30100/50000 (60%)]  \tLoss:   90.366646\trec:   63.119164\tkl:   27.247484\n",
            "Epoch: 752 [40100/50000 (80%)]  \tLoss:   91.392387\trec:   63.297775\tkl:   28.094614\n",
            "====> Epoch: 752 Average train loss: 89.2207\n",
            "====> Validation set loss: 92.3752\n",
            "====> Validation set kl: 27.7042\n",
            "Epoch: 753 [  100/50000 ( 0%)]  \tLoss:   89.202744\trec:   61.471092\tkl:   27.731651\n",
            "Epoch: 753 [10100/50000 (20%)]  \tLoss:   91.714760\trec:   63.577263\tkl:   28.137505\n",
            "Epoch: 753 [20100/50000 (40%)]  \tLoss:   87.271919\trec:   59.073616\tkl:   28.198303\n",
            "Epoch: 753 [30100/50000 (60%)]  \tLoss:   91.580811\trec:   62.979492\tkl:   28.601315\n",
            "Epoch: 753 [40100/50000 (80%)]  \tLoss:   89.733887\trec:   61.993053\tkl:   27.740824\n",
            "====> Epoch: 753 Average train loss: 89.2404\n",
            "====> Validation set loss: 92.4358\n",
            "====> Validation set kl: 27.7815\n",
            "Epoch: 754 [  100/50000 ( 0%)]  \tLoss:   87.225021\trec:   59.755360\tkl:   27.469656\n",
            "Epoch: 754 [10100/50000 (20%)]  \tLoss:   91.554550\trec:   63.147148\tkl:   28.407404\n",
            "Epoch: 754 [20100/50000 (40%)]  \tLoss:   87.760574\trec:   59.977978\tkl:   27.782597\n",
            "Epoch: 754 [30100/50000 (60%)]  \tLoss:   89.890678\trec:   62.863327\tkl:   27.027353\n",
            "Epoch: 754 [40100/50000 (80%)]  \tLoss:   88.687889\trec:   60.531738\tkl:   28.156155\n",
            "====> Epoch: 754 Average train loss: 89.2242\n",
            "====> Validation set loss: 92.4584\n",
            "====> Validation set kl: 27.6984\n",
            "Epoch: 755 [  100/50000 ( 0%)]  \tLoss:   87.725037\trec:   59.999981\tkl:   27.725063\n",
            "Epoch: 755 [10100/50000 (20%)]  \tLoss:   90.147575\trec:   62.336044\tkl:   27.811527\n",
            "Epoch: 755 [20100/50000 (40%)]  \tLoss:   89.512344\trec:   61.339481\tkl:   28.172859\n",
            "Epoch: 755 [30100/50000 (60%)]  \tLoss:   86.345779\trec:   59.092266\tkl:   27.253510\n",
            "Epoch: 755 [40100/50000 (80%)]  \tLoss:   89.889336\trec:   61.533665\tkl:   28.355673\n",
            "====> Epoch: 755 Average train loss: 89.2425\n",
            "====> Validation set loss: 92.4930\n",
            "====> Validation set kl: 27.5812\n",
            "Epoch: 756 [  100/50000 ( 0%)]  \tLoss:   93.341354\trec:   64.222687\tkl:   29.118670\n",
            "Epoch: 756 [10100/50000 (20%)]  \tLoss:   89.055855\trec:   61.801147\tkl:   27.254711\n",
            "Epoch: 756 [20100/50000 (40%)]  \tLoss:   87.703590\trec:   60.110706\tkl:   27.592882\n",
            "Epoch: 756 [30100/50000 (60%)]  \tLoss:   90.303238\trec:   62.322720\tkl:   27.980524\n",
            "Epoch: 756 [40100/50000 (80%)]  \tLoss:   85.562485\trec:   59.526623\tkl:   26.035864\n",
            "====> Epoch: 756 Average train loss: 89.1998\n",
            "====> Validation set loss: 92.4780\n",
            "====> Validation set kl: 27.6315\n",
            "Epoch: 757 [  100/50000 ( 0%)]  \tLoss:   91.210213\trec:   62.526073\tkl:   28.684139\n",
            "Epoch: 757 [10100/50000 (20%)]  \tLoss:   91.162949\trec:   62.512199\tkl:   28.650747\n",
            "Epoch: 757 [20100/50000 (40%)]  \tLoss:   88.348457\trec:   60.938122\tkl:   27.410332\n",
            "Epoch: 757 [30100/50000 (60%)]  \tLoss:   84.341431\trec:   57.461895\tkl:   26.879538\n",
            "Epoch: 757 [40100/50000 (80%)]  \tLoss:   93.231407\trec:   64.833252\tkl:   28.398151\n",
            "====> Epoch: 757 Average train loss: 89.1949\n",
            "====> Validation set loss: 92.5357\n",
            "====> Validation set kl: 27.9144\n",
            "Epoch: 758 [  100/50000 ( 0%)]  \tLoss:   88.405457\trec:   59.827152\tkl:   28.578304\n",
            "Epoch: 758 [10100/50000 (20%)]  \tLoss:   89.230194\trec:   61.040928\tkl:   28.189266\n",
            "Epoch: 758 [20100/50000 (40%)]  \tLoss:   90.058708\trec:   62.386814\tkl:   27.671898\n",
            "Epoch: 758 [30100/50000 (60%)]  \tLoss:   93.508263\trec:   64.934418\tkl:   28.573847\n",
            "Epoch: 758 [40100/50000 (80%)]  \tLoss:   87.479752\trec:   60.667538\tkl:   26.812216\n",
            "====> Epoch: 758 Average train loss: 89.2124\n",
            "====> Validation set loss: 92.4537\n",
            "====> Validation set kl: 27.6283\n",
            "Epoch: 759 [  100/50000 ( 0%)]  \tLoss:   90.369286\trec:   62.643997\tkl:   27.725290\n",
            "Epoch: 759 [10100/50000 (20%)]  \tLoss:   90.737350\trec:   62.307606\tkl:   28.429743\n",
            "Epoch: 759 [20100/50000 (40%)]  \tLoss:   89.727829\trec:   62.343758\tkl:   27.384073\n",
            "Epoch: 759 [30100/50000 (60%)]  \tLoss:   90.670593\trec:   62.676640\tkl:   27.993958\n",
            "Epoch: 759 [40100/50000 (80%)]  \tLoss:   86.924393\trec:   59.547173\tkl:   27.377224\n",
            "====> Epoch: 759 Average train loss: 89.1970\n",
            "====> Validation set loss: 92.3659\n",
            "====> Validation set kl: 27.6023\n",
            "Epoch: 760 [  100/50000 ( 0%)]  \tLoss:   86.242409\trec:   58.546654\tkl:   27.695753\n",
            "Epoch: 760 [10100/50000 (20%)]  \tLoss:   91.297394\trec:   63.310226\tkl:   27.987162\n",
            "Epoch: 760 [20100/50000 (40%)]  \tLoss:   90.528282\trec:   62.284744\tkl:   28.243538\n",
            "Epoch: 760 [30100/50000 (60%)]  \tLoss:   90.496010\trec:   62.171879\tkl:   28.324141\n",
            "Epoch: 760 [40100/50000 (80%)]  \tLoss:   89.588799\trec:   61.506237\tkl:   28.082556\n",
            "====> Epoch: 760 Average train loss: 89.2124\n",
            "====> Validation set loss: 92.2915\n",
            "====> Validation set kl: 27.6492\n",
            "Epoch: 761 [  100/50000 ( 0%)]  \tLoss:   93.617935\trec:   64.953308\tkl:   28.664625\n",
            "Epoch: 761 [10100/50000 (20%)]  \tLoss:   88.397011\trec:   61.028610\tkl:   27.368393\n",
            "Epoch: 761 [20100/50000 (40%)]  \tLoss:   88.824989\trec:   61.299892\tkl:   27.525095\n",
            "Epoch: 761 [30100/50000 (60%)]  \tLoss:   89.498375\trec:   61.682522\tkl:   27.815851\n",
            "Epoch: 761 [40100/50000 (80%)]  \tLoss:   91.478943\trec:   62.744568\tkl:   28.734375\n",
            "====> Epoch: 761 Average train loss: 89.2205\n",
            "====> Validation set loss: 92.3922\n",
            "====> Validation set kl: 27.8472\n",
            "Epoch: 762 [  100/50000 ( 0%)]  \tLoss:   90.475006\trec:   62.323112\tkl:   28.151896\n",
            "Epoch: 762 [10100/50000 (20%)]  \tLoss:   87.322296\trec:   60.891190\tkl:   26.431101\n",
            "Epoch: 762 [20100/50000 (40%)]  \tLoss:   86.410576\trec:   59.736187\tkl:   26.674389\n",
            "Epoch: 762 [30100/50000 (60%)]  \tLoss:   88.801033\trec:   60.581856\tkl:   28.219181\n",
            "Epoch: 762 [40100/50000 (80%)]  \tLoss:   89.658707\trec:   62.470078\tkl:   27.188635\n",
            "====> Epoch: 762 Average train loss: 89.2018\n",
            "====> Validation set loss: 92.3734\n",
            "====> Validation set kl: 27.5883\n",
            "Epoch: 763 [  100/50000 ( 0%)]  \tLoss:   89.409920\trec:   62.023754\tkl:   27.386164\n",
            "Epoch: 763 [10100/50000 (20%)]  \tLoss:   91.888687\trec:   63.031933\tkl:   28.856752\n",
            "Epoch: 763 [20100/50000 (40%)]  \tLoss:   89.674942\trec:   62.438034\tkl:   27.236906\n",
            "Epoch: 763 [30100/50000 (60%)]  \tLoss:   91.197334\trec:   62.912514\tkl:   28.284821\n",
            "Epoch: 763 [40100/50000 (80%)]  \tLoss:   89.847458\trec:   61.989643\tkl:   27.857817\n",
            "====> Epoch: 763 Average train loss: 89.1869\n",
            "====> Validation set loss: 92.5034\n",
            "====> Validation set kl: 27.6477\n",
            "Epoch: 764 [  100/50000 ( 0%)]  \tLoss:   90.153549\trec:   62.738071\tkl:   27.415485\n",
            "Epoch: 764 [10100/50000 (20%)]  \tLoss:   91.441063\trec:   64.304337\tkl:   27.136728\n",
            "Epoch: 764 [20100/50000 (40%)]  \tLoss:   88.406723\trec:   60.031197\tkl:   28.375534\n",
            "Epoch: 764 [30100/50000 (60%)]  \tLoss:   92.481697\trec:   63.361240\tkl:   29.120459\n",
            "Epoch: 764 [40100/50000 (80%)]  \tLoss:   87.929901\trec:   59.927567\tkl:   28.002333\n",
            "====> Epoch: 764 Average train loss: 89.2086\n",
            "====> Validation set loss: 92.3807\n",
            "====> Validation set kl: 27.7604\n",
            "Epoch: 765 [  100/50000 ( 0%)]  \tLoss:   89.147057\trec:   61.184292\tkl:   27.962770\n",
            "Epoch: 765 [10100/50000 (20%)]  \tLoss:   93.209549\trec:   64.838051\tkl:   28.371504\n",
            "Epoch: 765 [20100/50000 (40%)]  \tLoss:   86.509377\trec:   58.603325\tkl:   27.906054\n",
            "Epoch: 765 [30100/50000 (60%)]  \tLoss:   88.306503\trec:   61.260399\tkl:   27.046104\n",
            "Epoch: 765 [40100/50000 (80%)]  \tLoss:   92.754181\trec:   64.042580\tkl:   28.711599\n",
            "====> Epoch: 765 Average train loss: 89.1869\n",
            "====> Validation set loss: 92.4141\n",
            "====> Validation set kl: 27.7465\n",
            "Epoch: 766 [  100/50000 ( 0%)]  \tLoss:   89.651527\trec:   61.587009\tkl:   28.064522\n",
            "Epoch: 766 [10100/50000 (20%)]  \tLoss:   86.479317\trec:   58.781673\tkl:   27.697639\n",
            "Epoch: 766 [20100/50000 (40%)]  \tLoss:   90.220001\trec:   61.824745\tkl:   28.395254\n",
            "Epoch: 766 [30100/50000 (60%)]  \tLoss:   88.251656\trec:   61.049706\tkl:   27.201956\n",
            "Epoch: 766 [40100/50000 (80%)]  \tLoss:   88.521423\trec:   60.649998\tkl:   27.871426\n",
            "====> Epoch: 766 Average train loss: 89.1735\n",
            "====> Validation set loss: 92.4456\n",
            "====> Validation set kl: 27.7941\n",
            "Epoch: 767 [  100/50000 ( 0%)]  \tLoss:   86.072594\trec:   58.837925\tkl:   27.234674\n",
            "Epoch: 767 [10100/50000 (20%)]  \tLoss:   87.098557\trec:   59.131474\tkl:   27.967081\n",
            "Epoch: 767 [20100/50000 (40%)]  \tLoss:   83.550964\trec:   56.774258\tkl:   26.776709\n",
            "Epoch: 767 [30100/50000 (60%)]  \tLoss:   91.296532\trec:   62.752304\tkl:   28.544228\n",
            "Epoch: 767 [40100/50000 (80%)]  \tLoss:   86.822517\trec:   59.557186\tkl:   27.265329\n",
            "====> Epoch: 767 Average train loss: 89.1894\n",
            "====> Validation set loss: 92.3176\n",
            "====> Validation set kl: 27.8930\n",
            "Epoch: 768 [  100/50000 ( 0%)]  \tLoss:   90.546638\trec:   62.521893\tkl:   28.024746\n",
            "Epoch: 768 [10100/50000 (20%)]  \tLoss:   89.818787\trec:   61.299072\tkl:   28.519718\n",
            "Epoch: 768 [20100/50000 (40%)]  \tLoss:   86.937187\trec:   59.533493\tkl:   27.403694\n",
            "Epoch: 768 [30100/50000 (60%)]  \tLoss:   89.681572\trec:   61.607494\tkl:   28.074076\n",
            "Epoch: 768 [40100/50000 (80%)]  \tLoss:   88.429039\trec:   60.458965\tkl:   27.970076\n",
            "====> Epoch: 768 Average train loss: 89.1735\n",
            "====> Validation set loss: 92.4128\n",
            "====> Validation set kl: 27.6059\n",
            "Epoch: 769 [  100/50000 ( 0%)]  \tLoss:   91.278084\trec:   62.751030\tkl:   28.527050\n",
            "Epoch: 769 [10100/50000 (20%)]  \tLoss:   92.488670\trec:   63.947552\tkl:   28.541117\n",
            "Epoch: 769 [20100/50000 (40%)]  \tLoss:   90.494507\trec:   63.020126\tkl:   27.474388\n",
            "Epoch: 769 [30100/50000 (60%)]  \tLoss:   91.491089\trec:   63.390251\tkl:   28.100842\n",
            "Epoch: 769 [40100/50000 (80%)]  \tLoss:   90.165581\trec:   62.719204\tkl:   27.446384\n",
            "====> Epoch: 769 Average train loss: 89.1951\n",
            "====> Validation set loss: 92.3936\n",
            "====> Validation set kl: 27.7318\n",
            "Epoch: 770 [  100/50000 ( 0%)]  \tLoss:   88.288994\trec:   59.037460\tkl:   29.251530\n",
            "Epoch: 770 [10100/50000 (20%)]  \tLoss:   90.800346\trec:   62.998955\tkl:   27.801401\n",
            "Epoch: 770 [20100/50000 (40%)]  \tLoss:   92.061714\trec:   63.719265\tkl:   28.342447\n",
            "Epoch: 770 [30100/50000 (60%)]  \tLoss:   86.911705\trec:   59.336479\tkl:   27.575226\n",
            "Epoch: 770 [40100/50000 (80%)]  \tLoss:   89.634956\trec:   61.993134\tkl:   27.641829\n",
            "====> Epoch: 770 Average train loss: 89.1746\n",
            "====> Validation set loss: 92.4268\n",
            "====> Validation set kl: 27.6958\n",
            "Epoch: 771 [  100/50000 ( 0%)]  \tLoss:   88.335670\trec:   60.312675\tkl:   28.023001\n",
            "Epoch: 771 [10100/50000 (20%)]  \tLoss:   91.283966\trec:   62.954678\tkl:   28.329285\n",
            "Epoch: 771 [20100/50000 (40%)]  \tLoss:   92.408867\trec:   63.690487\tkl:   28.718380\n",
            "Epoch: 771 [30100/50000 (60%)]  \tLoss:   88.228180\trec:   61.221268\tkl:   27.006910\n",
            "Epoch: 771 [40100/50000 (80%)]  \tLoss:   92.249474\trec:   64.086082\tkl:   28.163387\n",
            "====> Epoch: 771 Average train loss: 89.1775\n",
            "====> Validation set loss: 92.4585\n",
            "====> Validation set kl: 27.7653\n",
            "Epoch: 772 [  100/50000 ( 0%)]  \tLoss:   90.551071\trec:   62.534801\tkl:   28.016272\n",
            "Epoch: 772 [10100/50000 (20%)]  \tLoss:   88.677460\trec:   60.867401\tkl:   27.810053\n",
            "Epoch: 772 [20100/50000 (40%)]  \tLoss:   91.834259\trec:   62.771542\tkl:   29.062710\n",
            "Epoch: 772 [30100/50000 (60%)]  \tLoss:   86.237656\trec:   59.214836\tkl:   27.022814\n",
            "Epoch: 772 [40100/50000 (80%)]  \tLoss:   87.015366\trec:   58.746834\tkl:   28.268538\n",
            "====> Epoch: 772 Average train loss: 89.1847\n",
            "====> Validation set loss: 92.4133\n",
            "====> Validation set kl: 27.5552\n",
            "Epoch: 773 [  100/50000 ( 0%)]  \tLoss:   92.163795\trec:   63.257072\tkl:   28.906723\n",
            "Epoch: 773 [10100/50000 (20%)]  \tLoss:   87.549431\trec:   59.731449\tkl:   27.817984\n",
            "Epoch: 773 [20100/50000 (40%)]  \tLoss:   84.529198\trec:   57.443535\tkl:   27.085659\n",
            "Epoch: 773 [30100/50000 (60%)]  \tLoss:   86.493690\trec:   59.663975\tkl:   26.829716\n",
            "Epoch: 773 [40100/50000 (80%)]  \tLoss:   85.570480\trec:   58.528877\tkl:   27.041601\n",
            "====> Epoch: 773 Average train loss: 89.1603\n",
            "====> Validation set loss: 92.3833\n",
            "====> Validation set kl: 27.7305\n",
            "Epoch: 774 [  100/50000 ( 0%)]  \tLoss:   89.040367\trec:   61.586308\tkl:   27.454060\n",
            "Epoch: 774 [10100/50000 (20%)]  \tLoss:   90.637886\trec:   62.370327\tkl:   28.267569\n",
            "Epoch: 774 [20100/50000 (40%)]  \tLoss:   90.562965\trec:   61.416454\tkl:   29.146507\n",
            "Epoch: 774 [30100/50000 (60%)]  \tLoss:   90.195770\trec:   62.668110\tkl:   27.527658\n",
            "Epoch: 774 [40100/50000 (80%)]  \tLoss:   89.107208\trec:   62.131443\tkl:   26.975760\n",
            "====> Epoch: 774 Average train loss: 89.1840\n",
            "====> Validation set loss: 92.3518\n",
            "====> Validation set kl: 27.5027\n",
            "Epoch: 775 [  100/50000 ( 0%)]  \tLoss:   87.334923\trec:   59.962585\tkl:   27.372334\n",
            "Epoch: 775 [10100/50000 (20%)]  \tLoss:   86.481941\trec:   58.891888\tkl:   27.590054\n",
            "Epoch: 775 [20100/50000 (40%)]  \tLoss:   87.404449\trec:   60.251080\tkl:   27.153374\n",
            "Epoch: 775 [30100/50000 (60%)]  \tLoss:   91.507637\trec:   63.457722\tkl:   28.049913\n",
            "Epoch: 775 [40100/50000 (80%)]  \tLoss:   92.118301\trec:   63.767971\tkl:   28.350327\n",
            "====> Epoch: 775 Average train loss: 89.1441\n",
            "====> Validation set loss: 92.3686\n",
            "====> Validation set kl: 27.8466\n",
            "Epoch: 776 [  100/50000 ( 0%)]  \tLoss:   86.805099\trec:   60.034985\tkl:   26.770107\n",
            "Epoch: 776 [10100/50000 (20%)]  \tLoss:   88.808609\trec:   61.180023\tkl:   27.628593\n",
            "Epoch: 776 [20100/50000 (40%)]  \tLoss:   88.072411\trec:   60.512585\tkl:   27.559822\n",
            "Epoch: 776 [30100/50000 (60%)]  \tLoss:   87.616570\trec:   59.742657\tkl:   27.873915\n",
            "Epoch: 776 [40100/50000 (80%)]  \tLoss:   85.267632\trec:   57.935360\tkl:   27.332279\n",
            "====> Epoch: 776 Average train loss: 89.1617\n",
            "====> Validation set loss: 92.3955\n",
            "====> Validation set kl: 27.7017\n",
            "Epoch: 777 [  100/50000 ( 0%)]  \tLoss:   90.935692\trec:   62.687656\tkl:   28.248037\n",
            "Epoch: 777 [10100/50000 (20%)]  \tLoss:   85.250038\trec:   58.245853\tkl:   27.004185\n",
            "Epoch: 777 [20100/50000 (40%)]  \tLoss:   85.983696\trec:   58.713799\tkl:   27.269899\n",
            "Epoch: 777 [30100/50000 (60%)]  \tLoss:   87.994179\trec:   60.415417\tkl:   27.578758\n",
            "Epoch: 777 [40100/50000 (80%)]  \tLoss:   90.237343\trec:   62.073456\tkl:   28.163887\n",
            "====> Epoch: 777 Average train loss: 89.1765\n",
            "====> Validation set loss: 92.4770\n",
            "====> Validation set kl: 27.7840\n",
            "Epoch: 778 [  100/50000 ( 0%)]  \tLoss:   89.047104\trec:   60.859688\tkl:   28.187418\n",
            "Epoch: 778 [10100/50000 (20%)]  \tLoss:   90.394356\trec:   62.568035\tkl:   27.826313\n",
            "Epoch: 778 [20100/50000 (40%)]  \tLoss:   87.370918\trec:   60.029392\tkl:   27.341518\n",
            "Epoch: 778 [30100/50000 (60%)]  \tLoss:   92.229996\trec:   63.673641\tkl:   28.556356\n",
            "Epoch: 778 [40100/50000 (80%)]  \tLoss:   86.689880\trec:   59.434402\tkl:   27.255472\n",
            "====> Epoch: 778 Average train loss: 89.1769\n",
            "====> Validation set loss: 92.3981\n",
            "====> Validation set kl: 27.6372\n",
            "Epoch: 779 [  100/50000 ( 0%)]  \tLoss:   87.726250\trec:   60.093895\tkl:   27.632351\n",
            "Epoch: 779 [10100/50000 (20%)]  \tLoss:   88.380600\trec:   60.855228\tkl:   27.525377\n",
            "Epoch: 779 [20100/50000 (40%)]  \tLoss:   89.312950\trec:   61.431641\tkl:   27.881313\n",
            "Epoch: 779 [30100/50000 (60%)]  \tLoss:   91.280678\trec:   63.415573\tkl:   27.865107\n",
            "Epoch: 779 [40100/50000 (80%)]  \tLoss:   88.751320\trec:   60.519325\tkl:   28.231995\n",
            "====> Epoch: 779 Average train loss: 89.1485\n",
            "====> Validation set loss: 92.2466\n",
            "====> Validation set kl: 27.8435\n",
            "Epoch: 780 [  100/50000 ( 0%)]  \tLoss:   86.545456\trec:   59.636288\tkl:   26.909170\n",
            "Epoch: 780 [10100/50000 (20%)]  \tLoss:   86.071716\trec:   59.133160\tkl:   26.938560\n",
            "Epoch: 780 [20100/50000 (40%)]  \tLoss:   86.336197\trec:   59.434013\tkl:   26.902184\n",
            "Epoch: 780 [30100/50000 (60%)]  \tLoss:   91.295509\trec:   63.253807\tkl:   28.041698\n",
            "Epoch: 780 [40100/50000 (80%)]  \tLoss:   92.630165\trec:   64.296997\tkl:   28.333160\n",
            "====> Epoch: 780 Average train loss: 89.1436\n",
            "====> Validation set loss: 92.3875\n",
            "====> Validation set kl: 27.8983\n",
            "Epoch: 781 [  100/50000 ( 0%)]  \tLoss:   85.497810\trec:   58.748825\tkl:   26.748985\n",
            "Epoch: 781 [10100/50000 (20%)]  \tLoss:   88.712898\trec:   60.788486\tkl:   27.924416\n",
            "Epoch: 781 [20100/50000 (40%)]  \tLoss:   91.039375\trec:   62.339207\tkl:   28.700171\n",
            "Epoch: 781 [30100/50000 (60%)]  \tLoss:   86.349998\trec:   59.473240\tkl:   26.876760\n",
            "Epoch: 781 [40100/50000 (80%)]  \tLoss:   88.540154\trec:   60.719746\tkl:   27.820408\n",
            "====> Epoch: 781 Average train loss: 89.1564\n",
            "====> Validation set loss: 92.3078\n",
            "====> Validation set kl: 27.7632\n",
            "Epoch: 782 [  100/50000 ( 0%)]  \tLoss:   89.123375\trec:   60.729164\tkl:   28.394209\n",
            "Epoch: 782 [10100/50000 (20%)]  \tLoss:   87.160538\trec:   58.798504\tkl:   28.362028\n",
            "Epoch: 782 [20100/50000 (40%)]  \tLoss:   89.294640\trec:   61.378960\tkl:   27.915676\n",
            "Epoch: 782 [30100/50000 (60%)]  \tLoss:   87.192993\trec:   59.616333\tkl:   27.576668\n",
            "Epoch: 782 [40100/50000 (80%)]  \tLoss:   92.435898\trec:   63.572079\tkl:   28.863821\n",
            "====> Epoch: 782 Average train loss: 89.1515\n",
            "====> Validation set loss: 92.3979\n",
            "====> Validation set kl: 27.9447\n",
            "Epoch: 783 [  100/50000 ( 0%)]  \tLoss:   89.613396\trec:   61.402824\tkl:   28.210566\n",
            "Epoch: 783 [10100/50000 (20%)]  \tLoss:   91.015778\trec:   62.904705\tkl:   28.111078\n",
            "Epoch: 783 [20100/50000 (40%)]  \tLoss:   87.866135\trec:   60.176571\tkl:   27.689566\n",
            "Epoch: 783 [30100/50000 (60%)]  \tLoss:   87.745956\trec:   59.958969\tkl:   27.786989\n",
            "Epoch: 783 [40100/50000 (80%)]  \tLoss:   90.318161\trec:   61.778915\tkl:   28.539249\n",
            "====> Epoch: 783 Average train loss: 89.1528\n",
            "====> Validation set loss: 92.4029\n",
            "====> Validation set kl: 27.7668\n",
            "Epoch: 784 [  100/50000 ( 0%)]  \tLoss:   87.583771\trec:   60.404404\tkl:   27.179359\n",
            "Epoch: 784 [10100/50000 (20%)]  \tLoss:   91.348633\trec:   62.965687\tkl:   28.382948\n",
            "Epoch: 784 [20100/50000 (40%)]  \tLoss:   91.185036\trec:   63.436768\tkl:   27.748276\n",
            "Epoch: 784 [30100/50000 (60%)]  \tLoss:   88.063034\trec:   60.478252\tkl:   27.584782\n",
            "Epoch: 784 [40100/50000 (80%)]  \tLoss:   86.371033\trec:   59.889729\tkl:   26.481302\n",
            "====> Epoch: 784 Average train loss: 89.1463\n",
            "====> Validation set loss: 92.4922\n",
            "====> Validation set kl: 27.7375\n",
            "Epoch: 785 [  100/50000 ( 0%)]  \tLoss:   85.740738\trec:   59.331776\tkl:   26.408966\n",
            "Epoch: 785 [10100/50000 (20%)]  \tLoss:   89.540977\trec:   61.492626\tkl:   28.048344\n",
            "Epoch: 785 [20100/50000 (40%)]  \tLoss:   90.711304\trec:   61.922710\tkl:   28.788597\n",
            "Epoch: 785 [30100/50000 (60%)]  \tLoss:   89.801025\trec:   62.693783\tkl:   27.107239\n",
            "Epoch: 785 [40100/50000 (80%)]  \tLoss:   89.077827\trec:   62.540077\tkl:   26.537750\n",
            "====> Epoch: 785 Average train loss: 89.1469\n",
            "====> Validation set loss: 92.3676\n",
            "====> Validation set kl: 27.8928\n",
            "Epoch: 786 [  100/50000 ( 0%)]  \tLoss:   90.525925\trec:   61.996346\tkl:   28.529577\n",
            "Epoch: 786 [10100/50000 (20%)]  \tLoss:   88.130936\trec:   59.648308\tkl:   28.482632\n",
            "Epoch: 786 [20100/50000 (40%)]  \tLoss:   86.337120\trec:   59.284676\tkl:   27.052439\n",
            "Epoch: 786 [30100/50000 (60%)]  \tLoss:   94.476929\trec:   65.881943\tkl:   28.594984\n",
            "Epoch: 786 [40100/50000 (80%)]  \tLoss:   91.966385\trec:   63.578159\tkl:   28.388227\n",
            "====> Epoch: 786 Average train loss: 89.1184\n",
            "====> Validation set loss: 92.3538\n",
            "====> Validation set kl: 27.7725\n",
            "Epoch: 787 [  100/50000 ( 0%)]  \tLoss:   88.912125\trec:   60.100727\tkl:   28.811403\n",
            "Epoch: 787 [10100/50000 (20%)]  \tLoss:   89.742958\trec:   60.596149\tkl:   29.146803\n",
            "Epoch: 787 [20100/50000 (40%)]  \tLoss:   89.029968\trec:   61.141079\tkl:   27.888891\n",
            "Epoch: 787 [30100/50000 (60%)]  \tLoss:   89.793121\trec:   61.660091\tkl:   28.133032\n",
            "Epoch: 787 [40100/50000 (80%)]  \tLoss:   85.868179\trec:   58.242599\tkl:   27.625584\n",
            "====> Epoch: 787 Average train loss: 89.1475\n",
            "====> Validation set loss: 92.3580\n",
            "====> Validation set kl: 27.6965\n",
            "Epoch: 788 [  100/50000 ( 0%)]  \tLoss:   88.976776\trec:   61.266464\tkl:   27.710314\n",
            "Epoch: 788 [10100/50000 (20%)]  \tLoss:   91.248085\trec:   62.507401\tkl:   28.740681\n",
            "Epoch: 788 [20100/50000 (40%)]  \tLoss:   92.916443\trec:   64.911758\tkl:   28.004679\n",
            "Epoch: 788 [30100/50000 (60%)]  \tLoss:   93.099869\trec:   64.575516\tkl:   28.524353\n",
            "Epoch: 788 [40100/50000 (80%)]  \tLoss:   89.330132\trec:   61.504490\tkl:   27.825644\n",
            "====> Epoch: 788 Average train loss: 89.1326\n",
            "====> Validation set loss: 92.4314\n",
            "====> Validation set kl: 27.9062\n",
            "Epoch: 789 [  100/50000 ( 0%)]  \tLoss:   87.508514\trec:   59.068924\tkl:   28.439594\n",
            "Epoch: 789 [10100/50000 (20%)]  \tLoss:   91.150352\trec:   62.463768\tkl:   28.686581\n",
            "Epoch: 789 [20100/50000 (40%)]  \tLoss:   86.797966\trec:   59.451817\tkl:   27.346148\n",
            "Epoch: 789 [30100/50000 (60%)]  \tLoss:   92.383522\trec:   63.479031\tkl:   28.904491\n",
            "Epoch: 789 [40100/50000 (80%)]  \tLoss:   90.542809\trec:   61.466732\tkl:   29.076084\n",
            "====> Epoch: 789 Average train loss: 89.1471\n",
            "====> Validation set loss: 92.3774\n",
            "====> Validation set kl: 27.8073\n",
            "Epoch: 790 [  100/50000 ( 0%)]  \tLoss:   93.429527\trec:   64.395874\tkl:   29.033651\n",
            "Epoch: 790 [10100/50000 (20%)]  \tLoss:   88.794594\trec:   60.408943\tkl:   28.385654\n",
            "Epoch: 790 [20100/50000 (40%)]  \tLoss:   90.178902\trec:   63.297485\tkl:   26.881422\n",
            "Epoch: 790 [30100/50000 (60%)]  \tLoss:   86.334412\trec:   58.994125\tkl:   27.340288\n",
            "Epoch: 790 [40100/50000 (80%)]  \tLoss:   87.235069\trec:   59.454453\tkl:   27.780617\n",
            "====> Epoch: 790 Average train loss: 89.1234\n",
            "====> Validation set loss: 92.4155\n",
            "====> Validation set kl: 27.7094\n",
            "Epoch: 791 [  100/50000 ( 0%)]  \tLoss:   86.808174\trec:   59.536747\tkl:   27.271425\n",
            "Epoch: 791 [10100/50000 (20%)]  \tLoss:   87.842995\trec:   60.642071\tkl:   27.200928\n",
            "Epoch: 791 [20100/50000 (40%)]  \tLoss:   87.620255\trec:   59.541149\tkl:   28.079105\n",
            "Epoch: 791 [30100/50000 (60%)]  \tLoss:   92.763283\trec:   64.145538\tkl:   28.617746\n",
            "Epoch: 791 [40100/50000 (80%)]  \tLoss:   91.323402\trec:   62.168709\tkl:   29.154694\n",
            "====> Epoch: 791 Average train loss: 89.1154\n",
            "====> Validation set loss: 92.4180\n",
            "====> Validation set kl: 27.8644\n",
            "Epoch: 792 [  100/50000 ( 0%)]  \tLoss:   90.724648\trec:   62.149414\tkl:   28.575233\n",
            "Epoch: 792 [10100/50000 (20%)]  \tLoss:   87.417801\trec:   58.979355\tkl:   28.438444\n",
            "Epoch: 792 [20100/50000 (40%)]  \tLoss:   87.952995\trec:   59.744999\tkl:   28.207994\n",
            "Epoch: 792 [30100/50000 (60%)]  \tLoss:   93.351578\trec:   63.928093\tkl:   29.423483\n",
            "Epoch: 792 [40100/50000 (80%)]  \tLoss:   89.234077\trec:   61.940720\tkl:   27.293364\n",
            "====> Epoch: 792 Average train loss: 89.1333\n",
            "====> Validation set loss: 92.4149\n",
            "====> Validation set kl: 27.7572\n",
            "Epoch: 793 [  100/50000 ( 0%)]  \tLoss:   90.977409\trec:   62.047039\tkl:   28.930370\n",
            "Epoch: 793 [10100/50000 (20%)]  \tLoss:   85.698669\trec:   59.239853\tkl:   26.458813\n",
            "Epoch: 793 [20100/50000 (40%)]  \tLoss:   85.512657\trec:   58.569080\tkl:   26.943571\n",
            "Epoch: 793 [30100/50000 (60%)]  \tLoss:   90.219910\trec:   63.270809\tkl:   26.949100\n",
            "Epoch: 793 [40100/50000 (80%)]  \tLoss:   88.051231\trec:   61.113972\tkl:   26.937260\n",
            "====> Epoch: 793 Average train loss: 89.1419\n",
            "====> Validation set loss: 92.3704\n",
            "====> Validation set kl: 27.8838\n",
            "Epoch: 794 [  100/50000 ( 0%)]  \tLoss:   88.407501\trec:   60.100334\tkl:   28.307167\n",
            "Epoch: 794 [10100/50000 (20%)]  \tLoss:   88.445412\trec:   60.638855\tkl:   27.806549\n",
            "Epoch: 794 [20100/50000 (40%)]  \tLoss:   90.430977\trec:   62.316010\tkl:   28.114965\n",
            "Epoch: 794 [30100/50000 (60%)]  \tLoss:   90.378540\trec:   62.374950\tkl:   28.003595\n",
            "Epoch: 794 [40100/50000 (80%)]  \tLoss:   93.377335\trec:   64.803001\tkl:   28.574327\n",
            "====> Epoch: 794 Average train loss: 89.1109\n",
            "====> Validation set loss: 92.3481\n",
            "====> Validation set kl: 27.5802\n",
            "Epoch: 795 [  100/50000 ( 0%)]  \tLoss:   87.552292\trec:   60.155830\tkl:   27.396461\n",
            "Epoch: 795 [10100/50000 (20%)]  \tLoss:   89.162071\trec:   60.097725\tkl:   29.064341\n",
            "Epoch: 795 [20100/50000 (40%)]  \tLoss:   86.232635\trec:   59.375889\tkl:   26.856745\n",
            "Epoch: 795 [30100/50000 (60%)]  \tLoss:   88.795532\trec:   60.492752\tkl:   28.302786\n",
            "Epoch: 795 [40100/50000 (80%)]  \tLoss:   89.648926\trec:   61.589828\tkl:   28.059095\n",
            "====> Epoch: 795 Average train loss: 89.1105\n",
            "====> Validation set loss: 92.3090\n",
            "====> Validation set kl: 27.8547\n",
            "Epoch: 796 [  100/50000 ( 0%)]  \tLoss:   86.302116\trec:   58.419384\tkl:   27.882730\n",
            "Epoch: 796 [10100/50000 (20%)]  \tLoss:   90.469429\trec:   62.069668\tkl:   28.399765\n",
            "Epoch: 796 [20100/50000 (40%)]  \tLoss:   91.416710\trec:   62.948914\tkl:   28.467791\n",
            "Epoch: 796 [30100/50000 (60%)]  \tLoss:   88.090431\trec:   60.735409\tkl:   27.355021\n",
            "Epoch: 796 [40100/50000 (80%)]  \tLoss:   92.625313\trec:   64.109024\tkl:   28.516287\n",
            "====> Epoch: 796 Average train loss: 89.1244\n",
            "====> Validation set loss: 92.3722\n",
            "====> Validation set kl: 27.8277\n",
            "Epoch: 797 [  100/50000 ( 0%)]  \tLoss:   92.453583\trec:   63.371796\tkl:   29.081787\n",
            "Epoch: 797 [10100/50000 (20%)]  \tLoss:   91.746933\trec:   63.330002\tkl:   28.416931\n",
            "Epoch: 797 [20100/50000 (40%)]  \tLoss:   87.279404\trec:   59.726364\tkl:   27.553034\n",
            "Epoch: 797 [30100/50000 (60%)]  \tLoss:   90.499481\trec:   62.543621\tkl:   27.955862\n",
            "Epoch: 797 [40100/50000 (80%)]  \tLoss:   87.325897\trec:   60.540291\tkl:   26.785610\n",
            "====> Epoch: 797 Average train loss: 89.1215\n",
            "====> Validation set loss: 92.3783\n",
            "====> Validation set kl: 27.7426\n",
            "Epoch: 798 [  100/50000 ( 0%)]  \tLoss:   88.902496\trec:   60.825527\tkl:   28.076973\n",
            "Epoch: 798 [10100/50000 (20%)]  \tLoss:   87.765007\trec:   60.132187\tkl:   27.632824\n",
            "Epoch: 798 [20100/50000 (40%)]  \tLoss:   88.323769\trec:   60.717888\tkl:   27.605873\n",
            "Epoch: 798 [30100/50000 (60%)]  \tLoss:   92.126808\trec:   64.526863\tkl:   27.599941\n",
            "Epoch: 798 [40100/50000 (80%)]  \tLoss:   91.772217\trec:   62.889526\tkl:   28.882692\n",
            "====> Epoch: 798 Average train loss: 89.1041\n",
            "====> Validation set loss: 92.3995\n",
            "====> Validation set kl: 27.7550\n",
            "Epoch: 799 [  100/50000 ( 0%)]  \tLoss:   88.341278\trec:   60.281326\tkl:   28.059948\n",
            "Epoch: 799 [10100/50000 (20%)]  \tLoss:   89.396225\trec:   60.687855\tkl:   28.708368\n",
            "Epoch: 799 [20100/50000 (40%)]  \tLoss:   91.192047\trec:   62.641785\tkl:   28.550261\n",
            "Epoch: 799 [30100/50000 (60%)]  \tLoss:   91.238083\trec:   62.545940\tkl:   28.692141\n",
            "Epoch: 799 [40100/50000 (80%)]  \tLoss:   89.002022\trec:   60.885689\tkl:   28.116329\n",
            "====> Epoch: 799 Average train loss: 89.1135\n",
            "====> Validation set loss: 92.3817\n",
            "====> Validation set kl: 27.8600\n",
            "Epoch: 800 [  100/50000 ( 0%)]  \tLoss:   93.524834\trec:   64.583603\tkl:   28.941233\n",
            "Epoch: 800 [10100/50000 (20%)]  \tLoss:   90.160721\trec:   61.766308\tkl:   28.394419\n",
            "Epoch: 800 [20100/50000 (40%)]  \tLoss:   88.286240\trec:   61.057777\tkl:   27.228462\n",
            "Epoch: 800 [30100/50000 (60%)]  \tLoss:   90.826424\trec:   61.942909\tkl:   28.883514\n",
            "Epoch: 800 [40100/50000 (80%)]  \tLoss:   88.193054\trec:   60.884636\tkl:   27.308420\n",
            "====> Epoch: 800 Average train loss: 89.1021\n",
            "====> Validation set loss: 92.4673\n",
            "====> Validation set kl: 27.7284\n",
            "Epoch: 801 [  100/50000 ( 0%)]  \tLoss:   89.264565\trec:   61.461063\tkl:   27.803501\n",
            "Epoch: 801 [10100/50000 (20%)]  \tLoss:   90.197716\trec:   62.097328\tkl:   28.100380\n",
            "Epoch: 801 [20100/50000 (40%)]  \tLoss:   90.941734\trec:   63.034451\tkl:   27.907290\n",
            "Epoch: 801 [30100/50000 (60%)]  \tLoss:   91.118805\trec:   62.786865\tkl:   28.331947\n",
            "Epoch: 801 [40100/50000 (80%)]  \tLoss:   87.440094\trec:   59.674496\tkl:   27.765602\n",
            "====> Epoch: 801 Average train loss: 89.0950\n",
            "====> Validation set loss: 92.3484\n",
            "====> Validation set kl: 27.5862\n",
            "Epoch: 802 [  100/50000 ( 0%)]  \tLoss:   90.769920\trec:   62.950546\tkl:   27.819370\n",
            "Epoch: 802 [10100/50000 (20%)]  \tLoss:   88.034813\trec:   60.885742\tkl:   27.149069\n",
            "Epoch: 802 [20100/50000 (40%)]  \tLoss:   88.533485\trec:   60.931034\tkl:   27.602448\n",
            "Epoch: 802 [30100/50000 (60%)]  \tLoss:   89.401573\trec:   61.363808\tkl:   28.037760\n",
            "Epoch: 802 [40100/50000 (80%)]  \tLoss:   88.704025\trec:   60.515995\tkl:   28.188023\n",
            "====> Epoch: 802 Average train loss: 89.0881\n",
            "====> Validation set loss: 92.4263\n",
            "====> Validation set kl: 27.7486\n",
            "Epoch: 803 [  100/50000 ( 0%)]  \tLoss:   89.308998\trec:   61.424744\tkl:   27.884260\n",
            "Epoch: 803 [10100/50000 (20%)]  \tLoss:   88.221199\trec:   60.573242\tkl:   27.647961\n",
            "Epoch: 803 [20100/50000 (40%)]  \tLoss:   85.711479\trec:   59.513142\tkl:   26.198339\n",
            "Epoch: 803 [30100/50000 (60%)]  \tLoss:   88.932518\trec:   61.473869\tkl:   27.458647\n",
            "Epoch: 803 [40100/50000 (80%)]  \tLoss:   84.899521\trec:   58.265514\tkl:   26.634007\n",
            "====> Epoch: 803 Average train loss: 89.0990\n",
            "====> Validation set loss: 92.3434\n",
            "====> Validation set kl: 27.7088\n",
            "Epoch: 804 [  100/50000 ( 0%)]  \tLoss:   86.992577\trec:   60.372585\tkl:   26.619995\n",
            "Epoch: 804 [10100/50000 (20%)]  \tLoss:   89.642929\trec:   62.156990\tkl:   27.485937\n",
            "Epoch: 804 [20100/50000 (40%)]  \tLoss:   90.898552\trec:   62.511433\tkl:   28.387119\n",
            "Epoch: 804 [30100/50000 (60%)]  \tLoss:   89.142494\trec:   60.698677\tkl:   28.443825\n",
            "Epoch: 804 [40100/50000 (80%)]  \tLoss:   84.635666\trec:   57.846542\tkl:   26.789124\n",
            "====> Epoch: 804 Average train loss: 89.0916\n",
            "====> Validation set loss: 92.3810\n",
            "====> Validation set kl: 27.8486\n",
            "Epoch: 805 [  100/50000 ( 0%)]  \tLoss:   91.762436\trec:   62.831345\tkl:   28.931091\n",
            "Epoch: 805 [10100/50000 (20%)]  \tLoss:   88.195175\trec:   60.650513\tkl:   27.544662\n",
            "Epoch: 805 [20100/50000 (40%)]  \tLoss:   87.619354\trec:   60.364052\tkl:   27.255302\n",
            "Epoch: 805 [30100/50000 (60%)]  \tLoss:   89.650749\trec:   61.140320\tkl:   28.510429\n",
            "Epoch: 805 [40100/50000 (80%)]  \tLoss:   88.409157\trec:   61.212490\tkl:   27.196672\n",
            "====> Epoch: 805 Average train loss: 89.0719\n",
            "====> Validation set loss: 92.3724\n",
            "====> Validation set kl: 27.8218\n",
            "Epoch: 806 [  100/50000 ( 0%)]  \tLoss:   84.591110\trec:   57.882839\tkl:   26.708265\n",
            "Epoch: 806 [10100/50000 (20%)]  \tLoss:   89.361656\trec:   62.343460\tkl:   27.018192\n",
            "Epoch: 806 [20100/50000 (40%)]  \tLoss:   87.641968\trec:   59.481453\tkl:   28.160519\n",
            "Epoch: 806 [30100/50000 (60%)]  \tLoss:   92.056725\trec:   62.943157\tkl:   29.113565\n",
            "Epoch: 806 [40100/50000 (80%)]  \tLoss:   90.908104\trec:   62.724766\tkl:   28.183342\n",
            "====> Epoch: 806 Average train loss: 89.0794\n",
            "====> Validation set loss: 92.2298\n",
            "====> Validation set kl: 27.7384\n",
            "Epoch: 807 [  100/50000 ( 0%)]  \tLoss:   88.619850\trec:   60.342163\tkl:   28.277689\n",
            "Epoch: 807 [10100/50000 (20%)]  \tLoss:   90.024239\trec:   61.000107\tkl:   29.024136\n",
            "Epoch: 807 [20100/50000 (40%)]  \tLoss:   88.766197\trec:   60.246128\tkl:   28.520075\n",
            "Epoch: 807 [30100/50000 (60%)]  \tLoss:   91.846924\trec:   63.448486\tkl:   28.398438\n",
            "Epoch: 807 [40100/50000 (80%)]  \tLoss:   86.703484\trec:   59.152454\tkl:   27.551029\n",
            "====> Epoch: 807 Average train loss: 89.0738\n",
            "====> Validation set loss: 92.2995\n",
            "====> Validation set kl: 27.8773\n",
            "Epoch: 808 [  100/50000 ( 0%)]  \tLoss:   87.738884\trec:   59.632053\tkl:   28.106834\n",
            "Epoch: 808 [10100/50000 (20%)]  \tLoss:   86.607323\trec:   59.833794\tkl:   26.773529\n",
            "Epoch: 808 [20100/50000 (40%)]  \tLoss:   85.917664\trec:   59.224041\tkl:   26.693621\n",
            "Epoch: 808 [30100/50000 (60%)]  \tLoss:   94.076424\trec:   65.539932\tkl:   28.536493\n",
            "Epoch: 808 [40100/50000 (80%)]  \tLoss:   85.453026\trec:   58.933441\tkl:   26.519588\n",
            "====> Epoch: 808 Average train loss: 89.0866\n",
            "====> Validation set loss: 92.3427\n",
            "====> Validation set kl: 27.6590\n",
            "Epoch: 809 [  100/50000 ( 0%)]  \tLoss:   86.862144\trec:   58.717224\tkl:   28.144918\n",
            "Epoch: 809 [10100/50000 (20%)]  \tLoss:   90.518242\trec:   62.171291\tkl:   28.346943\n",
            "Epoch: 809 [20100/50000 (40%)]  \tLoss:   90.382080\trec:   63.263748\tkl:   27.118326\n",
            "Epoch: 809 [30100/50000 (60%)]  \tLoss:   85.996262\trec:   58.798641\tkl:   27.197618\n",
            "Epoch: 809 [40100/50000 (80%)]  \tLoss:   90.985992\trec:   62.862797\tkl:   28.123196\n",
            "====> Epoch: 809 Average train loss: 89.0865\n",
            "====> Validation set loss: 92.3427\n",
            "====> Validation set kl: 27.7631\n",
            "Epoch: 810 [  100/50000 ( 0%)]  \tLoss:   90.793472\trec:   62.385254\tkl:   28.408222\n",
            "Epoch: 810 [10100/50000 (20%)]  \tLoss:   89.407478\trec:   61.454903\tkl:   27.952583\n",
            "Epoch: 810 [20100/50000 (40%)]  \tLoss:   87.628601\trec:   60.594543\tkl:   27.034060\n",
            "Epoch: 810 [30100/50000 (60%)]  \tLoss:   86.854393\trec:   58.730808\tkl:   28.123589\n",
            "Epoch: 810 [40100/50000 (80%)]  \tLoss:   91.753716\trec:   63.285576\tkl:   28.468142\n",
            "====> Epoch: 810 Average train loss: 89.0731\n",
            "====> Validation set loss: 92.3625\n",
            "====> Validation set kl: 27.8398\n",
            "Epoch: 811 [  100/50000 ( 0%)]  \tLoss:   85.177811\trec:   57.926025\tkl:   27.251789\n",
            "Epoch: 811 [10100/50000 (20%)]  \tLoss:   92.056953\trec:   63.618992\tkl:   28.437954\n",
            "Epoch: 811 [20100/50000 (40%)]  \tLoss:   86.396362\trec:   58.972260\tkl:   27.424109\n",
            "Epoch: 811 [30100/50000 (60%)]  \tLoss:   92.089394\trec:   63.570747\tkl:   28.518646\n",
            "Epoch: 811 [40100/50000 (80%)]  \tLoss:   85.109177\trec:   58.087898\tkl:   27.021278\n",
            "====> Epoch: 811 Average train loss: 89.0722\n",
            "====> Validation set loss: 92.3406\n",
            "====> Validation set kl: 27.8965\n",
            "Epoch: 812 [  100/50000 ( 0%)]  \tLoss:   85.734901\trec:   58.248173\tkl:   27.486732\n",
            "Epoch: 812 [10100/50000 (20%)]  \tLoss:   87.454491\trec:   60.280056\tkl:   27.174438\n",
            "Epoch: 812 [20100/50000 (40%)]  \tLoss:   88.792686\trec:   59.815525\tkl:   28.977160\n",
            "Epoch: 812 [30100/50000 (60%)]  \tLoss:   92.756287\trec:   63.699036\tkl:   29.057247\n",
            "Epoch: 812 [40100/50000 (80%)]  \tLoss:   84.644440\trec:   57.018505\tkl:   27.625935\n",
            "====> Epoch: 812 Average train loss: 89.0868\n",
            "====> Validation set loss: 92.4027\n",
            "====> Validation set kl: 27.5523\n",
            "Epoch: 813 [  100/50000 ( 0%)]  \tLoss:   88.215279\trec:   60.815823\tkl:   27.399454\n",
            "Epoch: 813 [10100/50000 (20%)]  \tLoss:   85.858765\trec:   58.557568\tkl:   27.301201\n",
            "Epoch: 813 [20100/50000 (40%)]  \tLoss:   90.018204\trec:   62.460136\tkl:   27.558067\n",
            "Epoch: 813 [30100/50000 (60%)]  \tLoss:   90.437614\trec:   62.377487\tkl:   28.060131\n",
            "Epoch: 813 [40100/50000 (80%)]  \tLoss:   89.009392\trec:   61.437691\tkl:   27.571701\n",
            "====> Epoch: 813 Average train loss: 89.0710\n",
            "====> Validation set loss: 92.2945\n",
            "====> Validation set kl: 27.8569\n",
            "Epoch: 814 [  100/50000 ( 0%)]  \tLoss:   89.295723\trec:   61.529686\tkl:   27.766031\n",
            "Epoch: 814 [10100/50000 (20%)]  \tLoss:   82.780197\trec:   55.820282\tkl:   26.959913\n",
            "Epoch: 814 [20100/50000 (40%)]  \tLoss:   88.362778\trec:   61.244968\tkl:   27.117809\n",
            "Epoch: 814 [30100/50000 (60%)]  \tLoss:   91.435585\trec:   62.746365\tkl:   28.689222\n",
            "Epoch: 814 [40100/50000 (80%)]  \tLoss:   90.939705\trec:   63.528015\tkl:   27.411690\n",
            "====> Epoch: 814 Average train loss: 89.0974\n",
            "====> Validation set loss: 92.3530\n",
            "====> Validation set kl: 27.7384\n",
            "Epoch: 815 [  100/50000 ( 0%)]  \tLoss:   88.331589\trec:   59.864239\tkl:   28.467356\n",
            "Epoch: 815 [10100/50000 (20%)]  \tLoss:   87.957138\trec:   60.118408\tkl:   27.838728\n",
            "Epoch: 815 [20100/50000 (40%)]  \tLoss:   91.128159\trec:   62.661297\tkl:   28.466862\n",
            "Epoch: 815 [30100/50000 (60%)]  \tLoss:   89.968727\trec:   62.092407\tkl:   27.876322\n",
            "Epoch: 815 [40100/50000 (80%)]  \tLoss:   87.048462\trec:   59.341698\tkl:   27.706764\n",
            "====> Epoch: 815 Average train loss: 89.0672\n",
            "====> Validation set loss: 92.2770\n",
            "====> Validation set kl: 27.8015\n",
            "Epoch: 816 [  100/50000 ( 0%)]  \tLoss:   88.326363\trec:   60.701069\tkl:   27.625292\n",
            "Epoch: 816 [10100/50000 (20%)]  \tLoss:   87.493454\trec:   59.708408\tkl:   27.785051\n",
            "Epoch: 816 [20100/50000 (40%)]  \tLoss:   91.682404\trec:   63.570366\tkl:   28.112030\n",
            "Epoch: 816 [30100/50000 (60%)]  \tLoss:   90.676651\trec:   61.719257\tkl:   28.957390\n",
            "Epoch: 816 [40100/50000 (80%)]  \tLoss:   87.953354\trec:   60.573933\tkl:   27.379425\n",
            "====> Epoch: 816 Average train loss: 89.0709\n",
            "====> Validation set loss: 92.4500\n",
            "====> Validation set kl: 27.6601\n",
            "Epoch: 817 [  100/50000 ( 0%)]  \tLoss:   87.560005\trec:   60.008503\tkl:   27.551506\n",
            "Epoch: 817 [10100/50000 (20%)]  \tLoss:   89.492294\trec:   60.771542\tkl:   28.720749\n",
            "Epoch: 817 [20100/50000 (40%)]  \tLoss:   89.080788\trec:   61.795609\tkl:   27.285177\n",
            "Epoch: 817 [30100/50000 (60%)]  \tLoss:   89.432320\trec:   62.036503\tkl:   27.395823\n",
            "Epoch: 817 [40100/50000 (80%)]  \tLoss:   87.872871\trec:   60.496540\tkl:   27.376328\n",
            "====> Epoch: 817 Average train loss: 89.0805\n",
            "====> Validation set loss: 92.2714\n",
            "====> Validation set kl: 27.7765\n",
            "Epoch: 818 [  100/50000 ( 0%)]  \tLoss:   89.445320\trec:   61.254272\tkl:   28.191048\n",
            "Epoch: 818 [10100/50000 (20%)]  \tLoss:   92.182411\trec:   63.121162\tkl:   29.061247\n",
            "Epoch: 818 [20100/50000 (40%)]  \tLoss:   88.232613\trec:   60.965569\tkl:   27.267042\n",
            "Epoch: 818 [30100/50000 (60%)]  \tLoss:   87.303185\trec:   59.373089\tkl:   27.930092\n",
            "Epoch: 818 [40100/50000 (80%)]  \tLoss:   87.587234\trec:   60.351532\tkl:   27.235704\n",
            "====> Epoch: 818 Average train loss: 89.0784\n",
            "====> Validation set loss: 92.3406\n",
            "====> Validation set kl: 27.9072\n",
            "Epoch: 819 [  100/50000 ( 0%)]  \tLoss:   88.316376\trec:   60.098358\tkl:   28.218014\n",
            "Epoch: 819 [10100/50000 (20%)]  \tLoss:   91.015854\trec:   62.332153\tkl:   28.683701\n",
            "Epoch: 819 [20100/50000 (40%)]  \tLoss:   84.888397\trec:   58.672871\tkl:   26.215532\n",
            "Epoch: 819 [30100/50000 (60%)]  \tLoss:   92.540627\trec:   63.911755\tkl:   28.628862\n",
            "Epoch: 819 [40100/50000 (80%)]  \tLoss:   89.283836\trec:   61.335995\tkl:   27.947842\n",
            "====> Epoch: 819 Average train loss: 89.0534\n",
            "====> Validation set loss: 92.3988\n",
            "====> Validation set kl: 27.7809\n",
            "Epoch: 820 [  100/50000 ( 0%)]  \tLoss:   96.486267\trec:   67.558846\tkl:   28.927422\n",
            "Epoch: 820 [10100/50000 (20%)]  \tLoss:   87.911697\trec:   60.437614\tkl:   27.474081\n",
            "Epoch: 820 [20100/50000 (40%)]  \tLoss:   86.849724\trec:   59.504890\tkl:   27.344828\n",
            "Epoch: 820 [30100/50000 (60%)]  \tLoss:   87.674438\trec:   59.645275\tkl:   28.029165\n",
            "Epoch: 820 [40100/50000 (80%)]  \tLoss:   90.233452\trec:   62.420517\tkl:   27.812944\n",
            "====> Epoch: 820 Average train loss: 89.0579\n",
            "====> Validation set loss: 92.4776\n",
            "====> Validation set kl: 27.7133\n",
            "Epoch: 821 [  100/50000 ( 0%)]  \tLoss:   88.030342\trec:   60.834919\tkl:   27.195417\n",
            "Epoch: 821 [10100/50000 (20%)]  \tLoss:   88.415939\trec:   60.514782\tkl:   27.901152\n",
            "Epoch: 821 [20100/50000 (40%)]  \tLoss:   90.722008\trec:   63.219784\tkl:   27.502228\n",
            "Epoch: 821 [30100/50000 (60%)]  \tLoss:   88.953087\trec:   60.278137\tkl:   28.674946\n",
            "Epoch: 821 [40100/50000 (80%)]  \tLoss:   86.304771\trec:   59.562405\tkl:   26.742371\n",
            "====> Epoch: 821 Average train loss: 89.0550\n",
            "====> Validation set loss: 92.2195\n",
            "====> Validation set kl: 27.7979\n",
            "Epoch: 822 [  100/50000 ( 0%)]  \tLoss:   88.845543\trec:   61.101517\tkl:   27.744026\n",
            "Epoch: 822 [10100/50000 (20%)]  \tLoss:   89.593002\trec:   61.676292\tkl:   27.916718\n",
            "Epoch: 822 [20100/50000 (40%)]  \tLoss:   90.003014\trec:   61.533379\tkl:   28.469639\n",
            "Epoch: 822 [30100/50000 (60%)]  \tLoss:   89.409676\trec:   62.353142\tkl:   27.056532\n",
            "Epoch: 822 [40100/50000 (80%)]  \tLoss:   90.089027\trec:   62.159325\tkl:   27.929705\n",
            "====> Epoch: 822 Average train loss: 89.0498\n",
            "====> Validation set loss: 92.3694\n",
            "====> Validation set kl: 27.7646\n",
            "Epoch: 823 [  100/50000 ( 0%)]  \tLoss:   89.894890\trec:   61.656914\tkl:   28.237978\n",
            "Epoch: 823 [10100/50000 (20%)]  \tLoss:   87.451912\trec:   60.038826\tkl:   27.413080\n",
            "Epoch: 823 [20100/50000 (40%)]  \tLoss:   87.847130\trec:   59.612499\tkl:   28.234631\n",
            "Epoch: 823 [30100/50000 (60%)]  \tLoss:   87.939293\trec:   60.103638\tkl:   27.835663\n",
            "Epoch: 823 [40100/50000 (80%)]  \tLoss:   87.924881\trec:   60.851742\tkl:   27.073139\n",
            "====> Epoch: 823 Average train loss: 89.0353\n",
            "====> Validation set loss: 92.3869\n",
            "====> Validation set kl: 27.5616\n",
            "Epoch: 824 [  100/50000 ( 0%)]  \tLoss:   88.412003\trec:   61.363338\tkl:   27.048658\n",
            "Epoch: 824 [10100/50000 (20%)]  \tLoss:   89.837830\trec:   61.865955\tkl:   27.971872\n",
            "Epoch: 824 [20100/50000 (40%)]  \tLoss:   91.053497\trec:   63.401615\tkl:   27.651882\n",
            "Epoch: 824 [30100/50000 (60%)]  \tLoss:   90.441338\trec:   62.177448\tkl:   28.263885\n",
            "Epoch: 824 [40100/50000 (80%)]  \tLoss:   88.866661\trec:   60.824463\tkl:   28.042202\n",
            "====> Epoch: 824 Average train loss: 89.0641\n",
            "====> Validation set loss: 92.3234\n",
            "====> Validation set kl: 27.9485\n",
            "Epoch: 825 [  100/50000 ( 0%)]  \tLoss:   93.607574\trec:   63.769882\tkl:   29.837692\n",
            "Epoch: 825 [10100/50000 (20%)]  \tLoss:   86.565109\trec:   59.884216\tkl:   26.680885\n",
            "Epoch: 825 [20100/50000 (40%)]  \tLoss:   91.515816\trec:   63.567562\tkl:   27.948252\n",
            "Epoch: 825 [30100/50000 (60%)]  \tLoss:   90.535469\trec:   61.748154\tkl:   28.787315\n",
            "Epoch: 825 [40100/50000 (80%)]  \tLoss:   88.290207\trec:   61.240498\tkl:   27.049709\n",
            "====> Epoch: 825 Average train loss: 89.0554\n",
            "====> Validation set loss: 92.3683\n",
            "====> Validation set kl: 27.8254\n",
            "Epoch: 826 [  100/50000 ( 0%)]  \tLoss:   86.889862\trec:   59.564823\tkl:   27.325043\n",
            "Epoch: 826 [10100/50000 (20%)]  \tLoss:   86.735580\trec:   59.399738\tkl:   27.335838\n",
            "Epoch: 826 [20100/50000 (40%)]  \tLoss:   86.129494\trec:   58.917469\tkl:   27.212027\n",
            "Epoch: 826 [30100/50000 (60%)]  \tLoss:   90.618874\trec:   61.629055\tkl:   28.989819\n",
            "Epoch: 826 [40100/50000 (80%)]  \tLoss:   87.516685\trec:   59.513016\tkl:   28.003672\n",
            "====> Epoch: 826 Average train loss: 89.0245\n",
            "====> Validation set loss: 92.3211\n",
            "====> Validation set kl: 27.7316\n",
            "Epoch: 827 [  100/50000 ( 0%)]  \tLoss:   91.441963\trec:   63.214890\tkl:   28.227068\n",
            "Epoch: 827 [10100/50000 (20%)]  \tLoss:   87.573959\trec:   59.394863\tkl:   28.179098\n",
            "Epoch: 827 [20100/50000 (40%)]  \tLoss:   88.152565\trec:   60.068871\tkl:   28.083698\n",
            "Epoch: 827 [30100/50000 (60%)]  \tLoss:   90.985245\trec:   62.620781\tkl:   28.364462\n",
            "Epoch: 827 [40100/50000 (80%)]  \tLoss:   88.434013\trec:   61.352097\tkl:   27.081911\n",
            "====> Epoch: 827 Average train loss: 89.0388\n",
            "====> Validation set loss: 92.3628\n",
            "====> Validation set kl: 27.9263\n",
            "Epoch: 828 [  100/50000 ( 0%)]  \tLoss:   90.250595\trec:   61.971180\tkl:   28.279411\n",
            "Epoch: 828 [10100/50000 (20%)]  \tLoss:   89.108047\trec:   61.085476\tkl:   28.022566\n",
            "Epoch: 828 [20100/50000 (40%)]  \tLoss:   88.280128\trec:   60.829212\tkl:   27.450911\n",
            "Epoch: 828 [30100/50000 (60%)]  \tLoss:   88.701363\trec:   61.079903\tkl:   27.621462\n",
            "Epoch: 828 [40100/50000 (80%)]  \tLoss:   89.141075\trec:   61.010242\tkl:   28.130825\n",
            "====> Epoch: 828 Average train loss: 89.0346\n",
            "====> Validation set loss: 92.3211\n",
            "====> Validation set kl: 27.8331\n",
            "Epoch: 829 [  100/50000 ( 0%)]  \tLoss:   91.671303\trec:   62.442425\tkl:   29.228876\n",
            "Epoch: 829 [10100/50000 (20%)]  \tLoss:   87.202446\trec:   60.213787\tkl:   26.988665\n",
            "Epoch: 829 [20100/50000 (40%)]  \tLoss:   90.303276\trec:   62.461826\tkl:   27.841454\n",
            "Epoch: 829 [30100/50000 (60%)]  \tLoss:   86.997032\trec:   59.813755\tkl:   27.183279\n",
            "Epoch: 829 [40100/50000 (80%)]  \tLoss:   86.791092\trec:   60.293846\tkl:   26.497248\n",
            "====> Epoch: 829 Average train loss: 89.0369\n",
            "====> Validation set loss: 92.3860\n",
            "====> Validation set kl: 27.8857\n",
            "Epoch: 830 [  100/50000 ( 0%)]  \tLoss:   85.850075\trec:   58.108337\tkl:   27.741737\n",
            "Epoch: 830 [10100/50000 (20%)]  \tLoss:   87.117577\trec:   58.929218\tkl:   28.188364\n",
            "Epoch: 830 [20100/50000 (40%)]  \tLoss:   88.742325\trec:   61.393280\tkl:   27.349043\n",
            "Epoch: 830 [30100/50000 (60%)]  \tLoss:   90.009491\trec:   61.543064\tkl:   28.466423\n",
            "Epoch: 830 [40100/50000 (80%)]  \tLoss:   90.829697\trec:   62.522018\tkl:   28.307673\n",
            "====> Epoch: 830 Average train loss: 89.0372\n",
            "====> Validation set loss: 92.2959\n",
            "====> Validation set kl: 27.8195\n",
            "Epoch: 831 [  100/50000 ( 0%)]  \tLoss:   91.438042\trec:   62.299221\tkl:   29.138828\n",
            "Epoch: 831 [10100/50000 (20%)]  \tLoss:   88.672928\trec:   61.433331\tkl:   27.239599\n",
            "Epoch: 831 [20100/50000 (40%)]  \tLoss:   90.034187\trec:   62.029774\tkl:   28.004416\n",
            "Epoch: 831 [30100/50000 (60%)]  \tLoss:   89.554451\trec:   61.534912\tkl:   28.019541\n",
            "Epoch: 831 [40100/50000 (80%)]  \tLoss:   87.090317\trec:   59.386032\tkl:   27.704285\n",
            "====> Epoch: 831 Average train loss: 89.0380\n",
            "====> Validation set loss: 92.4060\n",
            "====> Validation set kl: 27.8837\n",
            "Epoch: 832 [  100/50000 ( 0%)]  \tLoss:   90.625801\trec:   61.820736\tkl:   28.805065\n",
            "Epoch: 832 [10100/50000 (20%)]  \tLoss:   89.726715\trec:   62.737465\tkl:   26.989248\n",
            "Epoch: 832 [20100/50000 (40%)]  \tLoss:   82.109665\trec:   56.108669\tkl:   26.000990\n",
            "Epoch: 832 [30100/50000 (60%)]  \tLoss:   93.276337\trec:   64.694061\tkl:   28.582275\n",
            "Epoch: 832 [40100/50000 (80%)]  \tLoss:   90.884575\trec:   62.082714\tkl:   28.801867\n",
            "====> Epoch: 832 Average train loss: 89.0547\n",
            "====> Validation set loss: 92.3609\n",
            "====> Validation set kl: 27.6404\n",
            "Epoch: 833 [  100/50000 ( 0%)]  \tLoss:   92.022682\trec:   63.592983\tkl:   28.429705\n",
            "Epoch: 833 [10100/50000 (20%)]  \tLoss:   85.620773\trec:   58.363945\tkl:   27.256826\n",
            "Epoch: 833 [20100/50000 (40%)]  \tLoss:   88.567421\trec:   60.988426\tkl:   27.578991\n",
            "Epoch: 833 [30100/50000 (60%)]  \tLoss:   91.455688\trec:   62.092312\tkl:   29.363379\n",
            "Epoch: 833 [40100/50000 (80%)]  \tLoss:   89.749184\trec:   61.303535\tkl:   28.445652\n",
            "====> Epoch: 833 Average train loss: 89.0034\n",
            "====> Validation set loss: 92.3227\n",
            "====> Validation set kl: 27.7949\n",
            "Epoch: 834 [  100/50000 ( 0%)]  \tLoss:   86.762451\trec:   59.449120\tkl:   27.313332\n",
            "Epoch: 834 [10100/50000 (20%)]  \tLoss:   91.024841\trec:   62.146893\tkl:   28.877947\n",
            "Epoch: 834 [20100/50000 (40%)]  \tLoss:   90.761307\trec:   62.060539\tkl:   28.700766\n",
            "Epoch: 834 [30100/50000 (60%)]  \tLoss:   90.420845\trec:   62.659222\tkl:   27.761627\n",
            "Epoch: 834 [40100/50000 (80%)]  \tLoss:   91.103203\trec:   62.955276\tkl:   28.147924\n",
            "====> Epoch: 834 Average train loss: 89.0495\n",
            "====> Validation set loss: 92.3019\n",
            "====> Validation set kl: 27.8100\n",
            "Epoch: 835 [  100/50000 ( 0%)]  \tLoss:   88.404411\trec:   60.763329\tkl:   27.641079\n",
            "Epoch: 835 [10100/50000 (20%)]  \tLoss:   87.475136\trec:   59.821133\tkl:   27.653999\n",
            "Epoch: 835 [20100/50000 (40%)]  \tLoss:   89.699356\trec:   61.277626\tkl:   28.421722\n",
            "Epoch: 835 [30100/50000 (60%)]  \tLoss:   86.974937\trec:   59.916737\tkl:   27.058201\n",
            "Epoch: 835 [40100/50000 (80%)]  \tLoss:   92.451889\trec:   62.656746\tkl:   29.795145\n",
            "====> Epoch: 835 Average train loss: 89.0259\n",
            "====> Validation set loss: 92.4540\n",
            "====> Validation set kl: 27.7470\n",
            "Epoch: 836 [  100/50000 ( 0%)]  \tLoss:   90.523697\trec:   61.843925\tkl:   28.679771\n",
            "Epoch: 836 [10100/50000 (20%)]  \tLoss:   88.628532\trec:   61.365234\tkl:   27.263306\n",
            "Epoch: 836 [20100/50000 (40%)]  \tLoss:   89.695084\trec:   60.818611\tkl:   28.876476\n",
            "Epoch: 836 [30100/50000 (60%)]  \tLoss:   87.014519\trec:   59.732021\tkl:   27.282499\n",
            "Epoch: 836 [40100/50000 (80%)]  \tLoss:   92.329453\trec:   64.512657\tkl:   27.816790\n",
            "====> Epoch: 836 Average train loss: 89.0283\n",
            "====> Validation set loss: 92.3763\n",
            "====> Validation set kl: 27.8878\n",
            "Epoch: 837 [  100/50000 ( 0%)]  \tLoss:   86.816833\trec:   60.050591\tkl:   26.766239\n",
            "Epoch: 837 [10100/50000 (20%)]  \tLoss:   88.335594\trec:   60.648983\tkl:   27.686607\n",
            "Epoch: 837 [20100/50000 (40%)]  \tLoss:   88.032471\trec:   61.019001\tkl:   27.013468\n",
            "Epoch: 837 [30100/50000 (60%)]  \tLoss:   87.736252\trec:   61.499191\tkl:   26.237061\n",
            "Epoch: 837 [40100/50000 (80%)]  \tLoss:   89.871315\trec:   61.817951\tkl:   28.053366\n",
            "====> Epoch: 837 Average train loss: 89.0194\n",
            "====> Validation set loss: 92.2447\n",
            "====> Validation set kl: 27.9310\n",
            "Epoch: 838 [  100/50000 ( 0%)]  \tLoss:   87.860321\trec:   59.818420\tkl:   28.041899\n",
            "Epoch: 838 [10100/50000 (20%)]  \tLoss:   88.718468\trec:   60.700741\tkl:   28.017727\n",
            "Epoch: 838 [20100/50000 (40%)]  \tLoss:   91.608116\trec:   62.306824\tkl:   29.301289\n",
            "Epoch: 838 [30100/50000 (60%)]  \tLoss:   92.698517\trec:   64.441833\tkl:   28.256680\n",
            "Epoch: 838 [40100/50000 (80%)]  \tLoss:   89.081108\trec:   61.440849\tkl:   27.640266\n",
            "====> Epoch: 838 Average train loss: 89.0361\n",
            "====> Validation set loss: 92.3253\n",
            "====> Validation set kl: 27.7443\n",
            "Epoch: 839 [  100/50000 ( 0%)]  \tLoss:   89.693611\trec:   61.541286\tkl:   28.152323\n",
            "Epoch: 839 [10100/50000 (20%)]  \tLoss:   89.644333\trec:   62.443241\tkl:   27.201088\n",
            "Epoch: 839 [20100/50000 (40%)]  \tLoss:   92.238358\trec:   64.441299\tkl:   27.797066\n",
            "Epoch: 839 [30100/50000 (60%)]  \tLoss:   90.045624\trec:   61.628006\tkl:   28.417622\n",
            "Epoch: 839 [40100/50000 (80%)]  \tLoss:   89.626640\trec:   61.900692\tkl:   27.725945\n",
            "====> Epoch: 839 Average train loss: 89.0104\n",
            "====> Validation set loss: 92.2281\n",
            "====> Validation set kl: 27.8307\n",
            "Epoch: 840 [  100/50000 ( 0%)]  \tLoss:   95.386017\trec:   66.038734\tkl:   29.347277\n",
            "Epoch: 840 [10100/50000 (20%)]  \tLoss:   90.536911\trec:   61.522900\tkl:   29.014015\n",
            "Epoch: 840 [20100/50000 (40%)]  \tLoss:   86.966652\trec:   59.753777\tkl:   27.212868\n",
            "Epoch: 840 [30100/50000 (60%)]  \tLoss:   88.591805\trec:   60.502460\tkl:   28.089346\n",
            "Epoch: 840 [40100/50000 (80%)]  \tLoss:   87.420074\trec:   59.866318\tkl:   27.553757\n",
            "====> Epoch: 840 Average train loss: 89.0188\n",
            "====> Validation set loss: 92.2660\n",
            "====> Validation set kl: 27.6465\n",
            "Epoch: 841 [  100/50000 ( 0%)]  \tLoss:   87.664352\trec:   60.863846\tkl:   26.800512\n",
            "Epoch: 841 [10100/50000 (20%)]  \tLoss:   85.418945\trec:   57.891865\tkl:   27.527082\n",
            "Epoch: 841 [20100/50000 (40%)]  \tLoss:   84.098175\trec:   57.214947\tkl:   26.883224\n",
            "Epoch: 841 [30100/50000 (60%)]  \tLoss:   90.917267\trec:   62.590954\tkl:   28.326313\n",
            "Epoch: 841 [40100/50000 (80%)]  \tLoss:   86.342331\trec:   59.263466\tkl:   27.078869\n",
            "====> Epoch: 841 Average train loss: 89.0141\n",
            "====> Validation set loss: 92.3787\n",
            "====> Validation set kl: 27.8626\n",
            "Epoch: 842 [  100/50000 ( 0%)]  \tLoss:   86.167870\trec:   58.435799\tkl:   27.732073\n",
            "Epoch: 842 [10100/50000 (20%)]  \tLoss:   87.917313\trec:   59.840855\tkl:   28.076462\n",
            "Epoch: 842 [20100/50000 (40%)]  \tLoss:   89.428253\trec:   62.098946\tkl:   27.329306\n",
            "Epoch: 842 [30100/50000 (60%)]  \tLoss:   88.992836\trec:   62.139530\tkl:   26.853312\n",
            "Epoch: 842 [40100/50000 (80%)]  \tLoss:   91.567398\trec:   63.928261\tkl:   27.639139\n",
            "====> Epoch: 842 Average train loss: 89.0113\n",
            "====> Validation set loss: 92.3373\n",
            "====> Validation set kl: 27.7158\n",
            "Epoch: 843 [  100/50000 ( 0%)]  \tLoss:   85.561935\trec:   58.737431\tkl:   26.824499\n",
            "Epoch: 843 [10100/50000 (20%)]  \tLoss:   84.145645\trec:   57.369427\tkl:   26.776211\n",
            "Epoch: 843 [20100/50000 (40%)]  \tLoss:   89.971817\trec:   62.569317\tkl:   27.402502\n",
            "Epoch: 843 [30100/50000 (60%)]  \tLoss:   90.246132\trec:   61.854374\tkl:   28.391758\n",
            "Epoch: 843 [40100/50000 (80%)]  \tLoss:   90.095116\trec:   62.256233\tkl:   27.838879\n",
            "====> Epoch: 843 Average train loss: 88.9922\n",
            "====> Validation set loss: 92.3616\n",
            "====> Validation set kl: 27.7828\n",
            "Epoch: 844 [  100/50000 ( 0%)]  \tLoss:   86.776924\trec:   59.331215\tkl:   27.445709\n",
            "Epoch: 844 [10100/50000 (20%)]  \tLoss:   89.307228\trec:   61.129559\tkl:   28.177664\n",
            "Epoch: 844 [20100/50000 (40%)]  \tLoss:   89.146523\trec:   61.424267\tkl:   27.722250\n",
            "Epoch: 844 [30100/50000 (60%)]  \tLoss:   89.294830\trec:   61.103718\tkl:   28.191114\n",
            "Epoch: 844 [40100/50000 (80%)]  \tLoss:   88.633583\trec:   61.441238\tkl:   27.192345\n",
            "====> Epoch: 844 Average train loss: 89.0058\n",
            "====> Validation set loss: 92.4241\n",
            "====> Validation set kl: 27.8663\n",
            "Epoch: 845 [  100/50000 ( 0%)]  \tLoss:   90.723503\trec:   62.105145\tkl:   28.618359\n",
            "Epoch: 845 [10100/50000 (20%)]  \tLoss:   91.730904\trec:   64.006943\tkl:   27.723961\n",
            "Epoch: 845 [20100/50000 (40%)]  \tLoss:   90.498047\trec:   62.928894\tkl:   27.569147\n",
            "Epoch: 845 [30100/50000 (60%)]  \tLoss:   87.969673\trec:   60.221054\tkl:   27.748619\n",
            "Epoch: 845 [40100/50000 (80%)]  \tLoss:   90.053848\trec:   62.383495\tkl:   27.670349\n",
            "====> Epoch: 845 Average train loss: 88.9895\n",
            "====> Validation set loss: 92.4176\n",
            "====> Validation set kl: 27.7542\n",
            "Epoch: 846 [  100/50000 ( 0%)]  \tLoss:   89.995995\trec:   62.125477\tkl:   27.870514\n",
            "Epoch: 846 [10100/50000 (20%)]  \tLoss:   91.109764\trec:   63.188251\tkl:   27.921509\n",
            "Epoch: 846 [20100/50000 (40%)]  \tLoss:   87.274689\trec:   59.723007\tkl:   27.551680\n",
            "Epoch: 846 [30100/50000 (60%)]  \tLoss:   87.889969\trec:   60.000652\tkl:   27.889317\n",
            "Epoch: 846 [40100/50000 (80%)]  \tLoss:   93.456573\trec:   64.373955\tkl:   29.082619\n",
            "====> Epoch: 846 Average train loss: 88.9832\n",
            "====> Validation set loss: 92.2402\n",
            "====> Validation set kl: 27.7370\n",
            "Epoch: 847 [  100/50000 ( 0%)]  \tLoss:   90.755898\trec:   63.459454\tkl:   27.296444\n",
            "Epoch: 847 [10100/50000 (20%)]  \tLoss:   92.163193\trec:   62.676357\tkl:   29.486835\n",
            "Epoch: 847 [20100/50000 (40%)]  \tLoss:   91.892982\trec:   63.606941\tkl:   28.286047\n",
            "Epoch: 847 [30100/50000 (60%)]  \tLoss:   86.863571\trec:   59.167419\tkl:   27.696150\n",
            "Epoch: 847 [40100/50000 (80%)]  \tLoss:   91.121300\trec:   62.568748\tkl:   28.552551\n",
            "====> Epoch: 847 Average train loss: 88.9752\n",
            "====> Validation set loss: 92.3189\n",
            "====> Validation set kl: 27.7148\n",
            "Epoch: 848 [  100/50000 ( 0%)]  \tLoss:   87.244308\trec:   60.115185\tkl:   27.129120\n",
            "Epoch: 848 [10100/50000 (20%)]  \tLoss:   90.490593\trec:   61.706184\tkl:   28.784410\n",
            "Epoch: 848 [20100/50000 (40%)]  \tLoss:   90.216843\trec:   61.919079\tkl:   28.297760\n",
            "Epoch: 848 [30100/50000 (60%)]  \tLoss:   88.084023\trec:   60.032810\tkl:   28.051212\n",
            "Epoch: 848 [40100/50000 (80%)]  \tLoss:   88.210526\trec:   59.993122\tkl:   28.217403\n",
            "====> Epoch: 848 Average train loss: 88.9931\n",
            "====> Validation set loss: 92.2593\n",
            "====> Validation set kl: 27.5723\n",
            "Epoch: 849 [  100/50000 ( 0%)]  \tLoss:   86.922028\trec:   59.819317\tkl:   27.102709\n",
            "Epoch: 849 [10100/50000 (20%)]  \tLoss:   90.575912\trec:   62.652569\tkl:   27.923353\n",
            "Epoch: 849 [20100/50000 (40%)]  \tLoss:   93.037750\trec:   65.068779\tkl:   27.968971\n",
            "Epoch: 849 [30100/50000 (60%)]  \tLoss:   88.873390\trec:   60.504570\tkl:   28.368820\n",
            "Epoch: 849 [40100/50000 (80%)]  \tLoss:   85.024902\trec:   58.691753\tkl:   26.333143\n",
            "====> Epoch: 849 Average train loss: 88.9939\n",
            "====> Validation set loss: 92.3871\n",
            "====> Validation set kl: 27.7665\n",
            "Epoch: 850 [  100/50000 ( 0%)]  \tLoss:   89.420509\trec:   61.554401\tkl:   27.866100\n",
            "Epoch: 850 [10100/50000 (20%)]  \tLoss:   86.774467\trec:   59.493401\tkl:   27.281071\n",
            "Epoch: 850 [20100/50000 (40%)]  \tLoss:   89.847946\trec:   61.990166\tkl:   27.857780\n",
            "Epoch: 850 [30100/50000 (60%)]  \tLoss:   88.013229\trec:   59.776497\tkl:   28.236731\n",
            "Epoch: 850 [40100/50000 (80%)]  \tLoss:   89.260239\trec:   61.932030\tkl:   27.328215\n",
            "====> Epoch: 850 Average train loss: 88.9907\n",
            "====> Validation set loss: 92.4607\n",
            "====> Validation set kl: 27.8800\n",
            "Epoch: 851 [  100/50000 ( 0%)]  \tLoss:   91.796486\trec:   63.162605\tkl:   28.633877\n",
            "Epoch: 851 [10100/50000 (20%)]  \tLoss:   89.672203\trec:   59.917225\tkl:   29.754984\n",
            "Epoch: 851 [20100/50000 (40%)]  \tLoss:   89.965073\trec:   61.612274\tkl:   28.352806\n",
            "Epoch: 851 [30100/50000 (60%)]  \tLoss:   86.834435\trec:   59.816399\tkl:   27.018034\n",
            "Epoch: 851 [40100/50000 (80%)]  \tLoss:   90.980087\trec:   62.192715\tkl:   28.787373\n",
            "====> Epoch: 851 Average train loss: 88.9877\n",
            "====> Validation set loss: 92.2243\n",
            "====> Validation set kl: 27.8287\n",
            "Epoch: 852 [  100/50000 ( 0%)]  \tLoss:   91.715172\trec:   63.243816\tkl:   28.471354\n",
            "Epoch: 852 [10100/50000 (20%)]  \tLoss:   83.972519\trec:   56.889793\tkl:   27.082722\n",
            "Epoch: 852 [20100/50000 (40%)]  \tLoss:   85.459961\trec:   58.367241\tkl:   27.092720\n",
            "Epoch: 852 [30100/50000 (60%)]  \tLoss:   86.778595\trec:   59.412460\tkl:   27.366129\n",
            "Epoch: 852 [40100/50000 (80%)]  \tLoss:   87.109070\trec:   59.895966\tkl:   27.213104\n",
            "====> Epoch: 852 Average train loss: 88.9937\n",
            "====> Validation set loss: 92.3039\n",
            "====> Validation set kl: 27.7029\n",
            "Epoch: 853 [  100/50000 ( 0%)]  \tLoss:   88.060349\trec:   60.838604\tkl:   27.221750\n",
            "Epoch: 853 [10100/50000 (20%)]  \tLoss:   87.652687\trec:   60.133137\tkl:   27.519548\n",
            "Epoch: 853 [20100/50000 (40%)]  \tLoss:   89.061668\trec:   60.954159\tkl:   28.107506\n",
            "Epoch: 853 [30100/50000 (60%)]  \tLoss:   88.766991\trec:   60.437527\tkl:   28.329464\n",
            "Epoch: 853 [40100/50000 (80%)]  \tLoss:   92.351662\trec:   63.777191\tkl:   28.574467\n",
            "====> Epoch: 853 Average train loss: 88.9849\n",
            "====> Validation set loss: 92.3177\n",
            "====> Validation set kl: 27.7854\n",
            "Epoch: 854 [  100/50000 ( 0%)]  \tLoss:   88.904762\trec:   61.604851\tkl:   27.299911\n",
            "Epoch: 854 [10100/50000 (20%)]  \tLoss:   86.308769\trec:   58.632404\tkl:   27.676367\n",
            "Epoch: 854 [20100/50000 (40%)]  \tLoss:   89.117325\trec:   61.370193\tkl:   27.747133\n",
            "Epoch: 854 [30100/50000 (60%)]  \tLoss:   90.462799\trec:   62.402031\tkl:   28.060768\n",
            "Epoch: 854 [40100/50000 (80%)]  \tLoss:   92.245033\trec:   63.937347\tkl:   28.307686\n",
            "====> Epoch: 854 Average train loss: 88.9892\n",
            "====> Validation set loss: 92.2681\n",
            "====> Validation set kl: 27.7644\n",
            "Epoch: 855 [  100/50000 ( 0%)]  \tLoss:   88.373726\trec:   60.916351\tkl:   27.457373\n",
            "Epoch: 855 [10100/50000 (20%)]  \tLoss:   87.686691\trec:   60.391350\tkl:   27.295334\n",
            "Epoch: 855 [20100/50000 (40%)]  \tLoss:   88.270798\trec:   60.795486\tkl:   27.475317\n",
            "Epoch: 855 [30100/50000 (60%)]  \tLoss:   86.762047\trec:   59.728672\tkl:   27.033382\n",
            "Epoch: 855 [40100/50000 (80%)]  \tLoss:   89.286911\trec:   61.890293\tkl:   27.396616\n",
            "====> Epoch: 855 Average train loss: 88.9723\n",
            "====> Validation set loss: 92.3287\n",
            "====> Validation set kl: 27.9272\n",
            "Epoch: 856 [  100/50000 ( 0%)]  \tLoss:   92.052193\trec:   63.524658\tkl:   28.527536\n",
            "Epoch: 856 [10100/50000 (20%)]  \tLoss:   83.157928\trec:   56.818958\tkl:   26.338966\n",
            "Epoch: 856 [20100/50000 (40%)]  \tLoss:   87.739182\trec:   60.461716\tkl:   27.277460\n",
            "Epoch: 856 [30100/50000 (60%)]  \tLoss:   87.333389\trec:   59.602333\tkl:   27.731054\n",
            "Epoch: 856 [40100/50000 (80%)]  \tLoss:   92.059677\trec:   62.920666\tkl:   29.139008\n",
            "====> Epoch: 856 Average train loss: 88.9882\n",
            "====> Validation set loss: 92.3796\n",
            "====> Validation set kl: 27.8821\n",
            "Epoch: 857 [  100/50000 ( 0%)]  \tLoss:   88.646164\trec:   61.566143\tkl:   27.080021\n",
            "Epoch: 857 [10100/50000 (20%)]  \tLoss:   89.076149\trec:   61.446499\tkl:   27.629652\n",
            "Epoch: 857 [20100/50000 (40%)]  \tLoss:   88.588425\trec:   60.614841\tkl:   27.973585\n",
            "Epoch: 857 [30100/50000 (60%)]  \tLoss:   85.972534\trec:   58.570538\tkl:   27.401997\n",
            "Epoch: 857 [40100/50000 (80%)]  \tLoss:   85.720314\trec:   59.171516\tkl:   26.548788\n",
            "====> Epoch: 857 Average train loss: 88.9672\n",
            "====> Validation set loss: 92.3733\n",
            "====> Validation set kl: 27.8742\n",
            "Epoch: 858 [  100/50000 ( 0%)]  \tLoss:   86.234795\trec:   58.553356\tkl:   27.681437\n",
            "Epoch: 858 [10100/50000 (20%)]  \tLoss:   85.287781\trec:   58.340370\tkl:   26.947414\n",
            "Epoch: 858 [20100/50000 (40%)]  \tLoss:   90.431328\trec:   61.557610\tkl:   28.873720\n",
            "Epoch: 858 [30100/50000 (60%)]  \tLoss:   89.639305\trec:   61.504456\tkl:   28.134846\n",
            "Epoch: 858 [40100/50000 (80%)]  \tLoss:   90.923691\trec:   62.534042\tkl:   28.389643\n",
            "====> Epoch: 858 Average train loss: 88.9808\n",
            "====> Validation set loss: 92.3568\n",
            "====> Validation set kl: 27.5713\n",
            "Epoch: 859 [  100/50000 ( 0%)]  \tLoss:   89.351425\trec:   61.647881\tkl:   27.703548\n",
            "Epoch: 859 [10100/50000 (20%)]  \tLoss:   90.771065\trec:   62.314621\tkl:   28.456438\n",
            "Epoch: 859 [20100/50000 (40%)]  \tLoss:   85.919357\trec:   59.097046\tkl:   26.822306\n",
            "Epoch: 859 [30100/50000 (60%)]  \tLoss:   92.928093\trec:   63.854374\tkl:   29.073721\n",
            "Epoch: 859 [40100/50000 (80%)]  \tLoss:   89.592636\trec:   61.959629\tkl:   27.633013\n",
            "====> Epoch: 859 Average train loss: 88.9581\n",
            "====> Validation set loss: 92.2604\n",
            "====> Validation set kl: 27.8996\n",
            "Epoch: 860 [  100/50000 ( 0%)]  \tLoss:   86.283745\trec:   59.345356\tkl:   26.938391\n",
            "Epoch: 860 [10100/50000 (20%)]  \tLoss:   88.246193\trec:   60.327190\tkl:   27.919003\n",
            "Epoch: 860 [20100/50000 (40%)]  \tLoss:   84.752716\trec:   57.651062\tkl:   27.101654\n",
            "Epoch: 860 [30100/50000 (60%)]  \tLoss:   87.264839\trec:   59.559353\tkl:   27.705484\n",
            "Epoch: 860 [40100/50000 (80%)]  \tLoss:   88.614487\trec:   61.078926\tkl:   27.535570\n",
            "====> Epoch: 860 Average train loss: 88.9813\n",
            "====> Validation set loss: 92.2885\n",
            "====> Validation set kl: 27.8526\n",
            "Epoch: 861 [  100/50000 ( 0%)]  \tLoss:   85.578316\trec:   57.547146\tkl:   28.031168\n",
            "Epoch: 861 [10100/50000 (20%)]  \tLoss:   86.964088\trec:   59.274208\tkl:   27.689880\n",
            "Epoch: 861 [20100/50000 (40%)]  \tLoss:   92.343277\trec:   63.619808\tkl:   28.723471\n",
            "Epoch: 861 [30100/50000 (60%)]  \tLoss:   89.449425\trec:   62.105164\tkl:   27.344255\n",
            "Epoch: 861 [40100/50000 (80%)]  \tLoss:   91.798523\trec:   63.985691\tkl:   27.812828\n",
            "====> Epoch: 861 Average train loss: 88.9437\n",
            "====> Validation set loss: 92.2722\n",
            "====> Validation set kl: 27.5442\n",
            "Epoch: 862 [  100/50000 ( 0%)]  \tLoss:   86.704590\trec:   59.913105\tkl:   26.791481\n",
            "Epoch: 862 [10100/50000 (20%)]  \tLoss:   83.349289\trec:   55.947605\tkl:   27.401680\n",
            "Epoch: 862 [20100/50000 (40%)]  \tLoss:   87.561218\trec:   59.214294\tkl:   28.346924\n",
            "Epoch: 862 [30100/50000 (60%)]  \tLoss:   86.692947\trec:   59.264668\tkl:   27.428278\n",
            "Epoch: 862 [40100/50000 (80%)]  \tLoss:   88.844215\trec:   61.248981\tkl:   27.595234\n",
            "====> Epoch: 862 Average train loss: 88.9441\n",
            "====> Validation set loss: 92.3026\n",
            "====> Validation set kl: 27.7765\n",
            "Epoch: 863 [  100/50000 ( 0%)]  \tLoss:   85.348999\trec:   58.049442\tkl:   27.299555\n",
            "Epoch: 863 [10100/50000 (20%)]  \tLoss:   89.280479\trec:   61.575466\tkl:   27.705008\n",
            "Epoch: 863 [20100/50000 (40%)]  \tLoss:   87.135712\trec:   59.387871\tkl:   27.747843\n",
            "Epoch: 863 [30100/50000 (60%)]  \tLoss:   88.795006\trec:   60.558857\tkl:   28.236149\n",
            "Epoch: 863 [40100/50000 (80%)]  \tLoss:   89.831192\trec:   61.685223\tkl:   28.145969\n",
            "====> Epoch: 863 Average train loss: 88.9651\n",
            "====> Validation set loss: 92.3376\n",
            "====> Validation set kl: 27.6344\n",
            "Epoch: 864 [  100/50000 ( 0%)]  \tLoss:   91.635216\trec:   62.507866\tkl:   29.127350\n",
            "Epoch: 864 [10100/50000 (20%)]  \tLoss:   92.061493\trec:   63.242310\tkl:   28.819183\n",
            "Epoch: 864 [20100/50000 (40%)]  \tLoss:   90.728149\trec:   61.797523\tkl:   28.930630\n",
            "Epoch: 864 [30100/50000 (60%)]  \tLoss:   88.124565\trec:   60.454815\tkl:   27.669760\n",
            "Epoch: 864 [40100/50000 (80%)]  \tLoss:   86.076500\trec:   59.247459\tkl:   26.829042\n",
            "====> Epoch: 864 Average train loss: 88.9712\n",
            "====> Validation set loss: 92.3161\n",
            "====> Validation set kl: 27.7376\n",
            "Epoch: 865 [  100/50000 ( 0%)]  \tLoss:   90.219635\trec:   62.166328\tkl:   28.053310\n",
            "Epoch: 865 [10100/50000 (20%)]  \tLoss:   90.887154\trec:   62.742908\tkl:   28.144249\n",
            "Epoch: 865 [20100/50000 (40%)]  \tLoss:   87.732742\trec:   60.072937\tkl:   27.659803\n",
            "Epoch: 865 [30100/50000 (60%)]  \tLoss:   83.805428\trec:   56.982910\tkl:   26.822517\n",
            "Epoch: 865 [40100/50000 (80%)]  \tLoss:   90.003822\trec:   61.427738\tkl:   28.576084\n",
            "====> Epoch: 865 Average train loss: 88.9569\n",
            "====> Validation set loss: 92.2749\n",
            "====> Validation set kl: 27.6661\n",
            "Epoch: 866 [  100/50000 ( 0%)]  \tLoss:   88.280586\trec:   61.234921\tkl:   27.045668\n",
            "Epoch: 866 [10100/50000 (20%)]  \tLoss:   89.491043\trec:   61.244331\tkl:   28.246714\n",
            "Epoch: 866 [20100/50000 (40%)]  \tLoss:   86.580757\trec:   59.334011\tkl:   27.246742\n",
            "Epoch: 866 [30100/50000 (60%)]  \tLoss:   90.569786\trec:   62.213123\tkl:   28.356657\n",
            "Epoch: 866 [40100/50000 (80%)]  \tLoss:   85.698555\trec:   59.132645\tkl:   26.565903\n",
            "====> Epoch: 866 Average train loss: 88.9497\n",
            "====> Validation set loss: 92.3475\n",
            "====> Validation set kl: 27.8655\n",
            "Epoch: 867 [  100/50000 ( 0%)]  \tLoss:   86.513374\trec:   58.623623\tkl:   27.889755\n",
            "Epoch: 867 [10100/50000 (20%)]  \tLoss:   85.452690\trec:   57.203545\tkl:   28.249149\n",
            "Epoch: 867 [20100/50000 (40%)]  \tLoss:   91.659409\trec:   64.477097\tkl:   27.182320\n",
            "Epoch: 867 [30100/50000 (60%)]  \tLoss:   90.790474\trec:   62.670567\tkl:   28.119909\n",
            "Epoch: 867 [40100/50000 (80%)]  \tLoss:   88.985703\trec:   61.500313\tkl:   27.485390\n",
            "====> Epoch: 867 Average train loss: 88.9416\n",
            "====> Validation set loss: 92.2826\n",
            "====> Validation set kl: 27.7893\n",
            "Epoch: 868 [  100/50000 ( 0%)]  \tLoss:   88.863930\trec:   60.726269\tkl:   28.137669\n",
            "Epoch: 868 [10100/50000 (20%)]  \tLoss:   91.887184\trec:   63.529560\tkl:   28.357628\n",
            "Epoch: 868 [20100/50000 (40%)]  \tLoss:   90.621056\trec:   62.033901\tkl:   28.587149\n",
            "Epoch: 868 [30100/50000 (60%)]  \tLoss:   87.218430\trec:   60.328327\tkl:   26.890095\n",
            "Epoch: 868 [40100/50000 (80%)]  \tLoss:   89.531715\trec:   61.656025\tkl:   27.875692\n",
            "====> Epoch: 868 Average train loss: 88.9361\n",
            "====> Validation set loss: 92.2952\n",
            "====> Validation set kl: 27.6731\n",
            "Epoch: 869 [  100/50000 ( 0%)]  \tLoss:   87.039536\trec:   59.426617\tkl:   27.612926\n",
            "Epoch: 869 [10100/50000 (20%)]  \tLoss:   86.276718\trec:   58.596367\tkl:   27.680351\n",
            "Epoch: 869 [20100/50000 (40%)]  \tLoss:   90.831886\trec:   62.137070\tkl:   28.694817\n",
            "Epoch: 869 [30100/50000 (60%)]  \tLoss:   85.739380\trec:   58.282360\tkl:   27.457022\n",
            "Epoch: 869 [40100/50000 (80%)]  \tLoss:   91.293121\trec:   63.267254\tkl:   28.025871\n",
            "====> Epoch: 869 Average train loss: 88.9210\n",
            "====> Validation set loss: 92.3987\n",
            "====> Validation set kl: 27.7529\n",
            "Epoch: 870 [  100/50000 ( 0%)]  \tLoss:   88.649734\trec:   60.397148\tkl:   28.252586\n",
            "Epoch: 870 [10100/50000 (20%)]  \tLoss:   88.822784\trec:   60.745117\tkl:   28.077667\n",
            "Epoch: 870 [20100/50000 (40%)]  \tLoss:   88.148666\trec:   61.373425\tkl:   26.775238\n",
            "Epoch: 870 [30100/50000 (60%)]  \tLoss:   91.391541\trec:   62.661961\tkl:   28.729574\n",
            "Epoch: 870 [40100/50000 (80%)]  \tLoss:   90.450035\trec:   62.531853\tkl:   27.918186\n",
            "====> Epoch: 870 Average train loss: 88.9600\n",
            "====> Validation set loss: 92.3101\n",
            "====> Validation set kl: 27.7952\n",
            "Epoch: 871 [  100/50000 ( 0%)]  \tLoss:   90.875000\trec:   62.206474\tkl:   28.668530\n",
            "Epoch: 871 [10100/50000 (20%)]  \tLoss:   84.616676\trec:   57.943462\tkl:   26.673212\n",
            "Epoch: 871 [20100/50000 (40%)]  \tLoss:   89.046021\trec:   61.284184\tkl:   27.761837\n",
            "Epoch: 871 [30100/50000 (60%)]  \tLoss:   92.109634\trec:   63.158764\tkl:   28.950874\n",
            "Epoch: 871 [40100/50000 (80%)]  \tLoss:   89.549248\trec:   62.060593\tkl:   27.488649\n",
            "====> Epoch: 871 Average train loss: 88.9539\n",
            "====> Validation set loss: 92.3637\n",
            "====> Validation set kl: 27.8431\n",
            "Epoch: 872 [  100/50000 ( 0%)]  \tLoss:   89.346222\trec:   60.098953\tkl:   29.247263\n",
            "Epoch: 872 [10100/50000 (20%)]  \tLoss:   88.549034\trec:   60.160271\tkl:   28.388762\n",
            "Epoch: 872 [20100/50000 (40%)]  \tLoss:   87.643745\trec:   60.683300\tkl:   26.960449\n",
            "Epoch: 872 [30100/50000 (60%)]  \tLoss:   89.273796\trec:   61.389286\tkl:   27.884512\n",
            "Epoch: 872 [40100/50000 (80%)]  \tLoss:   88.789688\trec:   60.802315\tkl:   27.987370\n",
            "====> Epoch: 872 Average train loss: 88.9270\n",
            "====> Validation set loss: 92.3182\n",
            "====> Validation set kl: 27.8256\n",
            "Epoch: 873 [  100/50000 ( 0%)]  \tLoss:   87.466072\trec:   60.860909\tkl:   26.605171\n",
            "Epoch: 873 [10100/50000 (20%)]  \tLoss:   88.804977\trec:   60.210686\tkl:   28.594296\n",
            "Epoch: 873 [20100/50000 (40%)]  \tLoss:   88.426346\trec:   61.228378\tkl:   27.197964\n",
            "Epoch: 873 [30100/50000 (60%)]  \tLoss:   90.100937\trec:   62.261272\tkl:   27.839661\n",
            "Epoch: 873 [40100/50000 (80%)]  \tLoss:   90.283936\trec:   61.309940\tkl:   28.973993\n",
            "====> Epoch: 873 Average train loss: 88.9135\n",
            "====> Validation set loss: 92.2842\n",
            "====> Validation set kl: 27.8095\n",
            "Epoch: 874 [  100/50000 ( 0%)]  \tLoss:   89.549812\trec:   61.790459\tkl:   27.759357\n",
            "Epoch: 874 [10100/50000 (20%)]  \tLoss:   89.752029\trec:   61.992329\tkl:   27.759697\n",
            "Epoch: 874 [20100/50000 (40%)]  \tLoss:   87.704674\trec:   59.971527\tkl:   27.733147\n",
            "Epoch: 874 [30100/50000 (60%)]  \tLoss:   88.117867\trec:   60.488216\tkl:   27.629652\n",
            "Epoch: 874 [40100/50000 (80%)]  \tLoss:   87.324326\trec:   59.608562\tkl:   27.715759\n",
            "====> Epoch: 874 Average train loss: 88.9235\n",
            "====> Validation set loss: 92.2574\n",
            "====> Validation set kl: 27.6315\n",
            "Epoch: 875 [  100/50000 ( 0%)]  \tLoss:   90.002411\trec:   62.406384\tkl:   27.596022\n",
            "Epoch: 875 [10100/50000 (20%)]  \tLoss:   92.334091\trec:   63.872253\tkl:   28.461832\n",
            "Epoch: 875 [20100/50000 (40%)]  \tLoss:   85.446030\trec:   57.696171\tkl:   27.749868\n",
            "Epoch: 875 [30100/50000 (60%)]  \tLoss:   90.257721\trec:   61.993610\tkl:   28.264111\n",
            "Epoch: 875 [40100/50000 (80%)]  \tLoss:   87.647476\trec:   59.925762\tkl:   27.721720\n",
            "====> Epoch: 875 Average train loss: 88.9335\n",
            "====> Validation set loss: 92.4144\n",
            "====> Validation set kl: 27.8475\n",
            "Epoch: 876 [  100/50000 ( 0%)]  \tLoss:   90.132469\trec:   62.228729\tkl:   27.903740\n",
            "Epoch: 876 [10100/50000 (20%)]  \tLoss:   90.391853\trec:   62.128487\tkl:   28.263367\n",
            "Epoch: 876 [20100/50000 (40%)]  \tLoss:   88.001511\trec:   59.792778\tkl:   28.208735\n",
            "Epoch: 876 [30100/50000 (60%)]  \tLoss:   91.931763\trec:   63.853905\tkl:   28.077860\n",
            "Epoch: 876 [40100/50000 (80%)]  \tLoss:   91.685661\trec:   63.586082\tkl:   28.099585\n",
            "====> Epoch: 876 Average train loss: 88.9274\n",
            "====> Validation set loss: 92.4420\n",
            "====> Validation set kl: 27.9996\n",
            "Epoch: 877 [  100/50000 ( 0%)]  \tLoss:   89.165443\trec:   62.049892\tkl:   27.115561\n",
            "Epoch: 877 [10100/50000 (20%)]  \tLoss:   88.947350\trec:   62.039928\tkl:   26.907421\n",
            "Epoch: 877 [20100/50000 (40%)]  \tLoss:   91.527504\trec:   63.817966\tkl:   27.709541\n",
            "Epoch: 877 [30100/50000 (60%)]  \tLoss:   85.924156\trec:   58.848881\tkl:   27.075283\n",
            "Epoch: 877 [40100/50000 (80%)]  \tLoss:   89.081718\trec:   61.388165\tkl:   27.693560\n",
            "====> Epoch: 877 Average train loss: 88.9390\n",
            "====> Validation set loss: 92.3615\n",
            "====> Validation set kl: 27.9202\n",
            "Epoch: 878 [  100/50000 ( 0%)]  \tLoss:   90.199257\trec:   61.838650\tkl:   28.360605\n",
            "Epoch: 878 [10100/50000 (20%)]  \tLoss:   86.550308\trec:   59.237225\tkl:   27.313089\n",
            "Epoch: 878 [20100/50000 (40%)]  \tLoss:   88.493881\trec:   60.411579\tkl:   28.082298\n",
            "Epoch: 878 [30100/50000 (60%)]  \tLoss:   86.513161\trec:   59.178692\tkl:   27.334473\n",
            "Epoch: 878 [40100/50000 (80%)]  \tLoss:   87.806015\trec:   60.346699\tkl:   27.459312\n",
            "====> Epoch: 878 Average train loss: 88.9238\n",
            "====> Validation set loss: 92.3974\n",
            "====> Validation set kl: 27.9412\n",
            "Epoch: 879 [  100/50000 ( 0%)]  \tLoss:   88.365822\trec:   60.599545\tkl:   27.766273\n",
            "Epoch: 879 [10100/50000 (20%)]  \tLoss:   89.817871\trec:   61.773376\tkl:   28.044489\n",
            "Epoch: 879 [20100/50000 (40%)]  \tLoss:   91.244850\trec:   63.851482\tkl:   27.393372\n",
            "Epoch: 879 [30100/50000 (60%)]  \tLoss:   90.029793\trec:   62.433525\tkl:   27.596270\n",
            "Epoch: 879 [40100/50000 (80%)]  \tLoss:   93.733101\trec:   65.219810\tkl:   28.513290\n",
            "====> Epoch: 879 Average train loss: 88.9123\n",
            "====> Validation set loss: 92.3438\n",
            "====> Validation set kl: 27.9149\n",
            "Epoch: 880 [  100/50000 ( 0%)]  \tLoss:   88.412010\trec:   60.281494\tkl:   28.130520\n",
            "Epoch: 880 [10100/50000 (20%)]  \tLoss:   87.800240\trec:   60.288338\tkl:   27.511904\n",
            "Epoch: 880 [20100/50000 (40%)]  \tLoss:   90.615196\trec:   62.226582\tkl:   28.388615\n",
            "Epoch: 880 [30100/50000 (60%)]  \tLoss:   89.859596\trec:   61.806755\tkl:   28.052841\n",
            "Epoch: 880 [40100/50000 (80%)]  \tLoss:   87.274864\trec:   59.013767\tkl:   28.261087\n",
            "====> Epoch: 880 Average train loss: 88.9244\n",
            "====> Validation set loss: 92.2830\n",
            "====> Validation set kl: 27.7645\n",
            "Epoch: 881 [  100/50000 ( 0%)]  \tLoss:   89.348297\trec:   61.687157\tkl:   27.661142\n",
            "Epoch: 881 [10100/50000 (20%)]  \tLoss:   86.372559\trec:   58.520073\tkl:   27.852482\n",
            "Epoch: 881 [20100/50000 (40%)]  \tLoss:   87.431587\trec:   59.103905\tkl:   28.327684\n",
            "Epoch: 881 [30100/50000 (60%)]  \tLoss:   91.329773\trec:   63.556835\tkl:   27.772940\n",
            "Epoch: 881 [40100/50000 (80%)]  \tLoss:   90.467384\trec:   62.739353\tkl:   27.728031\n",
            "====> Epoch: 881 Average train loss: 88.9195\n",
            "====> Validation set loss: 92.2927\n",
            "====> Validation set kl: 27.9287\n",
            "Epoch: 882 [  100/50000 ( 0%)]  \tLoss:   91.217285\trec:   62.668621\tkl:   28.548656\n",
            "Epoch: 882 [10100/50000 (20%)]  \tLoss:   89.665337\trec:   61.601791\tkl:   28.063551\n",
            "Epoch: 882 [20100/50000 (40%)]  \tLoss:   89.881470\trec:   62.217102\tkl:   27.664370\n",
            "Epoch: 882 [30100/50000 (60%)]  \tLoss:   89.584381\trec:   61.165398\tkl:   28.418982\n",
            "Epoch: 882 [40100/50000 (80%)]  \tLoss:   87.999901\trec:   59.401234\tkl:   28.598667\n",
            "====> Epoch: 882 Average train loss: 88.9100\n",
            "====> Validation set loss: 92.3858\n",
            "====> Validation set kl: 27.7585\n",
            "Epoch: 883 [  100/50000 ( 0%)]  \tLoss:   90.448975\trec:   62.154064\tkl:   28.294905\n",
            "Epoch: 883 [10100/50000 (20%)]  \tLoss:   90.297447\trec:   61.667625\tkl:   28.629826\n",
            "Epoch: 883 [20100/50000 (40%)]  \tLoss:   89.498116\trec:   60.912479\tkl:   28.585636\n",
            "Epoch: 883 [30100/50000 (60%)]  \tLoss:   94.619987\trec:   65.874985\tkl:   28.745007\n",
            "Epoch: 883 [40100/50000 (80%)]  \tLoss:   87.899742\trec:   60.812004\tkl:   27.087742\n",
            "====> Epoch: 883 Average train loss: 88.9060\n",
            "====> Validation set loss: 92.2630\n",
            "====> Validation set kl: 27.7410\n",
            "Epoch: 884 [  100/50000 ( 0%)]  \tLoss:   86.376717\trec:   59.327374\tkl:   27.049343\n",
            "Epoch: 884 [10100/50000 (20%)]  \tLoss:   88.522285\trec:   60.002632\tkl:   28.519648\n",
            "Epoch: 884 [20100/50000 (40%)]  \tLoss:   88.747047\trec:   60.867020\tkl:   27.880026\n",
            "Epoch: 884 [30100/50000 (60%)]  \tLoss:   86.953346\trec:   59.337093\tkl:   27.616251\n",
            "Epoch: 884 [40100/50000 (80%)]  \tLoss:   88.970528\trec:   60.746834\tkl:   28.223690\n",
            "====> Epoch: 884 Average train loss: 88.9009\n",
            "====> Validation set loss: 92.2994\n",
            "====> Validation set kl: 27.8516\n",
            "Epoch: 885 [  100/50000 ( 0%)]  \tLoss:   84.532013\trec:   57.028973\tkl:   27.503038\n",
            "Epoch: 885 [10100/50000 (20%)]  \tLoss:   93.473907\trec:   64.720215\tkl:   28.753683\n",
            "Epoch: 885 [20100/50000 (40%)]  \tLoss:   87.519218\trec:   60.285740\tkl:   27.233480\n",
            "Epoch: 885 [30100/50000 (60%)]  \tLoss:   88.041229\trec:   60.555553\tkl:   27.485670\n",
            "Epoch: 885 [40100/50000 (80%)]  \tLoss:   88.942047\trec:   61.145954\tkl:   27.796089\n",
            "====> Epoch: 885 Average train loss: 88.8956\n",
            "====> Validation set loss: 92.3970\n",
            "====> Validation set kl: 27.9716\n",
            "Epoch: 886 [  100/50000 ( 0%)]  \tLoss:   92.324471\trec:   63.175419\tkl:   29.149050\n",
            "Epoch: 886 [10100/50000 (20%)]  \tLoss:   87.214249\trec:   58.831913\tkl:   28.382334\n",
            "Epoch: 886 [20100/50000 (40%)]  \tLoss:   87.052666\trec:   60.896961\tkl:   26.155704\n",
            "Epoch: 886 [30100/50000 (60%)]  \tLoss:   90.697029\trec:   61.731491\tkl:   28.965532\n",
            "Epoch: 886 [40100/50000 (80%)]  \tLoss:   93.220749\trec:   64.325493\tkl:   28.895256\n",
            "====> Epoch: 886 Average train loss: 88.9257\n",
            "====> Validation set loss: 92.2587\n",
            "====> Validation set kl: 27.8112\n",
            "Epoch: 887 [  100/50000 ( 0%)]  \tLoss:   91.928917\trec:   62.801483\tkl:   29.127434\n",
            "Epoch: 887 [10100/50000 (20%)]  \tLoss:   91.000542\trec:   62.306313\tkl:   28.694237\n",
            "Epoch: 887 [20100/50000 (40%)]  \tLoss:   87.921310\trec:   60.478466\tkl:   27.442839\n",
            "Epoch: 887 [30100/50000 (60%)]  \tLoss:   88.706818\trec:   60.046501\tkl:   28.660309\n",
            "Epoch: 887 [40100/50000 (80%)]  \tLoss:   85.420067\trec:   58.265629\tkl:   27.154440\n",
            "====> Epoch: 887 Average train loss: 88.9125\n",
            "====> Validation set loss: 92.2659\n",
            "====> Validation set kl: 27.7370\n",
            "Epoch: 888 [  100/50000 ( 0%)]  \tLoss:   85.188553\trec:   58.367050\tkl:   26.821507\n",
            "Epoch: 888 [10100/50000 (20%)]  \tLoss:   87.954536\trec:   59.639851\tkl:   28.314688\n",
            "Epoch: 888 [20100/50000 (40%)]  \tLoss:   87.153511\trec:   59.972538\tkl:   27.180973\n",
            "Epoch: 888 [30100/50000 (60%)]  \tLoss:   86.954803\trec:   60.282547\tkl:   26.672253\n",
            "Epoch: 888 [40100/50000 (80%)]  \tLoss:   92.333160\trec:   64.247643\tkl:   28.085518\n",
            "====> Epoch: 888 Average train loss: 88.9056\n",
            "====> Validation set loss: 92.3148\n",
            "====> Validation set kl: 27.7155\n",
            "Epoch: 889 [  100/50000 ( 0%)]  \tLoss:   90.377411\trec:   62.299881\tkl:   28.077526\n",
            "Epoch: 889 [10100/50000 (20%)]  \tLoss:   89.829361\trec:   61.813042\tkl:   28.016325\n",
            "Epoch: 889 [20100/50000 (40%)]  \tLoss:   89.457626\trec:   61.603939\tkl:   27.853685\n",
            "Epoch: 889 [30100/50000 (60%)]  \tLoss:   88.079643\trec:   60.619968\tkl:   27.459677\n",
            "Epoch: 889 [40100/50000 (80%)]  \tLoss:   89.218513\trec:   61.485973\tkl:   27.732534\n",
            "====> Epoch: 889 Average train loss: 88.8704\n",
            "====> Validation set loss: 92.2750\n",
            "====> Validation set kl: 27.8889\n",
            "Epoch: 890 [  100/50000 ( 0%)]  \tLoss:   90.243141\trec:   61.902206\tkl:   28.340937\n",
            "Epoch: 890 [10100/50000 (20%)]  \tLoss:   88.816513\trec:   60.774590\tkl:   28.041922\n",
            "Epoch: 890 [20100/50000 (40%)]  \tLoss:   86.108414\trec:   58.622684\tkl:   27.485731\n",
            "Epoch: 890 [30100/50000 (60%)]  \tLoss:   88.612228\trec:   60.946941\tkl:   27.665287\n",
            "Epoch: 890 [40100/50000 (80%)]  \tLoss:   90.590378\trec:   61.810810\tkl:   28.779568\n",
            "====> Epoch: 890 Average train loss: 88.8951\n",
            "====> Validation set loss: 92.3541\n",
            "====> Validation set kl: 27.9355\n",
            "Epoch: 891 [  100/50000 ( 0%)]  \tLoss:   88.475235\trec:   60.805168\tkl:   27.670063\n",
            "Epoch: 891 [10100/50000 (20%)]  \tLoss:   87.745102\trec:   60.094463\tkl:   27.650644\n",
            "Epoch: 891 [20100/50000 (40%)]  \tLoss:   88.064987\trec:   60.545418\tkl:   27.519569\n",
            "Epoch: 891 [30100/50000 (60%)]  \tLoss:   92.159958\trec:   63.140507\tkl:   29.019447\n",
            "Epoch: 891 [40100/50000 (80%)]  \tLoss:   86.078758\trec:   58.670818\tkl:   27.407936\n",
            "====> Epoch: 891 Average train loss: 88.8974\n",
            "====> Validation set loss: 92.3245\n",
            "====> Validation set kl: 27.6805\n",
            "Epoch: 892 [  100/50000 ( 0%)]  \tLoss:   87.770485\trec:   60.483311\tkl:   27.287174\n",
            "Epoch: 892 [10100/50000 (20%)]  \tLoss:   87.315575\trec:   59.904167\tkl:   27.411407\n",
            "Epoch: 892 [20100/50000 (40%)]  \tLoss:   89.022514\trec:   61.113510\tkl:   27.909008\n",
            "Epoch: 892 [30100/50000 (60%)]  \tLoss:   88.943550\trec:   60.775192\tkl:   28.168364\n",
            "Epoch: 892 [40100/50000 (80%)]  \tLoss:   92.659317\trec:   64.640221\tkl:   28.019100\n",
            "====> Epoch: 892 Average train loss: 88.9035\n",
            "====> Validation set loss: 92.3599\n",
            "====> Validation set kl: 27.9805\n",
            "Epoch: 893 [  100/50000 ( 0%)]  \tLoss:   89.260468\trec:   61.042732\tkl:   28.217733\n",
            "Epoch: 893 [10100/50000 (20%)]  \tLoss:   90.052856\trec:   62.136738\tkl:   27.916122\n",
            "Epoch: 893 [20100/50000 (40%)]  \tLoss:   85.260551\trec:   58.023964\tkl:   27.236591\n",
            "Epoch: 893 [30100/50000 (60%)]  \tLoss:   86.866112\trec:   58.434883\tkl:   28.431231\n",
            "Epoch: 893 [40100/50000 (80%)]  \tLoss:   90.360497\trec:   61.816357\tkl:   28.544142\n",
            "====> Epoch: 893 Average train loss: 88.8675\n",
            "====> Validation set loss: 92.3274\n",
            "====> Validation set kl: 27.8246\n",
            "Epoch: 894 [  100/50000 ( 0%)]  \tLoss:   90.711823\trec:   61.821491\tkl:   28.890333\n",
            "Epoch: 894 [10100/50000 (20%)]  \tLoss:   90.858681\trec:   62.141819\tkl:   28.716860\n",
            "Epoch: 894 [20100/50000 (40%)]  \tLoss:   86.352341\trec:   59.315716\tkl:   27.036629\n",
            "Epoch: 894 [30100/50000 (60%)]  \tLoss:   91.422592\trec:   63.231697\tkl:   28.190901\n",
            "Epoch: 894 [40100/50000 (80%)]  \tLoss:   91.005859\trec:   63.308388\tkl:   27.697466\n",
            "====> Epoch: 894 Average train loss: 88.8980\n",
            "====> Validation set loss: 92.3479\n",
            "====> Validation set kl: 27.7868\n",
            "Epoch: 895 [  100/50000 ( 0%)]  \tLoss:   90.892075\trec:   62.440266\tkl:   28.451813\n",
            "Epoch: 895 [10100/50000 (20%)]  \tLoss:   89.108803\trec:   61.673172\tkl:   27.435631\n",
            "Epoch: 895 [20100/50000 (40%)]  \tLoss:   92.831459\trec:   64.151276\tkl:   28.680183\n",
            "Epoch: 895 [30100/50000 (60%)]  \tLoss:   90.575546\trec:   62.554470\tkl:   28.021076\n",
            "Epoch: 895 [40100/50000 (80%)]  \tLoss:   86.521919\trec:   58.413597\tkl:   28.108324\n",
            "====> Epoch: 895 Average train loss: 88.8769\n",
            "====> Validation set loss: 92.3336\n",
            "====> Validation set kl: 27.7221\n",
            "Epoch: 896 [  100/50000 ( 0%)]  \tLoss:   91.130493\trec:   62.528522\tkl:   28.601974\n",
            "Epoch: 896 [10100/50000 (20%)]  \tLoss:   89.721802\trec:   61.833679\tkl:   27.888123\n",
            "Epoch: 896 [20100/50000 (40%)]  \tLoss:   87.627563\trec:   60.298290\tkl:   27.329279\n",
            "Epoch: 896 [30100/50000 (60%)]  \tLoss:   87.784393\trec:   60.507401\tkl:   27.276997\n",
            "Epoch: 896 [40100/50000 (80%)]  \tLoss:   89.344048\trec:   60.874619\tkl:   28.469431\n",
            "====> Epoch: 896 Average train loss: 88.8721\n",
            "====> Validation set loss: 92.3716\n",
            "====> Validation set kl: 27.8992\n",
            "Epoch: 897 [  100/50000 ( 0%)]  \tLoss:   88.484665\trec:   61.443737\tkl:   27.040930\n",
            "Epoch: 897 [10100/50000 (20%)]  \tLoss:   91.628014\trec:   63.430107\tkl:   28.197912\n",
            "Epoch: 897 [20100/50000 (40%)]  \tLoss:   87.505737\trec:   60.037235\tkl:   27.468500\n",
            "Epoch: 897 [30100/50000 (60%)]  \tLoss:   88.402557\trec:   60.635986\tkl:   27.766575\n",
            "Epoch: 897 [40100/50000 (80%)]  \tLoss:   84.499161\trec:   57.852234\tkl:   26.646919\n",
            "====> Epoch: 897 Average train loss: 88.8984\n",
            "====> Validation set loss: 92.3478\n",
            "====> Validation set kl: 27.9099\n",
            "Epoch: 898 [  100/50000 ( 0%)]  \tLoss:   90.442459\trec:   61.622471\tkl:   28.819994\n",
            "Epoch: 898 [10100/50000 (20%)]  \tLoss:   89.033623\trec:   60.190208\tkl:   28.843412\n",
            "Epoch: 898 [20100/50000 (40%)]  \tLoss:   91.815636\trec:   62.819408\tkl:   28.996225\n",
            "Epoch: 898 [30100/50000 (60%)]  \tLoss:   91.393394\trec:   62.622139\tkl:   28.771263\n",
            "Epoch: 898 [40100/50000 (80%)]  \tLoss:   85.062645\trec:   58.259167\tkl:   26.803474\n",
            "====> Epoch: 898 Average train loss: 88.8626\n",
            "====> Validation set loss: 92.3289\n",
            "====> Validation set kl: 27.6948\n",
            "Epoch: 899 [  100/50000 ( 0%)]  \tLoss:   89.486244\trec:   61.743801\tkl:   27.742443\n",
            "Epoch: 899 [10100/50000 (20%)]  \tLoss:   91.454994\trec:   63.076279\tkl:   28.378716\n",
            "Epoch: 899 [20100/50000 (40%)]  \tLoss:   87.374336\trec:   59.475643\tkl:   27.898691\n",
            "Epoch: 899 [30100/50000 (60%)]  \tLoss:   91.914169\trec:   62.982666\tkl:   28.931505\n",
            "Epoch: 899 [40100/50000 (80%)]  \tLoss:   89.080757\trec:   60.815365\tkl:   28.265390\n",
            "====> Epoch: 899 Average train loss: 88.8915\n",
            "====> Validation set loss: 92.3378\n",
            "====> Validation set kl: 27.8078\n",
            "Epoch: 900 [  100/50000 ( 0%)]  \tLoss:   86.729645\trec:   59.135342\tkl:   27.594307\n",
            "Epoch: 900 [10100/50000 (20%)]  \tLoss:   88.527481\trec:   60.094833\tkl:   28.432640\n",
            "Epoch: 900 [20100/50000 (40%)]  \tLoss:   90.551186\trec:   62.651009\tkl:   27.900185\n",
            "Epoch: 900 [30100/50000 (60%)]  \tLoss:   89.632912\trec:   60.883858\tkl:   28.749052\n",
            "Epoch: 900 [40100/50000 (80%)]  \tLoss:   88.129517\trec:   60.292435\tkl:   27.837084\n",
            "====> Epoch: 900 Average train loss: 88.8716\n",
            "====> Validation set loss: 92.3164\n",
            "====> Validation set kl: 27.8089\n",
            "Epoch: 901 [  100/50000 ( 0%)]  \tLoss:   89.571236\trec:   61.985371\tkl:   27.585871\n",
            "Epoch: 901 [10100/50000 (20%)]  \tLoss:   88.039772\trec:   60.063366\tkl:   27.976406\n",
            "Epoch: 901 [20100/50000 (40%)]  \tLoss:   87.513649\trec:   60.073589\tkl:   27.440063\n",
            "Epoch: 901 [30100/50000 (60%)]  \tLoss:   91.977699\trec:   62.430508\tkl:   29.547199\n",
            "Epoch: 901 [40100/50000 (80%)]  \tLoss:   88.654472\trec:   60.564079\tkl:   28.090389\n",
            "====> Epoch: 901 Average train loss: 88.8754\n",
            "====> Validation set loss: 92.2602\n",
            "====> Validation set kl: 27.7712\n",
            "Epoch: 902 [  100/50000 ( 0%)]  \tLoss:   90.577789\trec:   61.896858\tkl:   28.680937\n",
            "Epoch: 902 [10100/50000 (20%)]  \tLoss:   91.320587\trec:   62.748669\tkl:   28.571911\n",
            "Epoch: 902 [20100/50000 (40%)]  \tLoss:   84.771385\trec:   58.115761\tkl:   26.655624\n",
            "Epoch: 902 [30100/50000 (60%)]  \tLoss:   88.842262\trec:   60.289452\tkl:   28.552807\n",
            "Epoch: 902 [40100/50000 (80%)]  \tLoss:   83.298340\trec:   56.107353\tkl:   27.190987\n",
            "====> Epoch: 902 Average train loss: 88.8677\n",
            "====> Validation set loss: 92.2324\n",
            "====> Validation set kl: 27.7358\n",
            "Epoch: 903 [  100/50000 ( 0%)]  \tLoss:   85.359001\trec:   58.516396\tkl:   26.842604\n",
            "Epoch: 903 [10100/50000 (20%)]  \tLoss:   87.341896\trec:   59.761635\tkl:   27.580256\n",
            "Epoch: 903 [20100/50000 (40%)]  \tLoss:   89.565788\trec:   61.980476\tkl:   27.585312\n",
            "Epoch: 903 [30100/50000 (60%)]  \tLoss:   90.392189\trec:   62.955086\tkl:   27.437096\n",
            "Epoch: 903 [40100/50000 (80%)]  \tLoss:   86.628777\trec:   59.534668\tkl:   27.094109\n",
            "====> Epoch: 903 Average train loss: 88.8738\n",
            "====> Validation set loss: 92.4972\n",
            "====> Validation set kl: 27.9920\n",
            "Epoch: 904 [  100/50000 ( 0%)]  \tLoss:   85.401894\trec:   57.921494\tkl:   27.480394\n",
            "Epoch: 904 [10100/50000 (20%)]  \tLoss:   89.560249\trec:   62.268372\tkl:   27.291882\n",
            "Epoch: 904 [20100/50000 (40%)]  \tLoss:   88.856071\trec:   61.448704\tkl:   27.407370\n",
            "Epoch: 904 [30100/50000 (60%)]  \tLoss:   88.870506\trec:   60.483555\tkl:   28.386953\n",
            "Epoch: 904 [40100/50000 (80%)]  \tLoss:   88.805977\trec:   60.939201\tkl:   27.866770\n",
            "====> Epoch: 904 Average train loss: 88.8704\n",
            "====> Validation set loss: 92.2461\n",
            "====> Validation set kl: 27.6013\n",
            "Epoch: 905 [  100/50000 ( 0%)]  \tLoss:   90.585289\trec:   62.442211\tkl:   28.143084\n",
            "Epoch: 905 [10100/50000 (20%)]  \tLoss:   90.629433\trec:   62.523632\tkl:   28.105801\n",
            "Epoch: 905 [20100/50000 (40%)]  \tLoss:   88.137306\trec:   60.296616\tkl:   27.840683\n",
            "Epoch: 905 [30100/50000 (60%)]  \tLoss:   90.105965\trec:   62.209099\tkl:   27.896868\n",
            "Epoch: 905 [40100/50000 (80%)]  \tLoss:   89.329315\trec:   61.293049\tkl:   28.036263\n",
            "====> Epoch: 905 Average train loss: 88.8655\n",
            "====> Validation set loss: 92.3385\n",
            "====> Validation set kl: 27.5827\n",
            "Epoch: 906 [  100/50000 ( 0%)]  \tLoss:   87.156570\trec:   60.198093\tkl:   26.958475\n",
            "Epoch: 906 [10100/50000 (20%)]  \tLoss:   88.219688\trec:   60.217705\tkl:   28.001982\n",
            "Epoch: 906 [20100/50000 (40%)]  \tLoss:   88.741119\trec:   60.781151\tkl:   27.959970\n",
            "Epoch: 906 [30100/50000 (60%)]  \tLoss:   87.168686\trec:   59.672821\tkl:   27.495871\n",
            "Epoch: 906 [40100/50000 (80%)]  \tLoss:   87.820763\trec:   59.523075\tkl:   28.297686\n",
            "====> Epoch: 906 Average train loss: 88.8688\n",
            "====> Validation set loss: 92.2572\n",
            "====> Validation set kl: 27.8456\n",
            "Epoch: 907 [  100/50000 ( 0%)]  \tLoss:   90.233139\trec:   62.548244\tkl:   27.684898\n",
            "Epoch: 907 [10100/50000 (20%)]  \tLoss:   86.853516\trec:   59.895771\tkl:   26.957741\n",
            "Epoch: 907 [20100/50000 (40%)]  \tLoss:   86.789970\trec:   59.379463\tkl:   27.410507\n",
            "Epoch: 907 [30100/50000 (60%)]  \tLoss:   90.285782\trec:   62.969978\tkl:   27.315798\n",
            "Epoch: 907 [40100/50000 (80%)]  \tLoss:   86.847466\trec:   59.181961\tkl:   27.665510\n",
            "====> Epoch: 907 Average train loss: 88.8701\n",
            "====> Validation set loss: 92.3666\n",
            "====> Validation set kl: 27.8670\n",
            "Epoch: 908 [  100/50000 ( 0%)]  \tLoss:   85.139900\trec:   58.003525\tkl:   27.136375\n",
            "Epoch: 908 [10100/50000 (20%)]  \tLoss:   87.816505\trec:   59.789764\tkl:   28.026733\n",
            "Epoch: 908 [20100/50000 (40%)]  \tLoss:   84.752831\trec:   58.158073\tkl:   26.594761\n",
            "Epoch: 908 [30100/50000 (60%)]  \tLoss:   90.168022\trec:   60.746078\tkl:   29.421946\n",
            "Epoch: 908 [40100/50000 (80%)]  \tLoss:   94.039047\trec:   64.952126\tkl:   29.086920\n",
            "====> Epoch: 908 Average train loss: 88.8517\n",
            "====> Validation set loss: 92.2403\n",
            "====> Validation set kl: 27.8260\n",
            "Epoch: 909 [  100/50000 ( 0%)]  \tLoss:   88.739410\trec:   60.671257\tkl:   28.068155\n",
            "Epoch: 909 [10100/50000 (20%)]  \tLoss:   85.970024\trec:   59.172634\tkl:   26.797392\n",
            "Epoch: 909 [20100/50000 (40%)]  \tLoss:   90.358727\trec:   61.870544\tkl:   28.488186\n",
            "Epoch: 909 [30100/50000 (60%)]  \tLoss:   87.597801\trec:   58.801891\tkl:   28.795906\n",
            "Epoch: 909 [40100/50000 (80%)]  \tLoss:   90.686172\trec:   62.157627\tkl:   28.528543\n",
            "====> Epoch: 909 Average train loss: 88.8432\n",
            "====> Validation set loss: 92.2420\n",
            "====> Validation set kl: 27.8378\n",
            "Epoch: 910 [  100/50000 ( 0%)]  \tLoss:   88.958435\trec:   61.008102\tkl:   27.950336\n",
            "Epoch: 910 [10100/50000 (20%)]  \tLoss:   90.630898\trec:   62.442810\tkl:   28.188087\n",
            "Epoch: 910 [20100/50000 (40%)]  \tLoss:   86.320312\trec:   58.819111\tkl:   27.501196\n",
            "Epoch: 910 [30100/50000 (60%)]  \tLoss:   84.231522\trec:   56.394821\tkl:   27.836693\n",
            "Epoch: 910 [40100/50000 (80%)]  \tLoss:   86.934410\trec:   59.298409\tkl:   27.636009\n",
            "====> Epoch: 910 Average train loss: 88.8335\n",
            "====> Validation set loss: 92.2740\n",
            "====> Validation set kl: 27.6029\n",
            "Epoch: 911 [  100/50000 ( 0%)]  \tLoss:   88.216675\trec:   60.487820\tkl:   27.728859\n",
            "Epoch: 911 [10100/50000 (20%)]  \tLoss:   89.041847\trec:   61.352856\tkl:   27.688992\n",
            "Epoch: 911 [20100/50000 (40%)]  \tLoss:   86.364571\trec:   57.988411\tkl:   28.376152\n",
            "Epoch: 911 [30100/50000 (60%)]  \tLoss:   89.032501\trec:   61.318295\tkl:   27.714201\n",
            "Epoch: 911 [40100/50000 (80%)]  \tLoss:   88.552765\trec:   60.627178\tkl:   27.925589\n",
            "====> Epoch: 911 Average train loss: 88.8724\n",
            "====> Validation set loss: 92.3436\n",
            "====> Validation set kl: 27.6946\n",
            "Epoch: 912 [  100/50000 ( 0%)]  \tLoss:   91.564987\trec:   62.907387\tkl:   28.657600\n",
            "Epoch: 912 [10100/50000 (20%)]  \tLoss:   90.276993\trec:   62.204868\tkl:   28.072119\n",
            "Epoch: 912 [20100/50000 (40%)]  \tLoss:   87.378990\trec:   59.395622\tkl:   27.983372\n",
            "Epoch: 912 [30100/50000 (60%)]  \tLoss:   89.689369\trec:   61.970806\tkl:   27.718563\n",
            "Epoch: 912 [40100/50000 (80%)]  \tLoss:   91.582809\trec:   63.356884\tkl:   28.225925\n",
            "====> Epoch: 912 Average train loss: 88.8356\n",
            "====> Validation set loss: 92.2382\n",
            "====> Validation set kl: 27.9055\n",
            "Epoch: 913 [  100/50000 ( 0%)]  \tLoss:   88.276627\trec:   59.861580\tkl:   28.415051\n",
            "Epoch: 913 [10100/50000 (20%)]  \tLoss:   92.350105\trec:   63.296951\tkl:   29.053156\n",
            "Epoch: 913 [20100/50000 (40%)]  \tLoss:   91.110565\trec:   62.426296\tkl:   28.684273\n",
            "Epoch: 913 [30100/50000 (60%)]  \tLoss:   89.967010\trec:   62.564140\tkl:   27.402876\n",
            "Epoch: 913 [40100/50000 (80%)]  \tLoss:   88.707809\trec:   60.284599\tkl:   28.423210\n",
            "====> Epoch: 913 Average train loss: 88.8288\n",
            "====> Validation set loss: 92.3480\n",
            "====> Validation set kl: 27.8431\n",
            "Epoch: 914 [  100/50000 ( 0%)]  \tLoss:   87.099777\trec:   59.695038\tkl:   27.404734\n",
            "Epoch: 914 [10100/50000 (20%)]  \tLoss:   87.636200\trec:   60.244343\tkl:   27.391855\n",
            "Epoch: 914 [20100/50000 (40%)]  \tLoss:   90.330933\trec:   61.985672\tkl:   28.345266\n",
            "Epoch: 914 [30100/50000 (60%)]  \tLoss:   89.139648\trec:   61.601131\tkl:   27.538521\n",
            "Epoch: 914 [40100/50000 (80%)]  \tLoss:   87.962730\trec:   60.539463\tkl:   27.423265\n",
            "====> Epoch: 914 Average train loss: 88.8526\n",
            "====> Validation set loss: 92.3244\n",
            "====> Validation set kl: 27.8952\n",
            "Epoch: 915 [  100/50000 ( 0%)]  \tLoss:   91.451447\trec:   63.443333\tkl:   28.008112\n",
            "Epoch: 915 [10100/50000 (20%)]  \tLoss:   89.853218\trec:   61.866344\tkl:   27.986872\n",
            "Epoch: 915 [20100/50000 (40%)]  \tLoss:   93.254150\trec:   64.014580\tkl:   29.239567\n",
            "Epoch: 915 [30100/50000 (60%)]  \tLoss:   86.773094\trec:   59.205067\tkl:   27.568027\n",
            "Epoch: 915 [40100/50000 (80%)]  \tLoss:   86.387489\trec:   58.257908\tkl:   28.129580\n",
            "====> Epoch: 915 Average train loss: 88.8381\n",
            "====> Validation set loss: 92.2879\n",
            "====> Validation set kl: 27.8244\n",
            "Epoch: 916 [  100/50000 ( 0%)]  \tLoss:   87.302559\trec:   59.904675\tkl:   27.397881\n",
            "Epoch: 916 [10100/50000 (20%)]  \tLoss:   87.274010\trec:   59.958954\tkl:   27.315060\n",
            "Epoch: 916 [20100/50000 (40%)]  \tLoss:   91.267075\trec:   62.426804\tkl:   28.840273\n",
            "Epoch: 916 [30100/50000 (60%)]  \tLoss:   86.845917\trec:   59.374889\tkl:   27.471022\n",
            "Epoch: 916 [40100/50000 (80%)]  \tLoss:   89.916733\trec:   61.965954\tkl:   27.950779\n",
            "====> Epoch: 916 Average train loss: 88.8228\n",
            "====> Validation set loss: 92.3094\n",
            "====> Validation set kl: 27.9371\n",
            "Epoch: 917 [  100/50000 ( 0%)]  \tLoss:   88.020294\trec:   60.322552\tkl:   27.697741\n",
            "Epoch: 917 [10100/50000 (20%)]  \tLoss:   90.288429\trec:   61.481903\tkl:   28.806522\n",
            "Epoch: 917 [20100/50000 (40%)]  \tLoss:   90.419106\trec:   62.204628\tkl:   28.214481\n",
            "Epoch: 917 [30100/50000 (60%)]  \tLoss:   89.445900\trec:   61.655350\tkl:   27.790548\n",
            "Epoch: 917 [40100/50000 (80%)]  \tLoss:   92.085457\trec:   64.079384\tkl:   28.006073\n",
            "====> Epoch: 917 Average train loss: 88.8463\n",
            "====> Validation set loss: 92.3015\n",
            "====> Validation set kl: 27.6878\n",
            "Epoch: 918 [  100/50000 ( 0%)]  \tLoss:   90.156326\trec:   62.857059\tkl:   27.299265\n",
            "Epoch: 918 [10100/50000 (20%)]  \tLoss:   90.701447\trec:   62.440807\tkl:   28.260639\n",
            "Epoch: 918 [20100/50000 (40%)]  \tLoss:   89.175133\trec:   61.443298\tkl:   27.731838\n",
            "Epoch: 918 [30100/50000 (60%)]  \tLoss:   91.142090\trec:   62.997261\tkl:   28.144831\n",
            "Epoch: 918 [40100/50000 (80%)]  \tLoss:   84.612823\trec:   58.415241\tkl:   26.197575\n",
            "====> Epoch: 918 Average train loss: 88.8236\n",
            "====> Validation set loss: 92.3194\n",
            "====> Validation set kl: 27.8425\n",
            "Epoch: 919 [  100/50000 ( 0%)]  \tLoss:   89.649170\trec:   60.314354\tkl:   29.334814\n",
            "Epoch: 919 [10100/50000 (20%)]  \tLoss:   89.092804\trec:   61.166542\tkl:   27.926262\n",
            "Epoch: 919 [20100/50000 (40%)]  \tLoss:   90.566391\trec:   62.203758\tkl:   28.362633\n",
            "Epoch: 919 [30100/50000 (60%)]  \tLoss:   89.569077\trec:   61.262489\tkl:   28.306597\n",
            "Epoch: 919 [40100/50000 (80%)]  \tLoss:   89.753281\trec:   60.846142\tkl:   28.907143\n",
            "====> Epoch: 919 Average train loss: 88.8476\n",
            "====> Validation set loss: 92.3314\n",
            "====> Validation set kl: 27.8523\n",
            "Epoch: 920 [  100/50000 ( 0%)]  \tLoss:   85.492271\trec:   57.984257\tkl:   27.508018\n",
            "Epoch: 920 [10100/50000 (20%)]  \tLoss:   90.459518\trec:   62.396805\tkl:   28.062712\n",
            "Epoch: 920 [20100/50000 (40%)]  \tLoss:   84.730766\trec:   58.615467\tkl:   26.115299\n",
            "Epoch: 920 [30100/50000 (60%)]  \tLoss:   92.176788\trec:   63.114891\tkl:   29.061893\n",
            "Epoch: 920 [40100/50000 (80%)]  \tLoss:   86.165756\trec:   58.361755\tkl:   27.803999\n",
            "====> Epoch: 920 Average train loss: 88.8351\n",
            "====> Validation set loss: 92.1948\n",
            "====> Validation set kl: 27.8625\n",
            "Epoch: 921 [  100/50000 ( 0%)]  \tLoss:   88.841560\trec:   61.424606\tkl:   27.416950\n",
            "Epoch: 921 [10100/50000 (20%)]  \tLoss:   90.340332\trec:   61.614346\tkl:   28.725990\n",
            "Epoch: 921 [20100/50000 (40%)]  \tLoss:   87.252281\trec:   59.591297\tkl:   27.660990\n",
            "Epoch: 921 [30100/50000 (60%)]  \tLoss:   85.973541\trec:   58.753017\tkl:   27.220524\n",
            "Epoch: 921 [40100/50000 (80%)]  \tLoss:   88.970039\trec:   60.278759\tkl:   28.691280\n",
            "====> Epoch: 921 Average train loss: 88.8357\n",
            "====> Validation set loss: 92.2550\n",
            "====> Validation set kl: 27.5958\n",
            "Epoch: 922 [  100/50000 ( 0%)]  \tLoss:   90.809624\trec:   63.890594\tkl:   26.919027\n",
            "Epoch: 922 [10100/50000 (20%)]  \tLoss:   87.936813\trec:   59.862762\tkl:   28.074053\n",
            "Epoch: 922 [20100/50000 (40%)]  \tLoss:   92.026306\trec:   63.498661\tkl:   28.527641\n",
            "Epoch: 922 [30100/50000 (60%)]  \tLoss:   91.189529\trec:   63.096905\tkl:   28.092625\n",
            "Epoch: 922 [40100/50000 (80%)]  \tLoss:   85.376762\trec:   57.839085\tkl:   27.537682\n",
            "====> Epoch: 922 Average train loss: 88.8329\n",
            "====> Validation set loss: 92.3525\n",
            "====> Validation set kl: 27.7417\n",
            "Epoch: 923 [  100/50000 ( 0%)]  \tLoss:   91.012840\trec:   62.325222\tkl:   28.687616\n",
            "Epoch: 923 [10100/50000 (20%)]  \tLoss:   90.443947\trec:   63.116459\tkl:   27.327484\n",
            "Epoch: 923 [20100/50000 (40%)]  \tLoss:   86.293083\trec:   59.275349\tkl:   27.017736\n",
            "Epoch: 923 [30100/50000 (60%)]  \tLoss:   86.725700\trec:   59.336967\tkl:   27.388737\n",
            "Epoch: 923 [40100/50000 (80%)]  \tLoss:   91.468651\trec:   62.501503\tkl:   28.967142\n",
            "====> Epoch: 923 Average train loss: 88.8165\n",
            "====> Validation set loss: 92.3799\n",
            "====> Validation set kl: 27.9331\n",
            "Epoch: 924 [  100/50000 ( 0%)]  \tLoss:   89.336700\trec:   60.433723\tkl:   28.902977\n",
            "Epoch: 924 [10100/50000 (20%)]  \tLoss:   89.162460\trec:   61.405907\tkl:   27.756557\n",
            "Epoch: 924 [20100/50000 (40%)]  \tLoss:   89.567696\trec:   62.152058\tkl:   27.415628\n",
            "Epoch: 924 [30100/50000 (60%)]  \tLoss:   88.590660\trec:   61.342411\tkl:   27.248253\n",
            "Epoch: 924 [40100/50000 (80%)]  \tLoss:   90.853386\trec:   62.812675\tkl:   28.040714\n",
            "====> Epoch: 924 Average train loss: 88.8332\n",
            "====> Validation set loss: 92.2454\n",
            "====> Validation set kl: 27.7523\n",
            "Epoch: 925 [  100/50000 ( 0%)]  \tLoss:   89.304352\trec:   61.211502\tkl:   28.092846\n",
            "Epoch: 925 [10100/50000 (20%)]  \tLoss:   89.135849\trec:   60.889874\tkl:   28.245975\n",
            "Epoch: 925 [20100/50000 (40%)]  \tLoss:   87.765800\trec:   59.557236\tkl:   28.208561\n",
            "Epoch: 925 [30100/50000 (60%)]  \tLoss:   87.512794\trec:   60.039421\tkl:   27.473364\n",
            "Epoch: 925 [40100/50000 (80%)]  \tLoss:   87.037338\trec:   59.513603\tkl:   27.523743\n",
            "====> Epoch: 925 Average train loss: 88.8069\n",
            "====> Validation set loss: 92.2444\n",
            "====> Validation set kl: 27.7583\n",
            "Epoch: 926 [  100/50000 ( 0%)]  \tLoss:   87.148026\trec:   58.794689\tkl:   28.353336\n",
            "Epoch: 926 [10100/50000 (20%)]  \tLoss:   87.540184\trec:   59.759457\tkl:   27.780724\n",
            "Epoch: 926 [20100/50000 (40%)]  \tLoss:   88.894249\trec:   61.067665\tkl:   27.826578\n",
            "Epoch: 926 [30100/50000 (60%)]  \tLoss:   84.167091\trec:   56.896599\tkl:   27.270487\n",
            "Epoch: 926 [40100/50000 (80%)]  \tLoss:   89.897362\trec:   62.498749\tkl:   27.398613\n",
            "====> Epoch: 926 Average train loss: 88.8044\n",
            "====> Validation set loss: 92.3474\n",
            "====> Validation set kl: 28.0045\n",
            "Epoch: 927 [  100/50000 ( 0%)]  \tLoss:   92.688263\trec:   63.824814\tkl:   28.863443\n",
            "Epoch: 927 [10100/50000 (20%)]  \tLoss:   89.620064\trec:   61.940853\tkl:   27.679211\n",
            "Epoch: 927 [20100/50000 (40%)]  \tLoss:   91.961540\trec:   63.629063\tkl:   28.332481\n",
            "Epoch: 927 [30100/50000 (60%)]  \tLoss:   94.344955\trec:   64.786980\tkl:   29.557980\n",
            "Epoch: 927 [40100/50000 (80%)]  \tLoss:   87.950020\trec:   61.142231\tkl:   26.807787\n",
            "====> Epoch: 927 Average train loss: 88.7971\n",
            "====> Validation set loss: 92.2877\n",
            "====> Validation set kl: 27.8891\n",
            "Epoch: 928 [  100/50000 ( 0%)]  \tLoss:   84.921890\trec:   57.958778\tkl:   26.963120\n",
            "Epoch: 928 [10100/50000 (20%)]  \tLoss:   86.332100\trec:   59.082214\tkl:   27.249880\n",
            "Epoch: 928 [20100/50000 (40%)]  \tLoss:   89.490479\trec:   62.014153\tkl:   27.476320\n",
            "Epoch: 928 [30100/50000 (60%)]  \tLoss:   90.895309\trec:   61.618896\tkl:   29.276421\n",
            "Epoch: 928 [40100/50000 (80%)]  \tLoss:   88.653732\trec:   61.215878\tkl:   27.437853\n",
            "====> Epoch: 928 Average train loss: 88.8054\n",
            "====> Validation set loss: 92.3334\n",
            "====> Validation set kl: 27.6101\n",
            "Epoch: 929 [  100/50000 ( 0%)]  \tLoss:   86.725266\trec:   59.145561\tkl:   27.579702\n",
            "Epoch: 929 [10100/50000 (20%)]  \tLoss:   85.176437\trec:   58.021492\tkl:   27.154943\n",
            "Epoch: 929 [20100/50000 (40%)]  \tLoss:   89.821915\trec:   62.019844\tkl:   27.802067\n",
            "Epoch: 929 [30100/50000 (60%)]  \tLoss:   87.323296\trec:   60.432095\tkl:   26.891203\n",
            "Epoch: 929 [40100/50000 (80%)]  \tLoss:   89.344521\trec:   60.665440\tkl:   28.679081\n",
            "====> Epoch: 929 Average train loss: 88.8259\n",
            "====> Validation set loss: 92.3755\n",
            "====> Validation set kl: 27.6771\n",
            "Epoch: 930 [  100/50000 ( 0%)]  \tLoss:   91.326950\trec:   63.057549\tkl:   28.269402\n",
            "Epoch: 930 [10100/50000 (20%)]  \tLoss:   89.461441\trec:   61.415852\tkl:   28.045589\n",
            "Epoch: 930 [20100/50000 (40%)]  \tLoss:   89.867439\trec:   61.360794\tkl:   28.506649\n",
            "Epoch: 930 [30100/50000 (60%)]  \tLoss:   88.734917\trec:   60.594952\tkl:   28.139965\n",
            "Epoch: 930 [40100/50000 (80%)]  \tLoss:   91.080528\trec:   61.936638\tkl:   29.143887\n",
            "====> Epoch: 930 Average train loss: 88.8168\n",
            "====> Validation set loss: 92.2052\n",
            "====> Validation set kl: 27.7558\n",
            "Epoch: 931 [  100/50000 ( 0%)]  \tLoss:   85.631035\trec:   58.103828\tkl:   27.527208\n",
            "Epoch: 931 [10100/50000 (20%)]  \tLoss:   90.953629\trec:   62.666786\tkl:   28.286840\n",
            "Epoch: 931 [20100/50000 (40%)]  \tLoss:   95.083496\trec:   65.449860\tkl:   29.633636\n",
            "Epoch: 931 [30100/50000 (60%)]  \tLoss:   89.616776\trec:   61.305618\tkl:   28.311157\n",
            "Epoch: 931 [40100/50000 (80%)]  \tLoss:   90.562538\trec:   62.646717\tkl:   27.915815\n",
            "====> Epoch: 931 Average train loss: 88.7860\n",
            "====> Validation set loss: 92.2779\n",
            "====> Validation set kl: 27.8025\n",
            "Epoch: 932 [  100/50000 ( 0%)]  \tLoss:   85.443169\trec:   58.417439\tkl:   27.025732\n",
            "Epoch: 932 [10100/50000 (20%)]  \tLoss:   87.583786\trec:   59.424023\tkl:   28.159760\n",
            "Epoch: 932 [20100/50000 (40%)]  \tLoss:   91.330956\trec:   63.500252\tkl:   27.830706\n",
            "Epoch: 932 [30100/50000 (60%)]  \tLoss:   91.498718\trec:   62.755653\tkl:   28.743065\n",
            "Epoch: 932 [40100/50000 (80%)]  \tLoss:   88.615356\trec:   60.957069\tkl:   27.658293\n",
            "====> Epoch: 932 Average train loss: 88.8025\n",
            "====> Validation set loss: 92.2225\n",
            "====> Validation set kl: 27.8073\n",
            "Epoch: 933 [  100/50000 ( 0%)]  \tLoss:   85.738014\trec:   58.003887\tkl:   27.734133\n",
            "Epoch: 933 [10100/50000 (20%)]  \tLoss:   86.684494\trec:   59.046097\tkl:   27.638397\n",
            "Epoch: 933 [20100/50000 (40%)]  \tLoss:   89.503281\trec:   63.076580\tkl:   26.426693\n",
            "Epoch: 933 [30100/50000 (60%)]  \tLoss:   89.531364\trec:   61.585503\tkl:   27.945862\n",
            "Epoch: 933 [40100/50000 (80%)]  \tLoss:   86.840782\trec:   59.208538\tkl:   27.632242\n",
            "====> Epoch: 933 Average train loss: 88.7927\n",
            "====> Validation set loss: 92.1652\n",
            "====> Validation set kl: 27.6733\n",
            "Epoch: 934 [  100/50000 ( 0%)]  \tLoss:   90.308975\trec:   62.186317\tkl:   28.122656\n",
            "Epoch: 934 [10100/50000 (20%)]  \tLoss:   89.678612\trec:   61.896713\tkl:   27.781897\n",
            "Epoch: 934 [20100/50000 (40%)]  \tLoss:   89.070625\trec:   60.657459\tkl:   28.413158\n",
            "Epoch: 934 [30100/50000 (60%)]  \tLoss:   95.050018\trec:   65.509308\tkl:   29.540710\n",
            "Epoch: 934 [40100/50000 (80%)]  \tLoss:   91.032478\trec:   63.253387\tkl:   27.779097\n",
            "====> Epoch: 934 Average train loss: 88.8114\n",
            "====> Validation set loss: 92.3113\n",
            "====> Validation set kl: 27.8415\n",
            "Epoch: 935 [  100/50000 ( 0%)]  \tLoss:   89.825897\trec:   61.199368\tkl:   28.626522\n",
            "Epoch: 935 [10100/50000 (20%)]  \tLoss:   90.733009\trec:   61.778965\tkl:   28.954044\n",
            "Epoch: 935 [20100/50000 (40%)]  \tLoss:   86.784721\trec:   58.659412\tkl:   28.125315\n",
            "Epoch: 935 [30100/50000 (60%)]  \tLoss:   88.974098\trec:   61.176350\tkl:   27.797752\n",
            "Epoch: 935 [40100/50000 (80%)]  \tLoss:   87.369415\trec:   59.770042\tkl:   27.599369\n",
            "====> Epoch: 935 Average train loss: 88.8006\n",
            "====> Validation set loss: 92.2958\n",
            "====> Validation set kl: 27.9391\n",
            "Epoch: 936 [  100/50000 ( 0%)]  \tLoss:   90.484283\trec:   60.854919\tkl:   29.629368\n",
            "Epoch: 936 [10100/50000 (20%)]  \tLoss:   87.592888\trec:   59.995884\tkl:   27.597006\n",
            "Epoch: 936 [20100/50000 (40%)]  \tLoss:   88.128784\trec:   59.727062\tkl:   28.401724\n",
            "Epoch: 936 [30100/50000 (60%)]  \tLoss:   92.764687\trec:   63.045155\tkl:   29.719528\n",
            "Epoch: 936 [40100/50000 (80%)]  \tLoss:   90.632133\trec:   62.976254\tkl:   27.655880\n",
            "====> Epoch: 936 Average train loss: 88.7688\n",
            "====> Validation set loss: 92.2393\n",
            "====> Validation set kl: 27.7999\n",
            "Epoch: 937 [  100/50000 ( 0%)]  \tLoss:   89.427780\trec:   61.349350\tkl:   28.078434\n",
            "Epoch: 937 [10100/50000 (20%)]  \tLoss:   90.332840\trec:   60.909119\tkl:   29.423719\n",
            "Epoch: 937 [20100/50000 (40%)]  \tLoss:   86.781105\trec:   59.749092\tkl:   27.032011\n",
            "Epoch: 937 [30100/50000 (60%)]  \tLoss:   92.959747\trec:   65.203781\tkl:   27.755957\n",
            "Epoch: 937 [40100/50000 (80%)]  \tLoss:   91.625137\trec:   63.537354\tkl:   28.087778\n",
            "====> Epoch: 937 Average train loss: 88.8034\n",
            "====> Validation set loss: 92.2686\n",
            "====> Validation set kl: 27.6822\n",
            "Epoch: 938 [  100/50000 ( 0%)]  \tLoss:   90.782196\trec:   61.949535\tkl:   28.832663\n",
            "Epoch: 938 [10100/50000 (20%)]  \tLoss:   89.303139\trec:   60.932507\tkl:   28.370634\n",
            "Epoch: 938 [20100/50000 (40%)]  \tLoss:   89.132538\trec:   61.112286\tkl:   28.020250\n",
            "Epoch: 938 [30100/50000 (60%)]  \tLoss:   92.633194\trec:   64.172638\tkl:   28.460554\n",
            "Epoch: 938 [40100/50000 (80%)]  \tLoss:   89.558228\trec:   61.231228\tkl:   28.327000\n",
            "====> Epoch: 938 Average train loss: 88.7912\n",
            "====> Validation set loss: 92.3503\n",
            "====> Validation set kl: 27.8328\n",
            "Epoch: 939 [  100/50000 ( 0%)]  \tLoss:   86.570503\trec:   59.448246\tkl:   27.122263\n",
            "Epoch: 939 [10100/50000 (20%)]  \tLoss:   89.890076\trec:   62.135925\tkl:   27.754154\n",
            "Epoch: 939 [20100/50000 (40%)]  \tLoss:   88.194809\trec:   60.797234\tkl:   27.397575\n",
            "Epoch: 939 [30100/50000 (60%)]  \tLoss:   88.850517\trec:   61.590042\tkl:   27.260473\n",
            "Epoch: 939 [40100/50000 (80%)]  \tLoss:   89.905655\trec:   61.001293\tkl:   28.904362\n",
            "====> Epoch: 939 Average train loss: 88.7836\n",
            "====> Validation set loss: 92.3163\n",
            "====> Validation set kl: 27.8259\n",
            "Epoch: 940 [  100/50000 ( 0%)]  \tLoss:   86.327324\trec:   58.290352\tkl:   28.036970\n",
            "Epoch: 940 [10100/50000 (20%)]  \tLoss:   90.213829\trec:   61.949619\tkl:   28.264208\n",
            "Epoch: 940 [20100/50000 (40%)]  \tLoss:   87.908371\trec:   59.803635\tkl:   28.104731\n",
            "Epoch: 940 [30100/50000 (60%)]  \tLoss:   90.305626\trec:   61.454235\tkl:   28.851381\n",
            "Epoch: 940 [40100/50000 (80%)]  \tLoss:   86.208458\trec:   58.490139\tkl:   27.718313\n",
            "====> Epoch: 940 Average train loss: 88.8051\n",
            "====> Validation set loss: 92.2921\n",
            "====> Validation set kl: 27.7111\n",
            "Epoch: 941 [  100/50000 ( 0%)]  \tLoss:   87.451599\trec:   59.299946\tkl:   28.151657\n",
            "Epoch: 941 [10100/50000 (20%)]  \tLoss:   85.046371\trec:   56.522705\tkl:   28.523674\n",
            "Epoch: 941 [20100/50000 (40%)]  \tLoss:   89.216515\trec:   61.455723\tkl:   27.760790\n",
            "Epoch: 941 [30100/50000 (60%)]  \tLoss:   88.946365\trec:   60.813259\tkl:   28.133102\n",
            "Epoch: 941 [40100/50000 (80%)]  \tLoss:   89.372818\trec:   60.677299\tkl:   28.695522\n",
            "====> Epoch: 941 Average train loss: 88.7560\n",
            "====> Validation set loss: 92.1940\n",
            "====> Validation set kl: 27.9506\n",
            "Epoch: 942 [  100/50000 ( 0%)]  \tLoss:   85.396309\trec:   58.891037\tkl:   26.505262\n",
            "Epoch: 942 [10100/50000 (20%)]  \tLoss:   89.418671\trec:   61.359619\tkl:   28.059055\n",
            "Epoch: 942 [20100/50000 (40%)]  \tLoss:   91.417168\trec:   63.155579\tkl:   28.261587\n",
            "Epoch: 942 [30100/50000 (60%)]  \tLoss:   88.125038\trec:   59.774033\tkl:   28.351009\n",
            "Epoch: 942 [40100/50000 (80%)]  \tLoss:   85.949165\trec:   59.556141\tkl:   26.393024\n",
            "====> Epoch: 942 Average train loss: 88.7922\n",
            "====> Validation set loss: 92.2823\n",
            "====> Validation set kl: 27.8175\n",
            "Epoch: 943 [  100/50000 ( 0%)]  \tLoss:   87.791885\trec:   59.884766\tkl:   27.907118\n",
            "Epoch: 943 [10100/50000 (20%)]  \tLoss:   92.784096\trec:   63.513157\tkl:   29.270937\n",
            "Epoch: 943 [20100/50000 (40%)]  \tLoss:   91.168533\trec:   62.232967\tkl:   28.935566\n",
            "Epoch: 943 [30100/50000 (60%)]  \tLoss:   89.187401\trec:   61.375847\tkl:   27.811546\n",
            "Epoch: 943 [40100/50000 (80%)]  \tLoss:   91.002518\trec:   62.405708\tkl:   28.596811\n",
            "====> Epoch: 943 Average train loss: 88.7785\n",
            "====> Validation set loss: 92.4232\n",
            "====> Validation set kl: 27.8355\n",
            "Epoch: 944 [  100/50000 ( 0%)]  \tLoss:   90.145386\trec:   61.938732\tkl:   28.206659\n",
            "Epoch: 944 [10100/50000 (20%)]  \tLoss:   89.653160\trec:   61.755291\tkl:   27.897873\n",
            "Epoch: 944 [20100/50000 (40%)]  \tLoss:   87.428635\trec:   60.748669\tkl:   26.679955\n",
            "Epoch: 944 [30100/50000 (60%)]  \tLoss:   88.739357\trec:   60.342705\tkl:   28.396650\n",
            "Epoch: 944 [40100/50000 (80%)]  \tLoss:   85.821396\trec:   58.331722\tkl:   27.489670\n",
            "====> Epoch: 944 Average train loss: 88.7748\n",
            "====> Validation set loss: 92.3308\n",
            "====> Validation set kl: 27.4597\n",
            "Epoch: 945 [  100/50000 ( 0%)]  \tLoss:   90.254898\trec:   62.572655\tkl:   27.682243\n",
            "Epoch: 945 [10100/50000 (20%)]  \tLoss:   92.368706\trec:   63.614773\tkl:   28.753935\n",
            "Epoch: 945 [20100/50000 (40%)]  \tLoss:   87.749977\trec:   60.213127\tkl:   27.536856\n",
            "Epoch: 945 [30100/50000 (60%)]  \tLoss:   88.129707\trec:   60.042202\tkl:   28.087502\n",
            "Epoch: 945 [40100/50000 (80%)]  \tLoss:   88.336739\trec:   61.431870\tkl:   26.904863\n",
            "====> Epoch: 945 Average train loss: 88.7880\n",
            "====> Validation set loss: 92.2173\n",
            "====> Validation set kl: 27.9317\n",
            "Epoch: 946 [  100/50000 ( 0%)]  \tLoss:   87.330231\trec:   59.757305\tkl:   27.572927\n",
            "Epoch: 946 [10100/50000 (20%)]  \tLoss:   91.209206\trec:   62.404842\tkl:   28.804361\n",
            "Epoch: 946 [20100/50000 (40%)]  \tLoss:   87.934097\trec:   60.464901\tkl:   27.469196\n",
            "Epoch: 946 [30100/50000 (60%)]  \tLoss:   86.537567\trec:   58.458553\tkl:   28.079016\n",
            "Epoch: 946 [40100/50000 (80%)]  \tLoss:   91.656494\trec:   62.559387\tkl:   29.097107\n",
            "====> Epoch: 946 Average train loss: 88.7744\n",
            "====> Validation set loss: 92.2790\n",
            "====> Validation set kl: 28.0334\n",
            "Epoch: 947 [  100/50000 ( 0%)]  \tLoss:   92.864586\trec:   62.906933\tkl:   29.957659\n",
            "Epoch: 947 [10100/50000 (20%)]  \tLoss:   94.851471\trec:   65.123474\tkl:   29.727995\n",
            "Epoch: 947 [20100/50000 (40%)]  \tLoss:   91.774139\trec:   63.024090\tkl:   28.750046\n",
            "Epoch: 947 [30100/50000 (60%)]  \tLoss:   87.231590\trec:   59.695564\tkl:   27.536022\n",
            "Epoch: 947 [40100/50000 (80%)]  \tLoss:   84.955841\trec:   58.052673\tkl:   26.903166\n",
            "====> Epoch: 947 Average train loss: 88.7880\n",
            "====> Validation set loss: 92.2469\n",
            "====> Validation set kl: 27.7873\n",
            "Epoch: 948 [  100/50000 ( 0%)]  \tLoss:   89.192116\trec:   60.834534\tkl:   28.357584\n",
            "Epoch: 948 [10100/50000 (20%)]  \tLoss:   87.846130\trec:   59.379150\tkl:   28.466980\n",
            "Epoch: 948 [20100/50000 (40%)]  \tLoss:   85.427170\trec:   58.135998\tkl:   27.291164\n",
            "Epoch: 948 [30100/50000 (60%)]  \tLoss:   84.397331\trec:   57.380676\tkl:   27.016653\n",
            "Epoch: 948 [40100/50000 (80%)]  \tLoss:   87.048218\trec:   59.066998\tkl:   27.981222\n",
            "====> Epoch: 948 Average train loss: 88.7433\n",
            "====> Validation set loss: 92.3495\n",
            "====> Validation set kl: 27.6007\n",
            "Epoch: 949 [  100/50000 ( 0%)]  \tLoss:   88.681343\trec:   61.591843\tkl:   27.089497\n",
            "Epoch: 949 [10100/50000 (20%)]  \tLoss:   90.109695\trec:   62.370541\tkl:   27.739155\n",
            "Epoch: 949 [20100/50000 (40%)]  \tLoss:   85.733963\trec:   58.225330\tkl:   27.508635\n",
            "Epoch: 949 [30100/50000 (60%)]  \tLoss:   88.409317\trec:   61.018787\tkl:   27.390522\n",
            "Epoch: 949 [40100/50000 (80%)]  \tLoss:   89.564697\trec:   61.498737\tkl:   28.065958\n",
            "====> Epoch: 949 Average train loss: 88.7715\n",
            "====> Validation set loss: 92.2613\n",
            "====> Validation set kl: 27.8553\n",
            "Epoch: 950 [  100/50000 ( 0%)]  \tLoss:   86.392624\trec:   59.339279\tkl:   27.053345\n",
            "Epoch: 950 [10100/50000 (20%)]  \tLoss:   86.516769\trec:   59.259914\tkl:   27.256849\n",
            "Epoch: 950 [20100/50000 (40%)]  \tLoss:   92.979874\trec:   63.973213\tkl:   29.006662\n",
            "Epoch: 950 [30100/50000 (60%)]  \tLoss:   87.981277\trec:   60.512089\tkl:   27.469191\n",
            "Epoch: 950 [40100/50000 (80%)]  \tLoss:   88.671127\trec:   60.550823\tkl:   28.120304\n",
            "====> Epoch: 950 Average train loss: 88.7647\n",
            "====> Validation set loss: 92.1789\n",
            "====> Validation set kl: 27.7606\n",
            "Epoch: 951 [  100/50000 ( 0%)]  \tLoss:   90.539604\trec:   62.267616\tkl:   28.271990\n",
            "Epoch: 951 [10100/50000 (20%)]  \tLoss:   85.965996\trec:   59.107563\tkl:   26.858435\n",
            "Epoch: 951 [20100/50000 (40%)]  \tLoss:   93.119194\trec:   63.931774\tkl:   29.187422\n",
            "Epoch: 951 [30100/50000 (60%)]  \tLoss:   84.727394\trec:   57.475018\tkl:   27.252373\n",
            "Epoch: 951 [40100/50000 (80%)]  \tLoss:   88.285294\trec:   59.985222\tkl:   28.300070\n",
            "====> Epoch: 951 Average train loss: 88.7407\n",
            "====> Validation set loss: 92.2694\n",
            "====> Validation set kl: 27.8306\n",
            "Epoch: 952 [  100/50000 ( 0%)]  \tLoss:   87.597549\trec:   59.249680\tkl:   28.347868\n",
            "Epoch: 952 [10100/50000 (20%)]  \tLoss:   90.141022\trec:   61.451336\tkl:   28.689690\n",
            "Epoch: 952 [20100/50000 (40%)]  \tLoss:   88.344910\trec:   60.557262\tkl:   27.787643\n",
            "Epoch: 952 [30100/50000 (60%)]  \tLoss:   84.812477\trec:   56.968075\tkl:   27.844408\n",
            "Epoch: 952 [40100/50000 (80%)]  \tLoss:   90.418282\trec:   61.996746\tkl:   28.421532\n",
            "====> Epoch: 952 Average train loss: 88.7528\n",
            "====> Validation set loss: 92.2619\n",
            "====> Validation set kl: 27.7719\n",
            "Epoch: 953 [  100/50000 ( 0%)]  \tLoss:   93.916176\trec:   65.622292\tkl:   28.293886\n",
            "Epoch: 953 [10100/50000 (20%)]  \tLoss:   89.888184\trec:   62.418407\tkl:   27.469778\n",
            "Epoch: 953 [20100/50000 (40%)]  \tLoss:   91.954430\trec:   63.275166\tkl:   28.679268\n",
            "Epoch: 953 [30100/50000 (60%)]  \tLoss:   88.382614\trec:   61.165791\tkl:   27.216825\n",
            "Epoch: 953 [40100/50000 (80%)]  \tLoss:   89.628220\trec:   60.929695\tkl:   28.698521\n",
            "====> Epoch: 953 Average train loss: 88.7529\n",
            "====> Validation set loss: 92.3125\n",
            "====> Validation set kl: 27.7175\n",
            "Epoch: 954 [  100/50000 ( 0%)]  \tLoss:   86.383690\trec:   58.846649\tkl:   27.537041\n",
            "Epoch: 954 [10100/50000 (20%)]  \tLoss:   88.170860\trec:   60.373535\tkl:   27.797325\n",
            "Epoch: 954 [20100/50000 (40%)]  \tLoss:   88.488388\trec:   61.245895\tkl:   27.242493\n",
            "Epoch: 954 [30100/50000 (60%)]  \tLoss:   89.156548\trec:   61.008270\tkl:   28.148277\n",
            "Epoch: 954 [40100/50000 (80%)]  \tLoss:   88.525818\trec:   61.362888\tkl:   27.162930\n",
            "====> Epoch: 954 Average train loss: 88.7692\n",
            "====> Validation set loss: 92.3279\n",
            "====> Validation set kl: 28.0617\n",
            "Epoch: 955 [  100/50000 ( 0%)]  \tLoss:   87.707245\trec:   59.464314\tkl:   28.242929\n",
            "Epoch: 955 [10100/50000 (20%)]  \tLoss:   88.743126\trec:   60.665127\tkl:   28.077997\n",
            "Epoch: 955 [20100/50000 (40%)]  \tLoss:   84.337234\trec:   56.833065\tkl:   27.504171\n",
            "Epoch: 955 [30100/50000 (60%)]  \tLoss:   90.559853\trec:   62.201591\tkl:   28.358259\n",
            "Epoch: 955 [40100/50000 (80%)]  \tLoss:   86.810097\trec:   58.799606\tkl:   28.010490\n",
            "====> Epoch: 955 Average train loss: 88.7671\n",
            "====> Validation set loss: 92.2411\n",
            "====> Validation set kl: 28.0754\n",
            "Epoch: 956 [  100/50000 ( 0%)]  \tLoss:   88.001686\trec:   59.951340\tkl:   28.050344\n",
            "Epoch: 956 [10100/50000 (20%)]  \tLoss:   89.777046\trec:   61.671612\tkl:   28.105442\n",
            "Epoch: 956 [20100/50000 (40%)]  \tLoss:   89.465309\trec:   61.165497\tkl:   28.299809\n",
            "Epoch: 956 [30100/50000 (60%)]  \tLoss:   87.550163\trec:   60.012634\tkl:   27.537527\n",
            "Epoch: 956 [40100/50000 (80%)]  \tLoss:   89.652916\trec:   61.049873\tkl:   28.603046\n",
            "====> Epoch: 956 Average train loss: 88.7505\n",
            "====> Validation set loss: 92.1942\n",
            "====> Validation set kl: 27.8894\n",
            "Epoch: 957 [  100/50000 ( 0%)]  \tLoss:   91.144073\trec:   63.455254\tkl:   27.688816\n",
            "Epoch: 957 [10100/50000 (20%)]  \tLoss:   86.894470\trec:   58.660244\tkl:   28.234230\n",
            "Epoch: 957 [20100/50000 (40%)]  \tLoss:   88.838692\trec:   59.994453\tkl:   28.844242\n",
            "Epoch: 957 [30100/50000 (60%)]  \tLoss:   86.939865\trec:   59.181622\tkl:   27.758240\n",
            "Epoch: 957 [40100/50000 (80%)]  \tLoss:   88.092110\trec:   59.421833\tkl:   28.670267\n",
            "====> Epoch: 957 Average train loss: 88.7607\n",
            "====> Validation set loss: 92.2991\n",
            "====> Validation set kl: 27.7391\n",
            "Epoch: 958 [  100/50000 ( 0%)]  \tLoss:   88.011642\trec:   59.781590\tkl:   28.230051\n",
            "Epoch: 958 [10100/50000 (20%)]  \tLoss:   88.232712\trec:   60.280342\tkl:   27.952372\n",
            "Epoch: 958 [20100/50000 (40%)]  \tLoss:   89.929970\trec:   62.057098\tkl:   27.872868\n",
            "Epoch: 958 [30100/50000 (60%)]  \tLoss:   94.069450\trec:   64.903435\tkl:   29.166019\n",
            "Epoch: 958 [40100/50000 (80%)]  \tLoss:   89.064552\trec:   60.777657\tkl:   28.286888\n",
            "====> Epoch: 958 Average train loss: 88.7714\n",
            "====> Validation set loss: 92.3034\n",
            "====> Validation set kl: 27.8323\n",
            "Epoch: 959 [  100/50000 ( 0%)]  \tLoss:   88.829086\trec:   60.886864\tkl:   27.942226\n",
            "Epoch: 959 [10100/50000 (20%)]  \tLoss:   90.619102\trec:   63.068806\tkl:   27.550293\n",
            "Epoch: 959 [20100/50000 (40%)]  \tLoss:   85.633377\trec:   58.408203\tkl:   27.225180\n",
            "Epoch: 959 [30100/50000 (60%)]  \tLoss:   91.215752\trec:   63.554661\tkl:   27.661091\n",
            "Epoch: 959 [40100/50000 (80%)]  \tLoss:   91.357765\trec:   62.513454\tkl:   28.844303\n",
            "====> Epoch: 959 Average train loss: 88.7621\n",
            "====> Validation set loss: 92.2562\n",
            "====> Validation set kl: 27.8879\n",
            "Epoch: 960 [  100/50000 ( 0%)]  \tLoss:   87.251480\trec:   59.977627\tkl:   27.273861\n",
            "Epoch: 960 [10100/50000 (20%)]  \tLoss:   87.776756\trec:   60.127773\tkl:   27.648983\n",
            "Epoch: 960 [20100/50000 (40%)]  \tLoss:   88.298141\trec:   60.215069\tkl:   28.083071\n",
            "Epoch: 960 [30100/50000 (60%)]  \tLoss:   90.946518\trec:   63.001934\tkl:   27.944592\n",
            "Epoch: 960 [40100/50000 (80%)]  \tLoss:   89.157867\trec:   61.032810\tkl:   28.125061\n",
            "====> Epoch: 960 Average train loss: 88.7287\n",
            "====> Validation set loss: 92.3577\n",
            "====> Validation set kl: 27.8193\n",
            "Epoch: 961 [  100/50000 ( 0%)]  \tLoss:   86.841743\trec:   59.152843\tkl:   27.688900\n",
            "Epoch: 961 [10100/50000 (20%)]  \tLoss:   90.172813\trec:   60.850647\tkl:   29.322157\n",
            "Epoch: 961 [20100/50000 (40%)]  \tLoss:   90.906609\trec:   62.551662\tkl:   28.354946\n",
            "Epoch: 961 [30100/50000 (60%)]  \tLoss:   88.406502\trec:   61.179733\tkl:   27.226772\n",
            "Epoch: 961 [40100/50000 (80%)]  \tLoss:   87.071701\trec:   59.057079\tkl:   28.014618\n",
            "====> Epoch: 961 Average train loss: 88.7450\n",
            "====> Validation set loss: 92.2870\n",
            "====> Validation set kl: 27.8721\n",
            "Epoch: 962 [  100/50000 ( 0%)]  \tLoss:   90.237289\trec:   62.131092\tkl:   28.106201\n",
            "Epoch: 962 [10100/50000 (20%)]  \tLoss:   89.570770\trec:   60.594540\tkl:   28.976231\n",
            "Epoch: 962 [20100/50000 (40%)]  \tLoss:   88.759239\trec:   60.798344\tkl:   27.960894\n",
            "Epoch: 962 [30100/50000 (60%)]  \tLoss:   87.270447\trec:   60.011814\tkl:   27.258635\n",
            "Epoch: 962 [40100/50000 (80%)]  \tLoss:   87.012466\trec:   59.299664\tkl:   27.712809\n",
            "====> Epoch: 962 Average train loss: 88.7558\n",
            "====> Validation set loss: 92.3407\n",
            "====> Validation set kl: 27.8213\n",
            "Epoch: 963 [  100/50000 ( 0%)]  \tLoss:   87.589020\trec:   59.956406\tkl:   27.632612\n",
            "Epoch: 963 [10100/50000 (20%)]  \tLoss:   90.816597\trec:   62.837616\tkl:   27.978983\n",
            "Epoch: 963 [20100/50000 (40%)]  \tLoss:   88.701035\trec:   61.091091\tkl:   27.609938\n",
            "Epoch: 963 [30100/50000 (60%)]  \tLoss:   91.119255\trec:   62.461014\tkl:   28.658237\n",
            "Epoch: 963 [40100/50000 (80%)]  \tLoss:   89.759415\trec:   61.040672\tkl:   28.718742\n",
            "====> Epoch: 963 Average train loss: 88.7523\n",
            "====> Validation set loss: 92.1968\n",
            "====> Validation set kl: 27.7243\n",
            "Epoch: 964 [  100/50000 ( 0%)]  \tLoss:   87.195076\trec:   59.982544\tkl:   27.212528\n",
            "Epoch: 964 [10100/50000 (20%)]  \tLoss:   93.270027\trec:   63.793552\tkl:   29.476477\n",
            "Epoch: 964 [20100/50000 (40%)]  \tLoss:   88.854019\trec:   60.508335\tkl:   28.345688\n",
            "Epoch: 964 [30100/50000 (60%)]  \tLoss:   86.226837\trec:   59.608055\tkl:   26.618782\n",
            "Epoch: 964 [40100/50000 (80%)]  \tLoss:   89.057831\trec:   60.332527\tkl:   28.725302\n",
            "====> Epoch: 964 Average train loss: 88.7557\n",
            "====> Validation set loss: 92.2311\n",
            "====> Validation set kl: 28.0819\n",
            "Epoch: 965 [  100/50000 ( 0%)]  \tLoss:   91.925224\trec:   63.957588\tkl:   27.967636\n",
            "Epoch: 965 [10100/50000 (20%)]  \tLoss:   86.417519\trec:   58.730263\tkl:   27.687256\n",
            "Epoch: 965 [20100/50000 (40%)]  \tLoss:   88.744980\trec:   60.632832\tkl:   28.112150\n",
            "Epoch: 965 [30100/50000 (60%)]  \tLoss:   86.654861\trec:   59.240448\tkl:   27.414408\n",
            "Epoch: 965 [40100/50000 (80%)]  \tLoss:   83.475319\trec:   56.951218\tkl:   26.524103\n",
            "====> Epoch: 965 Average train loss: 88.7369\n",
            "====> Validation set loss: 92.3414\n",
            "====> Validation set kl: 27.8269\n",
            "Epoch: 966 [  100/50000 ( 0%)]  \tLoss:   90.253838\trec:   62.940632\tkl:   27.313202\n",
            "Epoch: 966 [10100/50000 (20%)]  \tLoss:   90.263817\trec:   61.907635\tkl:   28.356180\n",
            "Epoch: 966 [20100/50000 (40%)]  \tLoss:   86.943611\trec:   59.077881\tkl:   27.865726\n",
            "Epoch: 966 [30100/50000 (60%)]  \tLoss:   94.035858\trec:   65.155640\tkl:   28.880219\n",
            "Epoch: 966 [40100/50000 (80%)]  \tLoss:   88.681358\trec:   60.549633\tkl:   28.131725\n",
            "====> Epoch: 966 Average train loss: 88.7504\n",
            "====> Validation set loss: 92.3289\n",
            "====> Validation set kl: 27.7816\n",
            "Epoch: 967 [  100/50000 ( 0%)]  \tLoss:   85.607086\trec:   58.044922\tkl:   27.562162\n",
            "Epoch: 967 [10100/50000 (20%)]  \tLoss:   89.620094\trec:   61.765694\tkl:   27.854408\n",
            "Epoch: 967 [20100/50000 (40%)]  \tLoss:   87.436775\trec:   59.765373\tkl:   27.671398\n",
            "Epoch: 967 [30100/50000 (60%)]  \tLoss:   84.513756\trec:   57.236004\tkl:   27.277756\n",
            "Epoch: 967 [40100/50000 (80%)]  \tLoss:   86.869904\trec:   59.300495\tkl:   27.569401\n",
            "====> Epoch: 967 Average train loss: 88.7435\n",
            "====> Validation set loss: 92.2048\n",
            "====> Validation set kl: 27.8351\n",
            "Epoch: 968 [  100/50000 ( 0%)]  \tLoss:   87.536095\trec:   59.532894\tkl:   28.003193\n",
            "Epoch: 968 [10100/50000 (20%)]  \tLoss:   89.048683\trec:   60.294960\tkl:   28.753723\n",
            "Epoch: 968 [20100/50000 (40%)]  \tLoss:   90.068504\trec:   62.781296\tkl:   27.287209\n",
            "Epoch: 968 [30100/50000 (60%)]  \tLoss:   90.243698\trec:   62.293308\tkl:   27.950388\n",
            "Epoch: 968 [40100/50000 (80%)]  \tLoss:   86.952011\trec:   59.128498\tkl:   27.823509\n",
            "====> Epoch: 968 Average train loss: 88.7347\n",
            "====> Validation set loss: 92.2570\n",
            "====> Validation set kl: 27.7252\n",
            "Epoch: 969 [  100/50000 ( 0%)]  \tLoss:   85.522873\trec:   58.536743\tkl:   26.986132\n",
            "Epoch: 969 [10100/50000 (20%)]  \tLoss:   87.499275\trec:   60.287090\tkl:   27.212187\n",
            "Epoch: 969 [20100/50000 (40%)]  \tLoss:   91.699501\trec:   63.831287\tkl:   27.868216\n",
            "Epoch: 969 [30100/50000 (60%)]  \tLoss:   87.281197\trec:   59.398262\tkl:   27.882938\n",
            "Epoch: 969 [40100/50000 (80%)]  \tLoss:   84.503464\trec:   57.352509\tkl:   27.150953\n",
            "====> Epoch: 969 Average train loss: 88.7236\n",
            "====> Validation set loss: 92.2735\n",
            "====> Validation set kl: 27.7817\n",
            "Epoch: 970 [  100/50000 ( 0%)]  \tLoss:   87.254608\trec:   59.042206\tkl:   28.212404\n",
            "Epoch: 970 [10100/50000 (20%)]  \tLoss:   88.858009\trec:   60.776863\tkl:   28.081137\n",
            "Epoch: 970 [20100/50000 (40%)]  \tLoss:   90.532860\trec:   62.173885\tkl:   28.358974\n",
            "Epoch: 970 [30100/50000 (60%)]  \tLoss:   91.889305\trec:   64.127419\tkl:   27.761881\n",
            "Epoch: 970 [40100/50000 (80%)]  \tLoss:   91.397179\trec:   63.520821\tkl:   27.876354\n",
            "====> Epoch: 970 Average train loss: 88.7303\n",
            "====> Validation set loss: 92.1889\n",
            "====> Validation set kl: 27.8421\n",
            "Epoch: 971 [  100/50000 ( 0%)]  \tLoss:   91.228691\trec:   62.246975\tkl:   28.981709\n",
            "Epoch: 971 [10100/50000 (20%)]  \tLoss:   88.567711\trec:   60.629627\tkl:   27.938087\n",
            "Epoch: 971 [20100/50000 (40%)]  \tLoss:   89.484001\trec:   61.072849\tkl:   28.411150\n",
            "Epoch: 971 [30100/50000 (60%)]  \tLoss:   85.405411\trec:   57.341560\tkl:   28.063850\n",
            "Epoch: 971 [40100/50000 (80%)]  \tLoss:   88.289513\trec:   59.523933\tkl:   28.765575\n",
            "====> Epoch: 971 Average train loss: 88.7060\n",
            "====> Validation set loss: 92.3596\n",
            "====> Validation set kl: 27.8060\n",
            "Epoch: 972 [  100/50000 ( 0%)]  \tLoss:   90.168961\trec:   60.684704\tkl:   29.484262\n",
            "Epoch: 972 [10100/50000 (20%)]  \tLoss:   88.069267\trec:   59.674141\tkl:   28.395128\n",
            "Epoch: 972 [20100/50000 (40%)]  \tLoss:   93.141823\trec:   64.101013\tkl:   29.040810\n",
            "Epoch: 972 [30100/50000 (60%)]  \tLoss:   90.792320\trec:   61.893555\tkl:   28.898771\n",
            "Epoch: 972 [40100/50000 (80%)]  \tLoss:   88.938438\trec:   61.478798\tkl:   27.459633\n",
            "====> Epoch: 972 Average train loss: 88.7256\n",
            "====> Validation set loss: 92.2187\n",
            "====> Validation set kl: 27.8421\n",
            "Epoch: 973 [  100/50000 ( 0%)]  \tLoss:   90.122154\trec:   61.930984\tkl:   28.191174\n",
            "Epoch: 973 [10100/50000 (20%)]  \tLoss:   91.982430\trec:   62.880676\tkl:   29.101749\n",
            "Epoch: 973 [20100/50000 (40%)]  \tLoss:   89.815170\trec:   61.610413\tkl:   28.204765\n",
            "Epoch: 973 [30100/50000 (60%)]  \tLoss:   88.154037\trec:   59.843426\tkl:   28.310619\n",
            "Epoch: 973 [40100/50000 (80%)]  \tLoss:   89.690796\trec:   60.620342\tkl:   29.070456\n",
            "====> Epoch: 973 Average train loss: 88.7203\n",
            "====> Validation set loss: 92.2321\n",
            "====> Validation set kl: 27.7410\n",
            "Epoch: 974 [  100/50000 ( 0%)]  \tLoss:   90.680885\trec:   62.049599\tkl:   28.631290\n",
            "Epoch: 974 [10100/50000 (20%)]  \tLoss:   87.054985\trec:   58.885174\tkl:   28.169817\n",
            "Epoch: 974 [20100/50000 (40%)]  \tLoss:   90.701286\trec:   62.009563\tkl:   28.691729\n",
            "Epoch: 974 [30100/50000 (60%)]  \tLoss:   86.060173\trec:   59.053417\tkl:   27.006754\n",
            "Epoch: 974 [40100/50000 (80%)]  \tLoss:   87.745651\trec:   59.032391\tkl:   28.713259\n",
            "====> Epoch: 974 Average train loss: 88.7331\n",
            "====> Validation set loss: 92.1666\n",
            "====> Validation set kl: 27.8469\n",
            "Epoch: 975 [  100/50000 ( 0%)]  \tLoss:   89.551521\trec:   61.284393\tkl:   28.267126\n",
            "Epoch: 975 [10100/50000 (20%)]  \tLoss:   88.363564\trec:   60.213490\tkl:   28.150070\n",
            "Epoch: 975 [20100/50000 (40%)]  \tLoss:   92.438026\trec:   63.774818\tkl:   28.663208\n",
            "Epoch: 975 [30100/50000 (60%)]  \tLoss:   87.976440\trec:   60.041435\tkl:   27.935007\n",
            "Epoch: 975 [40100/50000 (80%)]  \tLoss:   89.590446\trec:   61.817120\tkl:   27.773333\n",
            "====> Epoch: 975 Average train loss: 88.7283\n",
            "====> Validation set loss: 92.3234\n",
            "====> Validation set kl: 27.8503\n",
            "Epoch: 976 [  100/50000 ( 0%)]  \tLoss:   90.433609\trec:   61.121120\tkl:   29.312490\n",
            "Epoch: 976 [10100/50000 (20%)]  \tLoss:   90.428413\trec:   61.619667\tkl:   28.808746\n",
            "Epoch: 976 [20100/50000 (40%)]  \tLoss:   92.340187\trec:   63.607597\tkl:   28.732588\n",
            "Epoch: 976 [30100/50000 (60%)]  \tLoss:   90.432594\trec:   61.946171\tkl:   28.486423\n",
            "Epoch: 976 [40100/50000 (80%)]  \tLoss:   88.630333\trec:   60.580467\tkl:   28.049862\n",
            "====> Epoch: 976 Average train loss: 88.7052\n",
            "====> Validation set loss: 92.2424\n",
            "====> Validation set kl: 27.9152\n",
            "Epoch: 977 [  100/50000 ( 0%)]  \tLoss:   90.205635\trec:   62.004440\tkl:   28.201189\n",
            "Epoch: 977 [10100/50000 (20%)]  \tLoss:   85.913261\trec:   58.338974\tkl:   27.574284\n",
            "Epoch: 977 [20100/50000 (40%)]  \tLoss:   90.271530\trec:   62.882027\tkl:   27.389505\n",
            "Epoch: 977 [30100/50000 (60%)]  \tLoss:   86.950066\trec:   59.623238\tkl:   27.326834\n",
            "Epoch: 977 [40100/50000 (80%)]  \tLoss:   90.603249\trec:   62.216843\tkl:   28.386404\n",
            "====> Epoch: 977 Average train loss: 88.7206\n",
            "====> Validation set loss: 92.2427\n",
            "====> Validation set kl: 27.7557\n",
            "Epoch: 978 [  100/50000 ( 0%)]  \tLoss:   86.466270\trec:   59.560078\tkl:   26.906185\n",
            "Epoch: 978 [10100/50000 (20%)]  \tLoss:   88.575348\trec:   60.216442\tkl:   28.358900\n",
            "Epoch: 978 [20100/50000 (40%)]  \tLoss:   88.883728\trec:   60.590012\tkl:   28.293713\n",
            "Epoch: 978 [30100/50000 (60%)]  \tLoss:   88.219162\trec:   61.372356\tkl:   26.846804\n",
            "Epoch: 978 [40100/50000 (80%)]  \tLoss:   89.657417\trec:   61.289646\tkl:   28.367771\n",
            "====> Epoch: 978 Average train loss: 88.7064\n",
            "====> Validation set loss: 92.2811\n",
            "====> Validation set kl: 27.8164\n",
            "Epoch: 979 [  100/50000 ( 0%)]  \tLoss:   87.456482\trec:   59.455570\tkl:   28.000917\n",
            "Epoch: 979 [10100/50000 (20%)]  \tLoss:   87.982010\trec:   60.394901\tkl:   27.587109\n",
            "Epoch: 979 [20100/50000 (40%)]  \tLoss:   88.380348\trec:   60.060085\tkl:   28.320269\n",
            "Epoch: 979 [30100/50000 (60%)]  \tLoss:   90.927422\trec:   61.872372\tkl:   29.055044\n",
            "Epoch: 979 [40100/50000 (80%)]  \tLoss:   88.342545\trec:   60.464081\tkl:   27.878464\n",
            "====> Epoch: 979 Average train loss: 88.7350\n",
            "====> Validation set loss: 92.3350\n",
            "====> Validation set kl: 28.0894\n",
            "Epoch: 980 [  100/50000 ( 0%)]  \tLoss:   86.789177\trec:   58.652176\tkl:   28.136999\n",
            "Epoch: 980 [10100/50000 (20%)]  \tLoss:   91.608986\trec:   63.087563\tkl:   28.521420\n",
            "Epoch: 980 [20100/50000 (40%)]  \tLoss:   84.378342\trec:   57.425247\tkl:   26.953094\n",
            "Epoch: 980 [30100/50000 (60%)]  \tLoss:   88.848061\trec:   60.733837\tkl:   28.114223\n",
            "Epoch: 980 [40100/50000 (80%)]  \tLoss:   89.595375\trec:   61.177162\tkl:   28.418215\n",
            "====> Epoch: 980 Average train loss: 88.7364\n",
            "====> Validation set loss: 92.3237\n",
            "====> Validation set kl: 27.9970\n",
            "Epoch: 981 [  100/50000 ( 0%)]  \tLoss:   87.296173\trec:   59.282837\tkl:   28.013336\n",
            "Epoch: 981 [10100/50000 (20%)]  \tLoss:   88.066818\trec:   59.798691\tkl:   28.268122\n",
            "Epoch: 981 [20100/50000 (40%)]  \tLoss:   88.564812\trec:   60.879921\tkl:   27.684893\n",
            "Epoch: 981 [30100/50000 (60%)]  \tLoss:   90.452705\trec:   62.411327\tkl:   28.041378\n",
            "Epoch: 981 [40100/50000 (80%)]  \tLoss:   90.474800\trec:   61.294525\tkl:   29.180275\n",
            "====> Epoch: 981 Average train loss: 88.7366\n",
            "====> Validation set loss: 92.2728\n",
            "====> Validation set kl: 28.0279\n",
            "Epoch: 982 [  100/50000 ( 0%)]  \tLoss:   88.411446\trec:   60.355869\tkl:   28.055578\n",
            "Epoch: 982 [10100/50000 (20%)]  \tLoss:   88.293739\trec:   59.854012\tkl:   28.439728\n",
            "Epoch: 982 [20100/50000 (40%)]  \tLoss:   88.703682\trec:   61.103016\tkl:   27.600664\n",
            "Epoch: 982 [30100/50000 (60%)]  \tLoss:   90.350494\trec:   61.946327\tkl:   28.404169\n",
            "Epoch: 982 [40100/50000 (80%)]  \tLoss:   88.583923\trec:   61.265671\tkl:   27.318249\n",
            "====> Epoch: 982 Average train loss: 88.7071\n",
            "====> Validation set loss: 92.2827\n",
            "====> Validation set kl: 27.7503\n",
            "Epoch: 983 [  100/50000 ( 0%)]  \tLoss:   88.830841\trec:   60.661491\tkl:   28.169350\n",
            "Epoch: 983 [10100/50000 (20%)]  \tLoss:   89.926659\trec:   61.820023\tkl:   28.106638\n",
            "Epoch: 983 [20100/50000 (40%)]  \tLoss:   88.403687\trec:   60.748039\tkl:   27.655651\n",
            "Epoch: 983 [30100/50000 (60%)]  \tLoss:   88.934158\trec:   60.320423\tkl:   28.613735\n",
            "Epoch: 983 [40100/50000 (80%)]  \tLoss:   84.751076\trec:   58.315975\tkl:   26.435093\n",
            "====> Epoch: 983 Average train loss: 88.6931\n",
            "====> Validation set loss: 92.2367\n",
            "====> Validation set kl: 27.8834\n",
            "Epoch: 984 [  100/50000 ( 0%)]  \tLoss:   81.922569\trec:   55.941238\tkl:   25.981327\n",
            "Epoch: 984 [10100/50000 (20%)]  \tLoss:   90.785751\trec:   62.003284\tkl:   28.782463\n",
            "Epoch: 984 [20100/50000 (40%)]  \tLoss:   87.454712\trec:   59.346298\tkl:   28.108419\n",
            "Epoch: 984 [30100/50000 (60%)]  \tLoss:   88.970352\trec:   61.280190\tkl:   27.690163\n",
            "Epoch: 984 [40100/50000 (80%)]  \tLoss:   89.491859\trec:   61.316631\tkl:   28.175232\n",
            "====> Epoch: 984 Average train loss: 88.7135\n",
            "====> Validation set loss: 92.2445\n",
            "====> Validation set kl: 27.8895\n",
            "Epoch: 985 [  100/50000 ( 0%)]  \tLoss:   90.516640\trec:   62.914555\tkl:   27.602089\n",
            "Epoch: 985 [10100/50000 (20%)]  \tLoss:   87.254608\trec:   59.853752\tkl:   27.400856\n",
            "Epoch: 985 [20100/50000 (40%)]  \tLoss:   90.177925\trec:   60.916161\tkl:   29.261766\n",
            "Epoch: 985 [30100/50000 (60%)]  \tLoss:   91.352341\trec:   63.010033\tkl:   28.342306\n",
            "Epoch: 985 [40100/50000 (80%)]  \tLoss:   87.426201\trec:   59.261700\tkl:   28.164501\n",
            "====> Epoch: 985 Average train loss: 88.6939\n",
            "====> Validation set loss: 92.2839\n",
            "====> Validation set kl: 27.7548\n",
            "Epoch: 986 [  100/50000 ( 0%)]  \tLoss:   85.361679\trec:   57.385811\tkl:   27.975864\n",
            "Epoch: 986 [10100/50000 (20%)]  \tLoss:   86.058220\trec:   58.695320\tkl:   27.362898\n",
            "Epoch: 986 [20100/50000 (40%)]  \tLoss:   87.280212\trec:   59.402668\tkl:   27.877546\n",
            "Epoch: 986 [30100/50000 (60%)]  \tLoss:   90.540199\trec:   61.727165\tkl:   28.813040\n",
            "Epoch: 986 [40100/50000 (80%)]  \tLoss:   87.490379\trec:   60.306366\tkl:   27.184011\n",
            "====> Epoch: 986 Average train loss: 88.7115\n",
            "====> Validation set loss: 92.3300\n",
            "====> Validation set kl: 27.9002\n",
            "Epoch: 987 [  100/50000 ( 0%)]  \tLoss:   88.663589\trec:   59.761360\tkl:   28.902233\n",
            "Epoch: 987 [10100/50000 (20%)]  \tLoss:   89.159950\trec:   61.048584\tkl:   28.111368\n",
            "Epoch: 987 [20100/50000 (40%)]  \tLoss:   89.815201\trec:   60.826836\tkl:   28.988369\n",
            "Epoch: 987 [30100/50000 (60%)]  \tLoss:   90.225990\trec:   62.127666\tkl:   28.098324\n",
            "Epoch: 987 [40100/50000 (80%)]  \tLoss:   87.852791\trec:   60.205360\tkl:   27.647430\n",
            "====> Epoch: 987 Average train loss: 88.7121\n",
            "====> Validation set loss: 92.2319\n",
            "====> Validation set kl: 27.7671\n",
            "Epoch: 988 [  100/50000 ( 0%)]  \tLoss:   86.904510\trec:   59.643093\tkl:   27.261410\n",
            "Epoch: 988 [10100/50000 (20%)]  \tLoss:   83.868530\trec:   57.082100\tkl:   26.786432\n",
            "Epoch: 988 [20100/50000 (40%)]  \tLoss:   86.070107\trec:   58.412270\tkl:   27.657833\n",
            "Epoch: 988 [30100/50000 (60%)]  \tLoss:   88.712784\trec:   60.503399\tkl:   28.209385\n",
            "Epoch: 988 [40100/50000 (80%)]  \tLoss:   90.261765\trec:   60.874146\tkl:   29.387625\n",
            "====> Epoch: 988 Average train loss: 88.7007\n",
            "====> Validation set loss: 92.2588\n",
            "====> Validation set kl: 27.8561\n",
            "Epoch: 989 [  100/50000 ( 0%)]  \tLoss:   85.923416\trec:   58.164593\tkl:   27.758825\n",
            "Epoch: 989 [10100/50000 (20%)]  \tLoss:   90.444191\trec:   61.794823\tkl:   28.649366\n",
            "Epoch: 989 [20100/50000 (40%)]  \tLoss:   83.397293\trec:   57.120590\tkl:   26.276707\n",
            "Epoch: 989 [30100/50000 (60%)]  \tLoss:   89.022224\trec:   61.493870\tkl:   27.528358\n",
            "Epoch: 989 [40100/50000 (80%)]  \tLoss:   92.425011\trec:   62.897778\tkl:   29.527227\n",
            "====> Epoch: 989 Average train loss: 88.6967\n",
            "====> Validation set loss: 92.2090\n",
            "====> Validation set kl: 27.9117\n",
            "Epoch: 990 [  100/50000 ( 0%)]  \tLoss:   90.023087\trec:   61.619209\tkl:   28.403873\n",
            "Epoch: 990 [10100/50000 (20%)]  \tLoss:   91.039032\trec:   62.177704\tkl:   28.861324\n",
            "Epoch: 990 [20100/50000 (40%)]  \tLoss:   92.355309\trec:   62.791260\tkl:   29.564053\n",
            "Epoch: 990 [30100/50000 (60%)]  \tLoss:   89.417877\trec:   61.843826\tkl:   27.574055\n",
            "Epoch: 990 [40100/50000 (80%)]  \tLoss:   87.460075\trec:   59.865818\tkl:   27.594255\n",
            "====> Epoch: 990 Average train loss: 88.6926\n",
            "====> Validation set loss: 92.3102\n",
            "====> Validation set kl: 27.8543\n",
            "Epoch: 991 [  100/50000 ( 0%)]  \tLoss:   92.040604\trec:   63.281391\tkl:   28.759211\n",
            "Epoch: 991 [10100/50000 (20%)]  \tLoss:   88.546959\trec:   61.676716\tkl:   26.870247\n",
            "Epoch: 991 [20100/50000 (40%)]  \tLoss:   90.253769\trec:   62.222057\tkl:   28.031708\n",
            "Epoch: 991 [30100/50000 (60%)]  \tLoss:   89.533432\trec:   62.349155\tkl:   27.184277\n",
            "Epoch: 991 [40100/50000 (80%)]  \tLoss:   89.929489\trec:   61.387959\tkl:   28.541538\n",
            "====> Epoch: 991 Average train loss: 88.7003\n",
            "====> Validation set loss: 92.2578\n",
            "====> Validation set kl: 27.7803\n",
            "Epoch: 992 [  100/50000 ( 0%)]  \tLoss:   86.978439\trec:   58.905281\tkl:   28.073154\n",
            "Epoch: 992 [10100/50000 (20%)]  \tLoss:   83.989861\trec:   56.840500\tkl:   27.149355\n",
            "Epoch: 992 [20100/50000 (40%)]  \tLoss:   90.498222\trec:   62.664150\tkl:   27.834068\n",
            "Epoch: 992 [30100/50000 (60%)]  \tLoss:   93.691689\trec:   64.470871\tkl:   29.220812\n",
            "Epoch: 992 [40100/50000 (80%)]  \tLoss:   87.663620\trec:   60.368916\tkl:   27.294708\n",
            "====> Epoch: 992 Average train loss: 88.6994\n",
            "====> Validation set loss: 92.1993\n",
            "====> Validation set kl: 27.7999\n",
            "Epoch: 993 [  100/50000 ( 0%)]  \tLoss:   91.405869\trec:   63.109070\tkl:   28.296793\n",
            "Epoch: 993 [10100/50000 (20%)]  \tLoss:   88.497009\trec:   60.747704\tkl:   27.749304\n",
            "Epoch: 993 [20100/50000 (40%)]  \tLoss:   85.703163\trec:   58.514847\tkl:   27.188314\n",
            "Epoch: 993 [30100/50000 (60%)]  \tLoss:   91.338531\trec:   62.619209\tkl:   28.719322\n",
            "Epoch: 993 [40100/50000 (80%)]  \tLoss:   89.611603\trec:   61.537987\tkl:   28.073612\n",
            "====> Epoch: 993 Average train loss: 88.6821\n",
            "====> Validation set loss: 92.2501\n",
            "====> Validation set kl: 27.9318\n",
            "Epoch: 994 [  100/50000 ( 0%)]  \tLoss:   86.300270\trec:   58.709812\tkl:   27.590454\n",
            "Epoch: 994 [10100/50000 (20%)]  \tLoss:   86.978653\trec:   59.969170\tkl:   27.009483\n",
            "Epoch: 994 [20100/50000 (40%)]  \tLoss:   87.044609\trec:   59.736057\tkl:   27.308552\n",
            "Epoch: 994 [30100/50000 (60%)]  \tLoss:   86.297104\trec:   58.351551\tkl:   27.945557\n",
            "Epoch: 994 [40100/50000 (80%)]  \tLoss:   87.286476\trec:   58.769802\tkl:   28.516666\n",
            "====> Epoch: 994 Average train loss: 88.6694\n",
            "====> Validation set loss: 92.2824\n",
            "====> Validation set kl: 28.0123\n",
            "Epoch: 995 [  100/50000 ( 0%)]  \tLoss:   88.780464\trec:   60.803520\tkl:   27.976946\n",
            "Epoch: 995 [10100/50000 (20%)]  \tLoss:   87.469521\trec:   59.447048\tkl:   28.022469\n",
            "Epoch: 995 [20100/50000 (40%)]  \tLoss:   88.759743\trec:   61.157566\tkl:   27.602175\n",
            "Epoch: 995 [30100/50000 (60%)]  \tLoss:   89.625084\trec:   61.570969\tkl:   28.054115\n",
            "Epoch: 995 [40100/50000 (80%)]  \tLoss:   92.264122\trec:   63.882568\tkl:   28.381552\n",
            "====> Epoch: 995 Average train loss: 88.6844\n",
            "====> Validation set loss: 92.3193\n",
            "====> Validation set kl: 27.8696\n",
            "Epoch: 996 [  100/50000 ( 0%)]  \tLoss:   86.950806\trec:   58.427715\tkl:   28.523092\n",
            "Epoch: 996 [10100/50000 (20%)]  \tLoss:   90.069489\trec:   61.505440\tkl:   28.564049\n",
            "Epoch: 996 [20100/50000 (40%)]  \tLoss:   88.335175\trec:   60.984287\tkl:   27.350883\n",
            "Epoch: 996 [30100/50000 (60%)]  \tLoss:   85.170021\trec:   58.625690\tkl:   26.544331\n",
            "Epoch: 996 [40100/50000 (80%)]  \tLoss:   86.627373\trec:   59.440807\tkl:   27.186560\n",
            "====> Epoch: 996 Average train loss: 88.6906\n",
            "====> Validation set loss: 92.2504\n",
            "====> Validation set kl: 27.8085\n",
            "Epoch: 997 [  100/50000 ( 0%)]  \tLoss:   87.565094\trec:   59.751034\tkl:   27.814056\n",
            "Epoch: 997 [10100/50000 (20%)]  \tLoss:   89.873222\trec:   61.502766\tkl:   28.370453\n",
            "Epoch: 997 [20100/50000 (40%)]  \tLoss:   89.184921\trec:   61.473015\tkl:   27.711908\n",
            "Epoch: 997 [30100/50000 (60%)]  \tLoss:   87.601906\trec:   60.348885\tkl:   27.253019\n",
            "Epoch: 997 [40100/50000 (80%)]  \tLoss:   86.713249\trec:   58.809002\tkl:   27.904247\n",
            "====> Epoch: 997 Average train loss: 88.6735\n",
            "====> Validation set loss: 92.1553\n",
            "====> Validation set kl: 27.6833\n",
            "Epoch: 998 [  100/50000 ( 0%)]  \tLoss:   87.897423\trec:   59.479561\tkl:   28.417860\n",
            "Epoch: 998 [10100/50000 (20%)]  \tLoss:   89.072144\trec:   61.391869\tkl:   27.680283\n",
            "Epoch: 998 [20100/50000 (40%)]  \tLoss:   89.471657\trec:   60.209316\tkl:   29.262348\n",
            "Epoch: 998 [30100/50000 (60%)]  \tLoss:   86.987579\trec:   58.922058\tkl:   28.065512\n",
            "Epoch: 998 [40100/50000 (80%)]  \tLoss:   85.792320\trec:   58.428242\tkl:   27.364082\n",
            "====> Epoch: 998 Average train loss: 88.6778\n",
            "====> Validation set loss: 92.2722\n",
            "====> Validation set kl: 27.9591\n",
            "Epoch: 999 [  100/50000 ( 0%)]  \tLoss:   86.408745\trec:   58.827625\tkl:   27.581127\n",
            "Epoch: 999 [10100/50000 (20%)]  \tLoss:   91.695206\trec:   62.743610\tkl:   28.951591\n",
            "Epoch: 999 [20100/50000 (40%)]  \tLoss:   86.199913\trec:   58.901283\tkl:   27.298628\n",
            "Epoch: 999 [30100/50000 (60%)]  \tLoss:   86.310471\trec:   58.964725\tkl:   27.345739\n",
            "Epoch: 999 [40100/50000 (80%)]  \tLoss:   87.645020\trec:   59.336044\tkl:   28.308977\n",
            "====> Epoch: 999 Average train loss: 88.6750\n",
            "====> Validation set loss: 92.2450\n",
            "====> Validation set kl: 27.9629\n",
            "Epoch: 1000 [  100/50000 ( 0%)]  \tLoss:   88.552170\trec:   60.632824\tkl:   27.919342\n",
            "Epoch: 1000 [10100/50000 (20%)]  \tLoss:   85.128181\trec:   57.317654\tkl:   27.810524\n",
            "Epoch: 1000 [20100/50000 (40%)]  \tLoss:   88.830528\trec:   60.158875\tkl:   28.671644\n",
            "Epoch: 1000 [30100/50000 (60%)]  \tLoss:   92.169960\trec:   63.011063\tkl:   29.158892\n",
            "Epoch: 1000 [40100/50000 (80%)]  \tLoss:   88.627632\trec:   59.785492\tkl:   28.842142\n",
            "====> Epoch: 1000 Average train loss: 88.6762\n",
            "====> Validation set loss: 92.2625\n",
            "====> Validation set kl: 27.7901\n",
            "====> Validation set loss: 92.2606\n",
            "====> Validation set kl: 27.8337\n",
            "Computing log-likelihood on test set\n",
            "Progress: 0.00%\n",
            "Progress: 10.00%\n",
            "Progress: 20.00%\n",
            "Progress: 30.00%\n",
            "Progress: 40.00%\n",
            "Progress: 50.00%\n",
            "Progress: 60.00%\n",
            "Progress: 70.00%\n",
            "Progress: 80.00%\n",
            "Progress: 90.00%\n",
            "====> Test set loss: 91.4268\n",
            "====> Test set kl: 27.6662\n",
            "====> Test set log-likelihood: 87.5068\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}